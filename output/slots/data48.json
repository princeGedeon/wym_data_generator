[{"titre": "R\u00e9gression lin\u00e9aire", "text_origine": "En statistiques, en \u00e9conom\u00e9trie et en apprentissage automatique, un mod\u00e8le de r\u00e9gression lin\u00e9aire est un mod\u00e8le de r\u00e9gression qui cherche \u00e0 \u00e9tablir une relation lin\u00e9aire entre une variable, dite expliqu\u00e9e, et une ou plusieurs variables, dites explicatives.\nOn parle aussi de mod\u00e8le lin\u00e9aire ou de mod\u00e8le de r\u00e9gression lin\u00e9aire.\nParmi les mod\u00e8les de r\u00e9gression lin\u00e9aire, le plus simple est l'ajustement affine. Celui-ci consiste \u00e0 rechercher la droite permettant d'expliquer le comportement d'une variable statistique y comme \u00e9tant une fonction affine d'une autre variable statistique x.\nEn g\u00e9n\u00e9ral, le mod\u00e8le de r\u00e9gression lin\u00e9aire d\u00e9signe un mod\u00e8le dans lequel l'esp\u00e9rance conditionnelle de y connaissant x est une fonction affine des param\u00e8tres. Cependant, on peut aussi consid\u00e9rer des mod\u00e8les dans lesquels c'est la m\u00e9diane conditionnelle de y connaissant x ou n'importe quel quantile de la distribution de y connaissant x qui est une fonction affine des param\u00e8tres.\nLe mod\u00e8le de r\u00e9gression lin\u00e9aire est souvent estim\u00e9 par la m\u00e9thode des moindres carr\u00e9s mais il existe aussi de nombreuses autres m\u00e9thodes pour estimer ce mod\u00e8le. On peut par exemple estimer le mod\u00e8le par maximum de vraisemblance ou encore par inf\u00e9rence bay\u00e9sienne.\nBien qu'ils soient souvent pr\u00e9sent\u00e9s ensemble, le mod\u00e8le lin\u00e9aire et la m\u00e9thode des moindres carr\u00e9s ne d\u00e9signent pas la m\u00eame chose. Le mod\u00e8le lin\u00e9aire d\u00e9signe une classe de mod\u00e8les qui peuvent \u00eatre estim\u00e9s par un grand nombre de m\u00e9thodes, et la m\u00e9thode des moindres carr\u00e9s d\u00e9signe une m\u00e9thode d'estimation. Elle peut \u00eatre utilis\u00e9e pour estimer diff\u00e9rents types de mod\u00e8les.", "element_cle": "1. La r\u00e9gression lin\u00e9aire est un mod\u00e8le statistique qui cherche \u00e0 \u00e9tablir une relation lin\u00e9aire entre une variable expliqu\u00e9e et une ou plusieurs variables explicatives.\n2. Parmi les mod\u00e8les de r\u00e9gression lin\u00e9aire, l'ajustement affine est le plus simple et consiste \u00e0 trouver une droite pour expliquer le comportement d'une variable statistique en fonction d'une autre.\n3. Le mod\u00e8le de r\u00e9gression lin\u00e9aire est souvent estim\u00e9 par la m\u00e9thode des moindres carr\u00e9s, mais il existe d'autres m\u00e9thodes comme le maximum de vraisemblance ou l'inf\u00e9rence bay\u00e9sienne.\n4. Le mod\u00e8le lin\u00e9aire et la m\u00e9thode des moindres carr\u00e9s sont souvent pr\u00e9sent\u00e9s ensemble, mais ils ne d\u00e9signent pas la m\u00eame chose. Le mod\u00e8le lin\u00e9aire est une classe de mod\u00e8les, tandis que les moindres carr\u00e9s sont une m\u00e9thode d'estimation.\n5. Le mod\u00e8le de r\u00e9gression lin\u00e9aire peut consid\u00e9rer l'esp\u00e9rance conditionnelle, la m\u00e9diane conditionnelle ou tout autre quantile de la distribution de la variable expliqu\u00e9e en fonction des param\u00e8tres.", "rap": "[Couplet 1]\nLa r\u00e9gression lin\u00e9aire, mod\u00e8le si puissant\nQui cherche la relation, entre des variables flamboyantes\nExpliqu\u00e9e et explicatives, c'est \u00e7a l'id\u00e9e\nPour comprendre le monde, et pr\u00e9dire nos id\u00e9es\n\n[Au refrain]\nR\u00e9gression lin\u00e9aire, dans les calculs tout nus\nAffine ou pas, elle ajuste le plus juste\nM\u00e9thode des moindres carr\u00e9s, tant convoit\u00e9e\nMais d'autres techniques, sont aussi utilis\u00e9es\n\n[Couplet 2]\nParmi les mod\u00e8les, l'ajustement affine\nTrouver une droite, pour comprendre le d\u00e9clin\nLa variable statistique, expliqu\u00e9e par une autre\nC'est \u00e7a l'essentiel, pour pas faire d'erreur\n\n[Au refrain]\nR\u00e9gression lin\u00e9aire, dans les calculs tout nus\nAffine ou pas, elle ajuste le plus juste\nM\u00e9thode des moindres carr\u00e9s, tant convoit\u00e9e\nMais d'autres techniques, sont aussi utilis\u00e9es\n\n[Refrain]\nR\u00e9gression lin\u00e9aire, mod\u00e8le math\u00e9matique\nPour comprendre les ph\u00e9nom\u00e8nes, c'est pas spectaculaire\nMais c'est essentiel, pour avancer dans la vie\nLa science des nombres, qui nous \u00e9blouit."}, {"titre": "R\u00e9gression lin\u00e9aire multiple", "text_origine": "En statistique, la r\u00e9gression lin\u00e9aire multiple est une m\u00e9thode de r\u00e9gression math\u00e9matique \u00e9tendant la r\u00e9gression lin\u00e9aire simple pour d\u00e9crire les variations d'une variable endog\u00e8ne associ\u00e9e aux variations de plusieurs variables exog\u00e8nes.\nPar exemple, une analyse de r\u00e9gression multiple peut r\u00e9v\u00e9ler une relation positive entre la demande de lunettes de soleil et diff\u00e9rents caract\u00e8res d\u00e9mographiques (\u00e2ge, salaire) des acheteurs de ce produit. La demande augmente et baisse avec les variations de ces caract\u00e9ristiques.", "element_cle": "- La r\u00e9gression lin\u00e9aire multiple est une m\u00e9thode statistique qui \u00e9tend la r\u00e9gression lin\u00e9aire simple\n- Elle permet de d\u00e9crire les variations d'une variable endog\u00e8ne avec plusieurs variables exog\u00e8nes\n- Elle peut \u00eatre utilis\u00e9e pour analyser la relation entre la demande de lunettes de soleil et les caract\u00e9ristiques d\u00e9mographiques des acheteurs\n- La demande de lunettes de soleil augmente ou diminue en fonction des variations de ces caract\u00e9ristiques\n- L'\u00e2ge et le salaire sont des exemples de caract\u00e9ristiques d\u00e9mographiques pouvant influencer la demande de lunettes de soleil.", "rap": "[Couplet 1]\nLa r\u00e9gression lin\u00e9aire multiple, m\u00e9thode statistique\nElle \u00e9tend la lin\u00e9aire simple, c'est math\u00e9matique\nOn d\u00e9crit les variations de la variable endog\u00e8ne\nAvec plusieurs variables exog\u00e8nes, c'est pas de la vanne\n\nTu veux savoir comment les lunettes de soleil se vendent\nAnalyse la relation, c'est pas du vent\nLa demande augmente ou diminue selon les caract\u00e9ristiques\nD\u00e9mographiques des acheteurs, c'est pas du cirque\n\n[Refrain]\nR\u00e9gression lin\u00e9aire multiple, analyse \u00e9ducative\nComprendre les fluctuations, c'est l'objectif captivant\nLunettes de soleil, effet de l'\u00e2ge et du salaire\nTout \u00e7a joue un r\u00f4le, c'est pas un d\u00e9lire ordinaire\n\n[Couplet 2]\nL'\u00e2ge et le salaire, exemples parmi tant d'autres\nQui peuvent influencer la demande, c'est un facteur\nLes jeunes privil\u00e9gient le style, les personnes \u00e2g\u00e9es la protection\nCes caract\u00e9ristiques d\u00e9mographiques, y'a pas d'illusion\n\nAlors si tu veux comprendre les tendances de march\u00e9\nUtilise la r\u00e9gression lin\u00e9aire multiple, c'est pas compliqu\u00e9\nAnalyse les variables exog\u00e8nes, trouve les corr\u00e9lations\nEt tu pourras pr\u00e9dire les ventes, une vraie r\u00e9volution\n\n[Refrain]\nR\u00e9gression lin\u00e9aire multiple, analyse \u00e9ducative\nComprendre les fluctuations, c'est l'objectif captivant\nLunettes de soleil, effet de l'\u00e2ge et du salaire\nTout \u00e7a joue un r\u00f4le, c'est pas un d\u00e9lire ordinaire"}, {"titre": "R\u00e9gression non lin\u00e9aire", "text_origine": "Une r\u00e9gression non lin\u00e9aire consiste \u00e0 ajuster un mod\u00e8le, en g\u00e9n\u00e9ral non lin\u00e9aire,\n\ny = \u0192a1, \u2026, am(x)pour un ensemble de valeurs (xi, yi)1 \u2264 i \u2264 n. Les variables xi et yi peuvent \u00eatre des scalaires ou des vecteurs.\nPar \u00ab ajuster \u00bb, il faut comprendre : d\u00e9terminer les param\u00e8tres de la loi, (a1, \u2026, am), afin de minimiser S = ||ri||, avec :\n\nri = yi - \u0192a1, \u2026, am(xi).\n||\u2026|| est une norme.On utilise en g\u00e9n\u00e9ral la norme euclidienne, ou norme \u21132 ; on parle alors de m\u00e9thode des moindres carr\u00e9s.\n\n\t\t\t\n\t\t\t\n\t\t\n\t\t\n\t\t\t\n\t\t\t\n\t\t\n(Illustrations extraites du livre Calcul d'incertitudes).", "element_cle": "1. La r\u00e9gression non lin\u00e9aire consiste \u00e0 ajuster un mod\u00e8le qui n'est pas lin\u00e9aire.\n2. Les variables xi et yi peuvent \u00eatre des scalaires ou des vecteurs.\n3. L'objectif est de d\u00e9terminer les param\u00e8tres de la loi afin de minimiser S, qui repr\u00e9sente la diff\u00e9rence entre les valeurs observ\u00e9es et celles pr\u00e9dites par le mod\u00e8le.\n4. On utilise g\u00e9n\u00e9ralement la norme euclidienne (norme \u21132) pour mesurer cette diff\u00e9rence.\n5. Cette m\u00e9thode est \u00e9galement connue sous le nom de m\u00e9thode des moindres carr\u00e9s.", "rap": "[Couplet 1]\nR\u00e9gression non lin\u00e9aire, un mod\u00e8le \u00e0 ajuster\nQuand les donn\u00e9es sont pas normales, faut pas se fier\nVariables xi et yi, scalaires ou vecteurs\nOn veut trouver les param\u00e8tres, c'est le d\u00e9fis majeur\n\nOn veut minimiser S, diff\u00e9rence observ\u00e9e\nAvec les valeurs pr\u00e9dites, un d\u00e9fi qui se dresse\nLa norme euclidienne, on l'utilise souvent\nPour mesurer l'\u00e9cart, c'est notre ingr\u00e9dient\n\n[Refrain]\nR\u00e9gression non lin\u00e9aire, on cherche les param\u00e8tres\nPour trouver le meilleur mod\u00e8le, il faut pers\u00e9v\u00e9rer\nM\u00e9thode des moindres carr\u00e9s, on l'appelle ainsi\nDans le monde des stats, c'est un outil pr\u00e9cis\n\n[Couplet 2]\nOn veut trouver la loi qui correspond le mieux\nAux donn\u00e9es qu'on a, \u00e7a demande de l'ardeur\nOn ajuste le mod\u00e8le, on fait des calculs\nOn cherche la meilleure approximation, c'est notre but\n\nLa r\u00e9gression non lin\u00e9aire, c'est pas de la tarte\nMais avec patience et rigueur, on peut faire des cartes\nOn optimise les param\u00e8tres, on cherche l'\u00e9quation\nQui d\u00e9crit au mieux les donn\u00e9es, sans aucune d\u00e9viation\n\n[Refrain]\nR\u00e9gression non lin\u00e9aire, on cherche les param\u00e8tres\nPour trouver le meilleur mod\u00e8le, il faut pers\u00e9v\u00e9rer\nM\u00e9thode des moindres carr\u00e9s, on l'appelle ainsi\nDans le monde des stats, c'est un outil pr\u00e9cis"}, {"titre": "Coefficient de d\u00e9termination", "text_origine": "En statistique, le coefficient de d\u00e9termination lin\u00e9aire de Pearson, not\u00e9 R2 ou r2, est une mesure de la qualit\u00e9 de la pr\u00e9diction d'une r\u00e9gression lin\u00e9aire. \nIl est d\u00e9fini par[r\u00e9f. n\u00e9cessaire] :\n\n  \n    \n      \n        \n          R\n          \n            2\n          \n        \n        =\n        1\n        \u2212\n        \n          \n            \n              \n                \n                  \u2211\n                  \n                    i\n                    =\n                    1\n                  \n                  \n                    n\n                  \n                \n                \n                  \n                    (\n                    \n                      \n                        y\n                        \n                          i\n                        \n                      \n                      \u2212\n                      \n                        \n                          \n                            \n                              y\n                              \n                                i\n                              \n                            \n                            ^\n                          \n                        \n                      \n                    \n                    )\n                  \n                  \n                    2\n                  \n                \n              \n              \n                \n                  \u2211\n                  \n                    i\n                    =\n                    1\n                  \n                  \n                    n\n                  \n                \n                \n                  \n                    (\n                    \n                      \n                        y\n                        \n                          i\n                        \n                      \n                      \u2212\n                      \n                        \n                          \n                            y\n                            \u00af\n                          \n                        \n                      \n                    \n                    )\n                  \n                  \n                    2\n                  \n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle R^{2}=1-{\\dfrac {\\sum _{i=1}^{n}\\left(y_{i}-{\\hat {y_{i}}}\\right)^{2}}{\\sum _{i=1}^{n}\\left(y_{i}-{\\bar {y}}\\right)^{2}}}}\n  o\u00f9 n est le nombre de mesures, \n  \n    \n      \n        \n          y\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle y_{i}}\n   la valeur de la mesure no i, \n  \n    \n      \n        \n          \n            \n              \n                y\n                \n                  i\n                \n              \n              ^\n            \n          \n        \n      \n    \n    {\\displaystyle {\\hat {y_{i}}}}\n   la valeur pr\u00e9dite correspondante et \n  \n    \n      \n        \n          \n            \n              y\n              \u00af\n            \n          \n        \n      \n    \n    {\\displaystyle {\\bar {y}}}\n   la moyenne des mesures.", "element_cle": "1. Le coefficient de d\u00e9termination lin\u00e9aire de Pearson est utilis\u00e9 en statistique pour mesurer la qualit\u00e9 de la pr\u00e9diction d'une r\u00e9gression lin\u00e9aire.\n2. Le coefficient de d\u00e9termination est not\u00e9 R2 ou r2.\n3. Il est d\u00e9fini comme la diff\u00e9rence entre 1 et la somme des carr\u00e9s des \u00e9carts entre les valeurs pr\u00e9dites et les valeurs r\u00e9elles.\n4. Le coefficient de d\u00e9termination est calcul\u00e9 en utilisant les valeurs y r\u00e9elles, les valeurs y pr\u00e9dites et la moyenne des valeurs y r\u00e9elles.\n5. Le coefficient de d\u00e9termination permet d'\u00e9valuer dans quelle mesure les valeurs pr\u00e9dites s'\u00e9cartent des valeurs r\u00e9elles dans une r\u00e9gression lin\u00e9aire.", "rap": "[Couplet 1]\nJ'suis l\u00e0 pour t'apprendre, j'te balance des stats (stats)\nOn va parler du coeff, ouais j'vais tout t'expliquer (expliquer)\nC'est le R2, ou le petit r2, ouais tu sais c'que j'veux dire (dire)\nC'est un truc de statistique, ouais \u00e7a va te surprendre (surprendre)\n\nLe coefficient de d\u00e9termination, ouais c'est une mesure (mesure)\nPour voir la qualit\u00e9 d'la pr\u00e9diction, dans l'r\u00e9gime lin\u00e9aire (lin\u00e9aire)\nIl calcule la diff\u00e9rence, entre les valeurs pr\u00e9dites et r\u00e9elles (r\u00e9elles)\nEt il joue avec les carr\u00e9s, ouais \u00e7a fait son affaire (ouais \u00e7a fait son affaire)\n\n[Refrain]\nLe coeff de d\u00e9termination, ouais c'est important (important)\nDans les stats, ouais faut l'avoir en t\u00eate (en t\u00eate)\nIl dit \u00e0 quel point, les pr\u00e9dictions sont fiables (fiables)\nAlors \u00e9coute bien, j'vais tout t'expliquer (expliquer)\n\n[Couplet 2]\nPour calculer le coeff, ouais faut quelques \u00e9l\u00e9ments (\u00e9l\u00e9ments)\nLes valeurs r\u00e9elles, les valeurs pr\u00e9dites, c'est \u00e7a l'plan (l'plan)\nPuis y a la moyenne, des valeurs r\u00e9elles (r\u00e9elles)\nC'est comme \u00e7a qu'on proc\u00e8de, ouais c'est dans le deal (dans le deal)\n\nLe coeff de d\u00e9termination, il est toujours entre 0 et 1 (0 et 1)\nPlus il est proche de 1, plus la pr\u00e9diction est fine (fine)\n\u00c7a veut dire que nos valeurs pr\u00e9dites, sont proches d'la r\u00e9alit\u00e9 (r\u00e9alit\u00e9)\nC'est \u00e7a qu'on veut, dans une r\u00e9gression lin\u00e9aire, c'est pas compliqu\u00e9 (compliqu\u00e9)\n\n[Refrain]\nLe coeff de d\u00e9termination, ouais c'est important (important)\nDans les stats, ouais faut l'avoir en t\u00eate (en t\u00eate)\nIl dit \u00e0 quel point, les pr\u00e9dictions sont fiables (fiables)\nAlors \u00e9coute bien, j'vais tout t'expliquer (expliquer)"}, {"titre": "R\u00e9gression (statistiques)", "text_origine": "En math\u00e9matiques, la r\u00e9gression recouvre plusieurs m\u00e9thodes d\u2019analyse statistique permettant d\u2019approcher une variable \u00e0 partir d\u2019autres qui lui sont corr\u00e9l\u00e9es. Par extension, le terme est aussi utilis\u00e9 pour certaines m\u00e9thodes d\u2019ajustement de courbe.\nEn apprentissage automatique, on distingue les probl\u00e8mes de r\u00e9gression des probl\u00e8mes de classification. Ainsi, on consid\u00e8re que les probl\u00e8mes de pr\u00e9diction d'une variable quantitative sont des probl\u00e8mes de r\u00e9gression tandis que les probl\u00e8mes de pr\u00e9diction d'une variable qualitative sont des probl\u00e8mes de classification. Certaines m\u00e9thodes, comme la r\u00e9gression logistique, sont \u00e0 la fois des m\u00e9thodes de r\u00e9gression au sens o\u00f9 il s'agit de pr\u00e9dire la probabilit\u00e9 d'appartenir \u00e0 chacune des classes et des m\u00e9thodes de classification.", "element_cle": "1. La r\u00e9gression est une m\u00e9thode d'analyse statistique pour approcher une variable corr\u00e9l\u00e9e \u00e0 partir d'autres variables.\n2. La r\u00e9gression est \u00e9galement utilis\u00e9e pour ajuster des courbes.\n3. En apprentissage automatique, on diff\u00e9rencie les probl\u00e8mes de r\u00e9gression et les probl\u00e8mes de classification.\n4. Les probl\u00e8mes de pr\u00e9diction de variables quantitatives sont des probl\u00e8mes de r\u00e9gression.\n5. Les probl\u00e8mes de pr\u00e9diction de variables qualitatives sont des probl\u00e8mes de classification.\n6. La r\u00e9gression logistique est \u00e0 la fois une m\u00e9thode de r\u00e9gression et de classification.", "rap": "[Couplet 1]\nLa r\u00e9gression, un outil statistique pr\u00e9cis\nPour approcher une variable, c'est la base du taf\nOn analyse les donn\u00e9es et leurs relations\nPour pr\u00e9dire l'avenir avec pr\u00e9cision\n\nOn ajuste des courbes, on fait des calculs\nLa r\u00e9gression, c'est pas du hasard, c'est du calcul\nEn machine learning, on fait la distinction\nEntre r\u00e9gression et classification\n\n[Refrain]\nR\u00e9gression, r\u00e9gression, on trace la courbe\nPr\u00e9dire le futur, tel est le but\nDes variables quantitatives aux qualitatives\nLa r\u00e9gression, c'est la m\u00e9thode explicite\n\n[Couplet 2]\nPour pr\u00e9dire des chiffres, on utilise la r\u00e9gression\nUn probl\u00e8me en math\u00e9matiques, une vraie passion\nMais pour pr\u00e9dire une classe, c'est la classification\nLa r\u00e9gression logistique, la solution\n\t\nOn combine regression et classification\nPour avoir des pr\u00e9dictions sans distinction\nLa r\u00e9gression logistique, c'est la double action\nDans le monde des stats, elle fait sensation\n\n[Refrain]\nR\u00e9gression, r\u00e9gression, on trace la courbe\nPr\u00e9dire le futur, tel est le but\nDes variables quantitatives aux qualitatives\nLa r\u00e9gression, c'est la m\u00e9thode explicite"}, {"titre": "Corr\u00e9lation (statistiques)", "text_origine": "En probabilit\u00e9s et en statistique, la corr\u00e9lation entre plusieurs variables al\u00e9atoires ou statistiques est une notion de liaison qui contredit leur ind\u00e9pendance.\nCette corr\u00e9lation est tr\u00e8s souvent r\u00e9duite \u00e0 la corr\u00e9lation lin\u00e9aire entre variables quantitatives, c\u2019est-\u00e0-dire l\u2019ajustement d\u2019une variable par rapport \u00e0 l\u2019autre par une relation affine obtenue par r\u00e9gression lin\u00e9aire. Pour cela, on calcule un coefficient de corr\u00e9lation lin\u00e9aire, quotient de leur covariance par le produit de leurs \u00e9carts types. Son signe indique si des valeurs plus hautes de l\u2019une correspondent \u00ab en moyenne \u00bb \u00e0 des valeurs plus hautes ou plus basses pour l\u2019autre. La valeur absolue du coefficient, toujours comprise entre 0 et 1, ne mesure pas l\u2019intensit\u00e9 de la liaison mais la pr\u00e9pond\u00e9rance de la relation affine sur les variations internes des variables. Un coefficient nul n\u2019implique pas l'ind\u00e9pendance, car d\u2019autres types de corr\u00e9lation sont possibles.\nD\u2019autres indicateurs permettent de calculer un coefficient de corr\u00e9lation pour des variables ordinales.\nLe fait que deux variables soient \u00ab fortement corr\u00e9l\u00e9es \u00bb ne d\u00e9montre pas qu'il y ait une relation de causalit\u00e9 entre l'une et l'autre. Le contre-exemple le plus typique est celui o\u00f9 elles sont en fait li\u00e9es par une causalit\u00e9 commune. Cette confusion est connue sous l'expression Cum hoc ergo propter hoc.", "element_cle": "1. La corr\u00e9lation est une notion de liaison entre plusieurs variables al\u00e9atoires ou statistiques.\n2. La corr\u00e9lation est souvent r\u00e9duite \u00e0 la corr\u00e9lation lin\u00e9aire entre variables quantitatives.\n3. Le coefficient de corr\u00e9lation lin\u00e9aire mesure la relation entre deux variables en fonction de leur covariance et de leurs \u00e9carts types.\n4. Le coefficient de corr\u00e9lation n'indique pas l'intensit\u00e9 de la liaison, mais la pr\u00e9pond\u00e9rance de la relation affine.\n5. Il existe d'autres types de corr\u00e9lation, en plus de la corr\u00e9lation lin\u00e9aire.\n6. Les variables fortement corr\u00e9l\u00e9es ne sont pas n\u00e9cessairement causalement li\u00e9es.\n7. La confusion entre corr\u00e9lation et causalit\u00e9 est connue sous l'expression \"Cum hoc ergo propter hoc\".", "rap": "[Couplet 1]\nLa corr\u00e9lation, c'est pas du bluff, c'est du s\u00e9rieux\nUne liaison entre variables, \u00e7a rend curieux\nQue ce soit lin\u00e9aire ou non, y'a de quoi cogiter\nMais faut bien comprendre pour pouvoir en profiter\n\nLa corr\u00e9lation, souvent r\u00e9duite au simple lin\u00e9aire\nEntre des variables quantitatives pour pas se tracasser\nLe coef de corr\u00e9lation, il est l\u00e0 pour mesurer\nLa relation entre deux var', il faut le consid\u00e9rer\n\n[Refrain]\nLa corr\u00e9lation, un lien entre nombres et v\u00e9rit\u00e9\nMais attention, c'est pas l'intensit\u00e9 qu'il faut juger\nD'autres types existent, faut pas les ignorer\nMais la corr\u00e9lation et causalit\u00e9, faut pas les m\u00e9langer\n\n[Couplet 2]\nLa corr\u00e9lation ne dit pas tout, \u00e9coute bien mon gars\nLa liaison peut \u00eatre forte, mais pas forc\u00e9ment causale\nAlors garde \u00e7a en t\u00eate, \u00e9vite les confusions\n\"Cum hoc ergo propter hoc\", oui c'est la raison\n\nLa corr\u00e9lation, une info pr\u00e9cieuse, crois-moi mon pote\nDans le monde des stats, elle vaut de l'or en bourse\nAlors apprends, explore, mets ta curiosit\u00e9 en action\nEt deviens le meilleur en interpr\u00e9tation\n\n[Refrain]\nLa corr\u00e9lation, un lien entre nombres et v\u00e9rit\u00e9\nMais attention, c'est pas l'intensit\u00e9 qu'il faut juger\nD'autres types existent, faut pas les ignorer\nMais la corr\u00e9lation et causalit\u00e9, faut pas les m\u00e9langer"}, {"titre": "M\u00e9thode des moindres carr\u00e9s", "text_origine": "La m\u00e9thode des moindres carr\u00e9s, ind\u00e9pendamment \u00e9labor\u00e9e par Legendre et Gauss au d\u00e9but du XIXe si\u00e8cle, permet de comparer des donn\u00e9es exp\u00e9rimentales, g\u00e9n\u00e9ralement entach\u00e9es d\u2019erreurs de mesure, \u00e0 un mod\u00e8le math\u00e9matique cens\u00e9 d\u00e9crire ces donn\u00e9es.\nCe mod\u00e8le peut prendre diverses formes. Il peut s\u2019agir de lois de conservation que les quantit\u00e9s mesur\u00e9es doivent respecter. La m\u00e9thode des moindres carr\u00e9s permet alors de minimiser l\u2019impact des erreurs exp\u00e9rimentales en \u00ab ajoutant de l\u2019information \u00bb dans le processus de mesure.", "element_cle": "1. La m\u00e9thode des moindres carr\u00e9s a \u00e9t\u00e9 d\u00e9velopp\u00e9e par Legendre et Gauss au d\u00e9but du XIXe si\u00e8cle.\n2. Elle permet de comparer des donn\u00e9es exp\u00e9rimentales \u00e0 un mod\u00e8le math\u00e9matique.\n3. Le mod\u00e8le peut prendre diff\u00e9rentes formes, telles que des lois de conservation.\n4. La m\u00e9thode des moindres carr\u00e9s minimise l'impact des erreurs exp\u00e9rimentales.\n5. Elle \"ajoute de l'information\" dans le processus de mesure.", "rap": "[Couplet 1]\nLa m\u00e9thode des moindres carr\u00e9s, un savoir ancestral\nD\u00e9velopp\u00e9e par Legendre et Gauss au XIXe si\u00e8cle\nComparer les donn\u00e9es, un mod\u00e8le math\u00e9matique en action\nPour explorer les myst\u00e8res, aller plus loin dans la r\u00e9flexion\n\n[Refrain]\nLa m\u00e9thode des moindres carr\u00e9s, un outil magistral\nPour analyser les faits, \u00e9viter les erreurs fatales\nUn pas dans l'\u00e9ducation, une avanc\u00e9e vitale\nCette m\u00e9thode r\u00e9volutionne, c'est essentiel, c'est capital\n\n[Couplet 2]\nDes lois de conservation, diff\u00e9rentes formes possibles\nLe mod\u00e8le s'adapte, tout devient plausible\nUn \u00e9quilibre juste, minimisant les erreurs\nPour des r\u00e9sultats pr\u00e9cis, une m\u00e9thode sans parall\u00e8le\n\n[Refrain]\nLa m\u00e9thode des moindres carr\u00e9s, une le\u00e7on de rigueur\nElle dissipe les doutes, un \u00e9clair dans l'obscur\nDans le processus de mesure, elle ajoute de l'information\nUn pas vers l'excellence, pour une \u00e9ducation en transformation"}, {"titre": "Bootstrap (statistiques)", "text_origine": "En statistiques, les techniques de bootstrap sont des m\u00e9thodes d'inf\u00e9rence statistique bas\u00e9es sur la r\u00e9plication multiple des donn\u00e9es \u00e0 partir du jeu de donn\u00e9es \u00e9tudi\u00e9, selon les techniques de r\u00e9\u00e9chantillonnage. Elles datent de la fin des ann\u00e9es 1970, \u00e9poque o\u00f9 la possibilit\u00e9 de calculs informatiques intensifs devient abordable. On calculait depuis pr\u00e8s d'un si\u00e8cle des estimations : mesures de dispersion (variance, \u00e9cart-type), intervalles de confiance, tables de d\u00e9cision pour des tests d'hypoth\u00e8se, etc., \u00e0 partir des expressions math\u00e9matiques des lois de probabilit\u00e9, ainsi que d'approximations de celles-ci quand le calcul n'\u00e9tait pas r\u00e9alisable. D\u00e9sormais, l'approche par calcul stochastique sur technologie num\u00e9rique permet de multiplier ces \u00e9valuations, et surtout de quantifier la sensibilit\u00e9 de ces \u00e9valuations aux particularit\u00e9s de l'\u00e9chantillon originel, i.e. le jeu de donn\u00e9es \u00e9tudi\u00e9, gr\u00e2ce \u00e0 l'analyse statistique des sous-\u00e9chantillons possibles.\nCette m\u00e9thode est bas\u00e9e sur des simulations stochastiques, comme les m\u00e9thodes de Monte-Carlo, les m\u00e9thodes num\u00e9riques bay\u00e9siennes (\u00e9chantillonneur de Gibbs, l'algorithme de Metropolis-Hastings), \u00e0 la diff\u00e9rence pr\u00e8s que le bootstrap ne n\u00e9cessite pas d'autre information que celle disponible sur les individus de l'\u00e9chantillon originel.\nPlus pr\u00e9cis\u00e9ment, et c'est le sens du terme \u00ab r\u00e9\u00e9chantillonnage \u00bb, un bootstrap consiste \u00e0 cr\u00e9er des \u00ab nouveaux \u00e9chantillons \u00bb statistiques, mais uniquement par tirage avec remise, \u00e0 partir de l'\u00e9chantillon initial. L'aspect autocentr\u00e9 et it\u00e9ratif de la m\u00e9thode a inspir\u00e9 sa d\u00e9signation anglaise : en effet, le bootstrap d\u00e9signe le fait de \u00ab se hisser en tirant sur ses propres lacets ou plus pr\u00e9cis\u00e9ment sur ses \u00ab bootstraps \u00bb qui d\u00e9signent en anglais les anneaux de cuir ou tissu cousus au rebord des bottes pour y passer les doigts afin de les enfiler plus facilement  \u00bb.", "element_cle": "1. Les techniques de bootstrap sont utilis\u00e9es en statistiques pour l'inf\u00e9rence statistique \u00e0 partir d'un jeu de donn\u00e9es.\n2. Le bootstrap a \u00e9t\u00e9 d\u00e9velopp\u00e9 \u00e0 la fin des ann\u00e9es 1970, gr\u00e2ce \u00e0 l'av\u00e8nement des calculs informatiques intensifs.\n3. Avant le bootstrap, les estimations en statistiques \u00e9taient bas\u00e9es sur des expressions math\u00e9matiques des lois de probabilit\u00e9.\n4. Le bootstrap permet de multiplier les \u00e9valuations statistiques et de quantifier la sensibilit\u00e9 des r\u00e9sultats aux particularit\u00e9s des donn\u00e9es.\n5. Le bootstrap utilise des simulations stochastiques et le r\u00e9\u00e9chantillonnage des donn\u00e9es initiales.", "rap": "[Couplet 1]\nLes techniques de Bootstrap, en statistiques,\nL'inf\u00e9rence statistique, c'est leur rideau de fer,\nA partir d'un jeu de donn\u00e9es, ils sont rois,\nPour estimer des param\u00e8tres, c'est leur choix.\n\nLes ann\u00e9es 70, le Bootstrap est arriv\u00e9,\nCalculs informatiques, les maths \u00e9taient lass\u00e9s,\nFinies les expressions, place \u00e0 l'informatique,\nLe Bootstrap est l\u00e0, il r\u00e9volutionne l'esth\u00e9tique.\n\n[Refrain]\nBootstrap, statistiques, nouvelles perspectives,\nMultiplication des \u00e9valuations, sensibilit\u00e9 directive,\nSimulations stochastiques, r\u00e9\u00e9chantillonnage des faits,\nLe Bootstrap ne fait qu'amplifier l'effet.\n\n[Couplet 2]\nAvant lui, les statistiques \u00e9taient dogmatiques,\nLes lois de probabilit\u00e9 \u00e9taient syst\u00e9matiques,\nMais le Bootstrap, lui, est plus pratique,\nIl jongle avec les donn\u00e9es, et les rend plus authentiques.\n\nDes simulations stochastiques, il en fait son affaire,\nPour quantifier la sensibilit\u00e9, il est le grand sorcier,\nLe r\u00e9\u00e9chantillonnage des donn\u00e9es, il en est le ma\u00eetre,\nLe Bootstrap cherche \u00e0 conna\u00eetre, \u00e0 conna\u00eetre et rena\u00eetre.\n\n[Refrain]\nBootstrap, statistiques, nouvelles perspectives,\nMultiplication des \u00e9valuations, sensibilit\u00e9 directive,\nSimulations stochastiques, r\u00e9\u00e9chantillonnage des faits,\nLe Bootstrap ne fait qu'amplifier l'effet."}, {"titre": "Corr\u00e9lation (statistiques)", "text_origine": "En probabilit\u00e9s et en statistique, la corr\u00e9lation entre plusieurs variables al\u00e9atoires ou statistiques est une notion de liaison qui contredit leur ind\u00e9pendance.\nCette corr\u00e9lation est tr\u00e8s souvent r\u00e9duite \u00e0 la corr\u00e9lation lin\u00e9aire entre variables quantitatives, c\u2019est-\u00e0-dire l\u2019ajustement d\u2019une variable par rapport \u00e0 l\u2019autre par une relation affine obtenue par r\u00e9gression lin\u00e9aire. Pour cela, on calcule un coefficient de corr\u00e9lation lin\u00e9aire, quotient de leur covariance par le produit de leurs \u00e9carts types. Son signe indique si des valeurs plus hautes de l\u2019une correspondent \u00ab en moyenne \u00bb \u00e0 des valeurs plus hautes ou plus basses pour l\u2019autre. La valeur absolue du coefficient, toujours comprise entre 0 et 1, ne mesure pas l\u2019intensit\u00e9 de la liaison mais la pr\u00e9pond\u00e9rance de la relation affine sur les variations internes des variables. Un coefficient nul n\u2019implique pas l'ind\u00e9pendance, car d\u2019autres types de corr\u00e9lation sont possibles.\nD\u2019autres indicateurs permettent de calculer un coefficient de corr\u00e9lation pour des variables ordinales.\nLe fait que deux variables soient \u00ab fortement corr\u00e9l\u00e9es \u00bb ne d\u00e9montre pas qu'il y ait une relation de causalit\u00e9 entre l'une et l'autre. Le contre-exemple le plus typique est celui o\u00f9 elles sont en fait li\u00e9es par une causalit\u00e9 commune. Cette confusion est connue sous l'expression Cum hoc ergo propter hoc.", "element_cle": "1. La corr\u00e9lation est une notion de liaison entre plusieurs variables al\u00e9atoires ou statistiques qui contredit leur ind\u00e9pendance.\n2. Elle est souvent r\u00e9duite \u00e0 une corr\u00e9lation lin\u00e9aire entre variables quantitatives, obtenue par r\u00e9gression lin\u00e9aire.\n3. Le coefficient de corr\u00e9lation lin\u00e9aire mesure la relation entre les variables, avec un signe indiquant si des valeurs plus hautes correspondent \u00e0 des valeurs plus hautes ou plus basses pour l'autre.\n4. Sa valeur absolue, toujours entre 0 et 1, mesure la pr\u00e9pond\u00e9rance de la relation affine sur les variations internes des variables.\n5. Un coefficient nul ne signifie pas n\u00e9cessairement une ind\u00e9pendance, car d'autres types de corr\u00e9lation sont possibles.\n6. Des indicateurs permettent de calculer un coefficient de corr\u00e9lation pour des variables ordinales.\n7. Une forte corr\u00e9lation ne d\u00e9montre pas une relation de causalit\u00e9 entre les variables.\n8. Une causalit\u00e9 commune peut \u00eatre la raison de la corr\u00e9lation, comme dans le ph\u00e9nom\u00e8ne Cum hoc ergo propter hoc.", "rap": "[Couplet 1]\nLa corr\u00e9lation, un lien qui d\u00e9range,\nEntre variables, statistiques qui se m\u00e9langent,\nOn r\u00e9duit souvent \u00e0 du lin\u00e9aire,\nMais y'a plus \u00e0 voir, faut \u00eatre clair.\n\nLe coef de corr\u00e9lation, un indicateur,\nQui mesure la relation entre acteurs,\nSigne positif ou n\u00e9gatif, on garde l'suspect,\nSi la valeur est haute ou basse, faut qu'tu t'respectes.\n\n[Refrain]\nCorr\u00e9lation, \u00e9ducation,\nDes chiffres qui donnent des le\u00e7ons,\nMais pas de preuve de causation,\nFaut garder les nuances en station.\n\n[Couplet 2]\nZ\u00e9ro n'implique pas n\u00e9cessairement,\nUne ind\u00e9pendance, faut l'comprendre,\nD'autres formes de corr\u00e9lation existent,\nOrdinales, elles aussi persistent.\n\nAttention, faut pas s'm\u00e9prendre,\nLa corr\u00e9lation n'implique pas qu'tu dois suivre,\nUne forte liaison entre deux variables,\nCausation commune, le vrai signal.\n\n[Refrain]\nCorr\u00e9lation, \u00e9ducation,\nDes chiffres qui donnent des le\u00e7ons,\nMais pas de preuve de causation,\nFaut garder les nuances en station."}, {"titre": "Corr\u00e9lation (statistiques)", "text_origine": "En probabilit\u00e9s et en statistique, la corr\u00e9lation entre plusieurs variables al\u00e9atoires ou statistiques est une notion de liaison qui contredit leur ind\u00e9pendance.\nCette corr\u00e9lation est tr\u00e8s souvent r\u00e9duite \u00e0 la corr\u00e9lation lin\u00e9aire entre variables quantitatives, c\u2019est-\u00e0-dire l\u2019ajustement d\u2019une variable par rapport \u00e0 l\u2019autre par une relation affine obtenue par r\u00e9gression lin\u00e9aire. Pour cela, on calcule un coefficient de corr\u00e9lation lin\u00e9aire, quotient de leur covariance par le produit de leurs \u00e9carts types. Son signe indique si des valeurs plus hautes de l\u2019une correspondent \u00ab en moyenne \u00bb \u00e0 des valeurs plus hautes ou plus basses pour l\u2019autre. La valeur absolue du coefficient, toujours comprise entre 0 et 1, ne mesure pas l\u2019intensit\u00e9 de la liaison mais la pr\u00e9pond\u00e9rance de la relation affine sur les variations internes des variables. Un coefficient nul n\u2019implique pas l'ind\u00e9pendance, car d\u2019autres types de corr\u00e9lation sont possibles.\nD\u2019autres indicateurs permettent de calculer un coefficient de corr\u00e9lation pour des variables ordinales.\nLe fait que deux variables soient \u00ab fortement corr\u00e9l\u00e9es \u00bb ne d\u00e9montre pas qu'il y ait une relation de causalit\u00e9 entre l'une et l'autre. Le contre-exemple le plus typique est celui o\u00f9 elles sont en fait li\u00e9es par une causalit\u00e9 commune. Cette confusion est connue sous l'expression Cum hoc ergo propter hoc.", "element_cle": "- La corr\u00e9lation est une notion de liaison entre plusieurs variables al\u00e9atoires ou statistiques.\n- La corr\u00e9lation est souvent r\u00e9duite \u00e0 la corr\u00e9lation lin\u00e9aire entre variables quantitatives.\n- Le coefficient de corr\u00e9lation lin\u00e9aire mesure le degr\u00e9 de corr\u00e9lation entre deux variables.\n- Un coefficient nul ne signifie pas n\u00e9cessairement une ind\u00e9pendance entre les variables.\n- D'autres indicateurs permettent de calculer la corr\u00e9lation pour des variables ordinales.\n- Une forte corr\u00e9lation ne prouve pas une relation de causalit\u00e9.\n- La confusion entre corr\u00e9lation et causalit\u00e9 est connue sous le nom de 'Cum hoc ergo propter hoc'.", "rap": "[Couplet 1]\nLa corr\u00e9lation, une liaison math\u00e9matique,\nEntre variables, une notion statistique,\nOn la r\u00e9duit souvent \u00e0 la lin\u00e9arit\u00e9,\nEntre quantit\u00e9s, faut pas se laisser berner.\n\nLe coefficient de corr\u00e9lation lin\u00e9aire,\nMesure le degr\u00e9 d'une relation \u00e9clair,\nEntre deux variables, \u00e7a va de z\u00e9ro \u00e0 un,\nMais \u00e7a ne signifie pas forc\u00e9ment rien.\n\n[Refrain]\nCorr\u00e9lation, calcul math\u00e9matique,\nEntre variables, pas seulement quantitatives,\nMais faut faire attention, ne pas se tromper,\nEntre corr\u00e9lation et causalit\u00e9.\n\n[Couplet 2]\nDes indicateurs, y'en a pour tous les go\u00fbts,\nPour calculer la corr\u00e9lation, y'a pas de tabou,\nPour des variables ordinales, on a des m\u00e9thodes,\nLa corr\u00e9lation, on en est tous t\u00e9moins.\n\nMais attention, faut pas confondre avec,\nUne relation de cause et d'effet,\nUne forte corr\u00e9lation ne prouve pas forc\u00e9ment,\nUne cause \u00e0 effet, c'est important de comprendre.\n\n[Refrain]\nCorr\u00e9lation, calcul math\u00e9matique,\nEntre variables, pas seulement quantitatives,\nMais faut faire attention, ne pas se tromper,\nEntre corr\u00e9lation et causalit\u00e9.\n\n[Couplet 1]\nCorrelation, a mathematical link,\nAmongst variables, a statistical trick,\nOften reduced to linear connection,\nBetween quantities, don't fall for deception.\n\nThe linear correlation coefficient,\nMeasures the degree of a relationship fit,\nBetween two variables, goes from zero to one,\nBut that doesn't necessarily mean it's done.\n\n[Refrain]\nCorrelation, a mathematical feat,\nAmongst variables, not just those that repeat,\nBut be careful, don't mistake the track,\nBetween correlation and causality's stack.\n\n[Couplet 2]\nIndicators, we've got plenty in range,\nTo calculate correlation, no rules estranged,\nFor ordinal variables, methods to choose,\nCorrelation, we all witness its hues.\n\nBut beware, don't mix it up with the rest,\nA cause and effect, correlation's not the best,\nA strong correlation doesn't always imply,\nCause and effect, important to comply.\n\n[Refrain]\nCorrelation, a mathematical feat,\nAmongst variables, not just those that repeat,\nBut be careful, don't mistake the track,\nBetween correlation and causality's stack."}, {"titre": "Corr\u00e9lation crois\u00e9e", "text_origine": "La corr\u00e9lation crois\u00e9e est parfois utilis\u00e9e en statistique pour d\u00e9signer la covariance des vecteurs al\u00e9atoires X et Y, afin de distinguer ce concept de la \u00ab covariance \u00bb d'un vecteur al\u00e9atoire, laquelle est comprise comme \u00e9tant la matrice de covariance des coordonn\u00e9es du vecteur.\nEn traitement du signal, la corr\u00e9lation crois\u00e9e (aussi appel\u00e9e covariance crois\u00e9e) est la mesure de la similitude entre deux signaux.\nOn utilise le terme de covariance crois\u00e9e entre deux signaux A et B dans le cas de la d\u00e9finition statistique :\n\n  \n    \n      \n        \n          \u0393\n          \n            A\n            B\n          \n        \n        (\n        \u03c4\n        )\n        =\n        \n          E\n        \n        \n          (\n          \n            A\n            (\n            t\n            )\n            B\n            (\n            t\n            \u2212\n            \u03c4\n            )\n          \n          )\n        \n        ,\n        \n      \n    \n    {\\displaystyle \\Gamma _{AB}(\\tau )=\\mathbb {E} \\left(A(t)B(t-\\tau )\\right),\\,}\n  et le terme de corr\u00e9lation crois\u00e9e (ou intercorr\u00e9lation) dans le cas d'une d\u00e9finition temporelle :\n\n  \n    \n      \n        \n          \u0393\n          \n            A\n            B\n          \n        \n        (\n        \u03c4\n        )\n        =\n        A\n        \u2217\n        \n          B\n          \n            \u2217\n          \n        \n        (\n        \u2212\n        )\n        =\n        \u222b\n        A\n        (\n        t\n        )\n        \n          B\n          \n            \u2217\n          \n        \n        (\n        t\n        \u2212\n        \u03c4\n        )\n        \n        d\n        t\n        .\n      \n    \n    {\\displaystyle \\Gamma _{AB}(\\tau )=A\\ast B^{*}(-)=\\int A(t)B^{*}(t-\\tau )\\,dt.}\n  Les deux concepts sont \u00e9quivalents si les signaux sont ergodiques \u00e0 l'ordre deux.\nLa transform\u00e9e de Fourier de la corr\u00e9lation crois\u00e9e est la densit\u00e9 spectrale d'interaction :\n\n  \n    \n      \n        \n          \u03b3\n          \n            A\n            B\n          \n        \n        =\n        \n          \n            F\n          \n        \n        [\n        \n          \u0393\n          \n            A\n            B\n          \n        \n        ]\n        (\n        \u03c4\n        )\n        =\n        \n          \n            F\n          \n        \n        [\n        A\n        ]\n        \u22c5\n        \n          \n            F\n          \n        \n        [\n        \n          B\n          \n            \u2217\n          \n        \n        (\n        \u2212\n        )\n        ]\n        =\n        a\n        (\n        \u03bd\n        )\n        \u22c5\n        \n          b\n          \n            \u2217\n          \n        \n        (\n        \u03bd\n        )\n      \n    \n    {\\displaystyle \\gamma _{AB}={\\mathcal {F}}[\\Gamma _{AB}](\\tau )={\\mathcal {F}}[A]\\cdot {\\mathcal {F}}[B^{*}(-)]=a(\\nu )\\cdot b^{*}(\\nu )}\n  .\nOn remarquera que le produit de convolution \u00e9quivaut \u00e0 la corr\u00e9lation crois\u00e9e de A(t) et B*(-t).", "element_cle": "1. La corr\u00e9lation crois\u00e9e est utilis\u00e9e en statistique pour mesurer la covariance entre deux vecteurs al\u00e9atoires, X et Y.\n2. En traitement du signal, la corr\u00e9lation crois\u00e9e est utilis\u00e9e pour mesurer la similitude entre deux signaux.\n3. La corr\u00e9lation crois\u00e9e est calcul\u00e9e \u00e0 l'aide de la covariance entre les signaux A et B.\n4. La corr\u00e9lation crois\u00e9e peut \u00eatre d\u00e9finie statistiquement ou temporellement.\n5. Les concepts de covariance crois\u00e9e et de corr\u00e9lation crois\u00e9e sont \u00e9quivalents si les signaux sont ergodiques \u00e0 l'ordre deux.\n6. La transform\u00e9e de Fourier de la corr\u00e9lation crois\u00e9e est la densit\u00e9 spectrale d'interaction.", "rap": "[Couplet 1]\nLa corr\u00e9lation crois\u00e9e, un concept puissant\nEn statistique, elle mesure l'impact\nEntre deux vecteurs al\u00e9atoires, X et Y\nOn calcule leur covariance pour y voir clair\n\nEn traitement du signal, elle se r\u00e9v\u00e8le\nPour mesurer la similitude entre deux signaux rebelles\nLa corr\u00e9lation crois\u00e9e, un outil bien pr\u00e9cieux\nEntre les signaux A et B, on fait des heureux\n\n[Refrain]\nLa corr\u00e9lation crois\u00e9e, un lien entre deux mondes\nElle nous \u00e9claire, elle nous inonde\nEntre statistique et traitement du signal\nElle fait briller nos esprits, elle nous \u00e9merveille\n\n[Couplet 2]\nStatistiquement ou temporellement d\u00e9finie\nLa corr\u00e9lation crois\u00e9e, elle nous lie\nElle nous d\u00e9voile les liens entre les donn\u00e9es\nElle nous guide vers l'\u00e9ducation bien men\u00e9e\n\nCovariance crois\u00e9e, corr\u00e9lation crois\u00e9e\nDes termes \u00e9quivalents pour des signaux ergodiques \u00e0 l'ordre deux\nOn explore les myst\u00e8res de ces corr\u00e9lations\nPour comprendre et avancer dans toutes les directions\n\n[Refrain]\nLa corr\u00e9lation crois\u00e9e, un lien entre deux mondes\nElle nous \u00e9claire, elle nous inonde\nEntre statistique et traitement du signal\nElle fait briller nos esprits, elle nous \u00e9merveille\n\n[Couplet 1]\nLa transform\u00e9e de Fourier de la corr\u00e9lation crois\u00e9e\nC'est la densit\u00e9 spectrale d'interaction \u00e9voqu\u00e9e\nUn pont entre les domaines, une voie d'exploration\nPour comprendre l'interaction entre signaux en action\n\nLa corr\u00e9lation crois\u00e9e, un outil de connaissances\nPour comprendre notre monde dans ses nuances\nElle nous guide vers des dates cl\u00e9s\nDes \u00e9v\u00e9nements marquants pour avancer \u00e9clair\u00e9s\n\n[Refrain]\nLa corr\u00e9lation crois\u00e9e, un lien entre deux mondes\nElle nous \u00e9claire, elle nous inonde\nEntre statistique et traitement du signal\nElle fait briller nos esprits, elle nous \u00e9merveille"}, {"titre": "Corr\u00e9lation de Spearman", "text_origine": "En statistique, la corr\u00e9lation de Spearman ou rho de Spearman, nomm\u00e9e d'apr\u00e8s Charles Spearman (1863-1945) et souvent not\u00e9e par la lettre grecque \n  \n    \n      \n        \u03c1\n      \n    \n    {\\displaystyle \\rho }\n   (rho) ou \n  \n    \n      \n        \n          r\n          \n            s\n          \n        \n      \n    \n    {\\displaystyle r_{s}}\n   est une mesure de d\u00e9pendance statistique non param\u00e9trique entre deux variables.\nLa corr\u00e9lation de Spearman est \u00e9tudi\u00e9e lorsque deux variables statistiques semblent corr\u00e9l\u00e9es sans que la relation entre les deux variables soit de type affine. Elle consiste \u00e0 trouver un coefficient de corr\u00e9lation, non pas entre les valeurs prises par les deux variables mais entre les rangs de ces valeurs. Elle estime \u00e0 quel point la relation entre deux variables peut \u00eatre d\u00e9crite par une fonction monotone. S'il n'y a pas de donn\u00e9es r\u00e9p\u00e9t\u00e9es, une corr\u00e9lation de Spearman parfaite de +1 ou -1 est obtenue quand l'une des variables est une fonction monotone parfaite de l'autre.", "element_cle": "1. La corr\u00e9lation de Spearman est une mesure de d\u00e9pendance statistique non param\u00e9trique entre deux variables.\n2. Elle est \u00e9tudi\u00e9e lorsque deux variables semblent corr\u00e9l\u00e9es sans que la relation entre les deux soit de type affine.\n3. La corr\u00e9lation de Spearman consiste \u00e0 trouver un coefficient de corr\u00e9lation entre les rangs des valeurs des variables.\n4. Elle estime \u00e0 quel point la relation entre deux variables peut \u00eatre d\u00e9crite par une fonction monotone.\n5. Une corr\u00e9lation de Spearman parfaite de +1 ou -1 est obtenue lorsque l'une des variables est une fonction monotone parfaite de l'autre.", "rap": "[Couplet 1]\nCorr\u00e9lation de Spearman, une analyse statistique\nPour mesurer la d\u00e9pendance entre deux variables, c'est magique\nQuand la relation n'est pas affine, pas de panique\nCette m\u00e9thode met en avant les rangs des valeurs, c'est pas comique\n\n[Couplet 2]\nSi les valeurs se suivent de fa\u00e7on monotone\nLa corr\u00e9lation de Spearman dit \"Yo, c'est bon\"\nUn coefficient de corr\u00e9lation proche de +1 ou -1\nSignifie que c'est une fonction monotone, \u00e7a c'est malin\n\n[Refrain]\nLa corr\u00e9lation de Spearman, un outil puissant\nPour analyser les donn\u00e9es, c'est fascinant\nElle nous montre comment deux variables sont li\u00e9es\nEt nous aide \u00e0 comprendre les ph\u00e9nom\u00e8nes \u00e9tudi\u00e9s"}, {"titre": "Corr\u00e9lation partielle", "text_origine": "Le coefficient de corr\u00e9lation partielle, not\u00e9 ici \n  \n    \n      \n        \n          r\n          \n            A\n            B\n            .\n            C\n          \n        \n      \n    \n    {\\displaystyle r_{AB.C}}\n  , permet de conna\u00eetre la valeur de la corr\u00e9lation entre deux variables A et B, si la variable C \u00e9tait demeur\u00e9e constante pour la s\u00e9rie d\u2019observations consid\u00e9r\u00e9es. \nDit autrement, le coefficient de corr\u00e9lation partielle \n  \n    \n      \n        \n          r\n          \n            A\n            B\n            .\n            C\n          \n        \n      \n    \n    {\\displaystyle r_{AB.C}}\n   est le coefficient de corr\u00e9lation totale entre les variables A et B quand on leur a retir\u00e9 leur meilleure explication lin\u00e9aire en termes de C. Il est donn\u00e9 par la formule :\n\n  \n    \n      \n        \n          r\n          \n            A\n            B\n            .\n            C\n          \n        \n        =\n        \n          \n            \n              \n                \n                  r\n                  \n                    A\n                    B\n                  \n                \n                \u2212\n                \n                  r\n                  \n                    A\n                    C\n                  \n                \n                \u22c5\n                \n                  r\n                  \n                    B\n                    C\n                  \n                \n              \n              \n                \n                  \n                    1\n                    \u2212\n                    \n                      r\n                      \n                        A\n                        C\n                      \n                      \n                        2\n                      \n                    \n                  \n                \n                \u22c5\n                \n                  \n                    1\n                    \u2212\n                    \n                      r\n                      \n                        B\n                        C\n                      \n                      \n                        2\n                      \n                    \n                  \n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle r_{AB.C}={\\dfrac {r_{AB}-r_{AC}\\cdot r_{BC}}{{\\sqrt {1-r_{AC}^{2}}}\\cdot {\\sqrt {1-r_{BC}^{2}}}}}}", "element_cle": "Voici la liste d'\u00e9l\u00e9ments cl\u00e9s :\n\n1. Le coefficient de corr\u00e9lation partielle permet de mesurer la relation entre deux variables A et B, en tenant compte de la variable C.\n2. Le coefficient de corr\u00e9lation partielle repr\u00e9sente la corr\u00e9lation entre A et B, en supposant que C reste constant.\n3. Il s'agit du coefficient de corr\u00e9lation totale entre A et B, apr\u00e8s avoir retir\u00e9 la meilleure explication lin\u00e9aire en termes de C.\n4. La formule du coefficient de corr\u00e9lation partielle est donn\u00e9e par : r(A,B.C) = (r(A,B) - r(A,C) * r(B,C)) / (1 - r(A,C)^2) * (1 - r(B,C)^2).\n5. La corr\u00e9lation partielle permet de prendre en compte l'effet de la variable C sur la relation entre A et B.", "rap": "[Couplet 1]\nJ'mets ma plume en action, faisant des connexions\nJ'te parle de corr\u00e9lation, avec pr\u00e9cision\nLe coefficient de corr\u00e9lation partielle, ma cible\nPour mesurer la relation entre deux variables, c'est pas difficile\n\n[Ah ouais]\nOn parle de r(A,B.C), repr\u00e9sente la corr\u00e9lation\nEntre A et B, en maintenant C constant\nOn retire l'explication lin\u00e9aire de C, comprends tu ?\nC'est l'coefficient de corr\u00e9lation totale, rien d'perdu\n\n[Refrain]\nCorr\u00e9lation partielle, prends en compte les facteurs\nEffet de la variable C, pertinence et rigueur\nCorr\u00e9lation partielle, dans les calculs c'est cl\u00e9\nOn d\u00e9chiffre les relations, on s'envole vers le sommet\n\n[Couplet 2]\nLa formule est simple, \u00e9coute bien mon poto\nr(A,B.C) \u00e9gal r(A,B) moins r(A,C) multipli\u00e9 r(B,C)\nLe tout divis\u00e9 par 1 moins r(A,C) au carr\u00e9\nFaut pas oublier, c'est pas compliqu\u00e9\n\n[Oh yeah]\n1 moins r(B,C) au carr\u00e9, on oublie pas non plus\nC'est la formule, pour le coefficient de corr\u00e9lation partielle\nOn prend en compte l'effet de C, sur A et B\nAvec rigueur et pr\u00e9cision, on met tout en lumi\u00e8re\n\n[Refrain]\nCorr\u00e9lation partielle, prends en compte les facteurs\nEffet de la variable C, pertinence et rigueur\nCorr\u00e9lation partielle, dans les calculs c'est cl\u00e9\nOn d\u00e9chiffre les relations, on s'envole vers le sommet"}, {"titre": "R\u00e9gression lin\u00e9aire", "text_origine": "En statistiques, en \u00e9conom\u00e9trie et en apprentissage automatique, un mod\u00e8le de r\u00e9gression lin\u00e9aire est un mod\u00e8le de r\u00e9gression qui cherche \u00e0 \u00e9tablir une relation lin\u00e9aire entre une variable, dite expliqu\u00e9e, et une ou plusieurs variables, dites explicatives.\nOn parle aussi de mod\u00e8le lin\u00e9aire ou de mod\u00e8le de r\u00e9gression lin\u00e9aire.\nParmi les mod\u00e8les de r\u00e9gression lin\u00e9aire, le plus simple est l'ajustement affine. Celui-ci consiste \u00e0 rechercher la droite permettant d'expliquer le comportement d'une variable statistique y comme \u00e9tant une fonction affine d'une autre variable statistique x.\nEn g\u00e9n\u00e9ral, le mod\u00e8le de r\u00e9gression lin\u00e9aire d\u00e9signe un mod\u00e8le dans lequel l'esp\u00e9rance conditionnelle de y connaissant x est une fonction affine des param\u00e8tres. Cependant, on peut aussi consid\u00e9rer des mod\u00e8les dans lesquels c'est la m\u00e9diane conditionnelle de y connaissant x ou n'importe quel quantile de la distribution de y connaissant x qui est une fonction affine des param\u00e8tres.\nLe mod\u00e8le de r\u00e9gression lin\u00e9aire est souvent estim\u00e9 par la m\u00e9thode des moindres carr\u00e9s mais il existe aussi de nombreuses autres m\u00e9thodes pour estimer ce mod\u00e8le. On peut par exemple estimer le mod\u00e8le par maximum de vraisemblance ou encore par inf\u00e9rence bay\u00e9sienne.\nBien qu'ils soient souvent pr\u00e9sent\u00e9s ensemble, le mod\u00e8le lin\u00e9aire et la m\u00e9thode des moindres carr\u00e9s ne d\u00e9signent pas la m\u00eame chose. Le mod\u00e8le lin\u00e9aire d\u00e9signe une classe de mod\u00e8les qui peuvent \u00eatre estim\u00e9s par un grand nombre de m\u00e9thodes, et la m\u00e9thode des moindres carr\u00e9s d\u00e9signe une m\u00e9thode d'estimation. Elle peut \u00eatre utilis\u00e9e pour estimer diff\u00e9rents types de mod\u00e8les.", "element_cle": "1. Le mod\u00e8le de r\u00e9gression lin\u00e9aire cherche \u00e0 \u00e9tablir une relation lin\u00e9aire entre des variables expliqu\u00e9es et explicatives.\n2. L'ajustement affine est le mod\u00e8le de r\u00e9gression lin\u00e9aire le plus simple.\n3. Le mod\u00e8le de r\u00e9gression lin\u00e9aire peut \u00eatre estim\u00e9 par la m\u00e9thode des moindres carr\u00e9s.\n4. Il existe d'autres m\u00e9thodes d'estimation pour le mod\u00e8le de r\u00e9gression lin\u00e9aire, comme le maximum de vraisemblance ou l'inf\u00e9rence bay\u00e9sienne.\n5. Le mod\u00e8le lin\u00e9aire et la m\u00e9thode des moindres carr\u00e9s ne sont pas la m\u00eame chose, le premier \u00e9tant une classe de mod\u00e8les et la seconde une m\u00e9thode d'estimation.", "rap": "[Couplet 1]\nR\u00e9gression lin\u00e9aire, une m\u00e9thode explicative\nPour analyser les variables, trouver la bonne alternative\nLe mod\u00e8le affine, le plus basique et simplifi\u00e9\nPour comprendre les donn\u00e9es, faut pas \u00eatre rebut\u00e9\n\nLe mod\u00e8le des moindres carr\u00e9s, on l'utilise souvent\nPour estimer les valeurs, on fait pas semblant\nMais il existe d'autres m\u00e9thodes, des options vari\u00e9es\nMaximum de vraisemblance, inf\u00e9rence bay\u00e9sienne, tout est \u00e9tudi\u00e9\n\n[Refrain]\nR\u00e9gression lin\u00e9aire, dans l'\u00e9ducation c'est essentiel\nAnalyser les variables, trouver la relation r\u00e9elle\nLe mod\u00e8le affine, la base de tout apprentissage\nEstimer les valeurs, un v\u00e9ritable avantage\n\n[Couplet 2]\nAttention \u00e0 ne pas confondre, mod\u00e8le et m\u00e9thode d'estimation\nLe mod\u00e8le lin\u00e9aire, une classe pour toutes les situations\nLes moindres carr\u00e9s, une approche bien sp\u00e9cifique\nPour trouver la droite d'ajustement, la plus caract\u00e9ristique\n\nOn avance pas \u00e0 pas, dans l'analyse des donn\u00e9es\nLe rap de la r\u00e9gression, c'est notre sp\u00e9cialit\u00e9\nOn met en \u00e9vidence, les notions \u00e9ducatives\nDates et \u00e9v\u00e9nements marquants, on reste toujours cr\u00e9atifs\n\n[Refrain]\nR\u00e9gression lin\u00e9aire, dans l'\u00e9ducation c'est essentiel\nAnalyser les variables, trouver la relation r\u00e9elle\nLe mod\u00e8le affine, la base de tout apprentissage\nEstimer les valeurs, un v\u00e9ritable avantage"}, {"titre": "Th\u00e9or\u00e8me central limite", "text_origine": "Le th\u00e9or\u00e8me central limite (aussi appel\u00e9 th\u00e9or\u00e8me limite central, th\u00e9or\u00e8me de la limite centrale ou th\u00e9or\u00e8me de la limite centr\u00e9e) \u00e9tablit la convergence en loi de la somme d'une suite de variables al\u00e9atoires vers la loi normale. Intuitivement, ce r\u00e9sultat affirme qu'une somme de variables al\u00e9atoires ind\u00e9pendantes et identiquement distribu\u00e9es tend (le plus souvent) vers une variable al\u00e9atoire gaussienne.\nCe th\u00e9or\u00e8me et ses g\u00e9n\u00e9ralisations offrent une explication de l'omnipr\u00e9sence de la loi normale dans la nature : de nombreux ph\u00e9nom\u00e8nes sont dus \u00e0 l'addition d'un grand nombre de petites perturbations al\u00e9atoires.", "element_cle": "1. Le th\u00e9or\u00e8me central limite \u00e9tablit la convergence en loi de la somme d'une suite de variables al\u00e9atoires vers la loi normale.\n2. Ce th\u00e9or\u00e8me affirme qu'une somme de variables al\u00e9atoires ind\u00e9pendantes et identiquement distribu\u00e9es tend vers une variable al\u00e9atoire gaussienne.\n3. Les g\u00e9n\u00e9ralisations de ce th\u00e9or\u00e8me expliquent l'omnipr\u00e9sence de la loi normale dans la nature.\n4. De nombreux ph\u00e9nom\u00e8nes sont dus \u00e0 l'addition d'un grand nombre de petites perturbations al\u00e9atoires.\n5. Le th\u00e9or\u00e8me de la limite centrale a des applications importantes dans de nombreux domaines, tels que la statistique et l'\u00e9conom\u00e9trie.", "rap": "[Couplet 1]\nLe th\u00e9or\u00e8me central limite, c'est la base\nLa convergence en loi, le monde s'embrase\nDes variables al\u00e9atoires, qui se rassemblent\nVers une loi normale, o\u00f9 les rimes se ressemblent\n\nCe th\u00e9or\u00e8me, c'est une v\u00e9rit\u00e9 universelle\nDes variables ind\u00e9pendantes, c'est essentiel\nIdentiquement distribu\u00e9es, c'est la cl\u00e9\nUne somme qui tend, vers une gaussienne bien r\u00e9gl\u00e9e\n\n[Refrain]\nLe th\u00e9or\u00e8me central limite, c'est scientifique\nIl explique l'omnipr\u00e9sence de la loi normale caract\u00e9ristique\nDans la nature, c'est le ph\u00e9nom\u00e8ne essentiel\nLes petites perturbations qui s'additionnent pour le r\u00e9el\n\n[Couplet 2]\nDe petits al\u00e9as qui s'accumulent\nLes lois normales, partout on les voit pulluler\nDans la nature, c'est une r\u00e9alit\u00e9\nLes statistiques et l'\u00e9conom\u00e9trie s'en sont inspir\u00e9es\n\nLe th\u00e9or\u00e8me de la limite centrale, puissant outil\nIl trouve des applications dans de nombreux domaines subtils\nLes dates, les \u00e9v\u00e9nements marquants s'expliquent\nGr\u00e2ce \u00e0 ce th\u00e9or\u00e8me, l'\u00e9ducation se r\u00e9plique\n\n[Refrain]\nLe th\u00e9or\u00e8me central limite, c'est scientifique\nIl explique l'omnipr\u00e9sence de la loi normale caract\u00e9ristique\nDans la nature, c'est le ph\u00e9nom\u00e8ne essentiel\nLes petites perturbations qui s'additionnent pour le r\u00e9el"}, {"titre": "Intervalle de confiance", "text_origine": "En math\u00e9matiques, plus pr\u00e9cis\u00e9ment en th\u00e9orie des probabilit\u00e9s et en statistiques, un intervalle de confiance est un intervalle cens\u00e9 contenir un param\u00e8tre inconnu que l'on cherche \u00e0 estimer (typiquement, une moyenne, la m\u00e9diane ou la variance). Sa d\u00e9finition est subtile et souvent mal comprise. Un intervalle de confiance est construit par une m\u00e9thode \u00e0 partir de donn\u00e9es. L'intervalle construit peut contenir la valeur du param\u00e8tre inconnu ou pas. On lui accorde un niveau de confiance souvent exprim\u00e9 sous la forme d'un pourcentage : le plus commun est le niveau \u00e0 95%. Cela signifie que la m\u00e9thode a 95% de chances de produire un intervalle contenant la vraie valeur du param\u00e8tre inconnu.\nMath\u00e9matiquement, un intervalle de confiance est al\u00e9atoire, puisque les donn\u00e9es le sont. En effet, les donn\u00e9es r\u00e9sultent souvent d'une s\u00e9rie de mesures ind\u00e9pendantes sur une population. La figure de droite montre un ph\u00e9nom\u00e8ne qui suit une loi normale (une loi dite en cloche) de moyenne \u03bc inconnue \u00e0 estimer. Les donn\u00e9es sont les \u00e9chantillons tir\u00e9s al\u00e9atoirement. On applique la m\u00e9thode 20 fois. L'intervalle produit contient des fois \u03bc et des fois il ne le contient pas. Ici, la m\u00e9thode a un niveau de confiance de 50% donc l'intervalle produit contient \u03bc dans environ la moiti\u00e9 des cas.\nEn particulier, cette notion permet de d\u00e9finir une marge d'erreur entre les r\u00e9sultats d'un sondage et un relev\u00e9 exhaustif de la population totale. Pour obtenir un intervalle plus r\u00e9duit, donc plus pr\u00e9cis, sans changer le nombre de sond\u00e9s, il faut accepter un niveau plus faible, donc un plus grand risque de se tromper. Au contraire, pour r\u00e9duire le risque d\u2019erreur, on peut \u00e9largir l\u2019intervalle.\nAttention, la notion d'intervalle de confiance ne doit pas \u00eatre confondu avec l'intervalle de fluctuation. Ce dernier est d\u00e9termin\u00e9 par le param\u00e8tre et encadre une variable al\u00e9atoire. Mais c\u2019est pr\u00e9cis\u00e9ment en renversant les in\u00e9galit\u00e9s d\u2019un intervalle de fluctuation, issu du th\u00e9or\u00e8me central limite ou de l\u2019in\u00e9galit\u00e9 de Bienaym\u00e9-Tchebychev, que l\u2019on peut obtenir l\u2019expression d\u2019un intervalle de confiance, comme celui qui estime l\u2019esp\u00e9rance d\u2019une loi \u00e0 partir de la moyenne empirique et d\u2019une majoration de l\u2019\u00e9cart type.", "element_cle": "- Un intervalle de confiance est utilis\u00e9 en math\u00e9matiques, en particulier en th\u00e9orie des probabilit\u00e9s et en statistiques, pour estimer un param\u00e8tre inconnu.\n- Il est obtenu \u00e0 partir de donn\u00e9es et peut ou non contenir la valeur du param\u00e8tre inconnu.\n- Le niveau de confiance est g\u00e9n\u00e9ralement exprim\u00e9 en pourcentage, le plus courant \u00e9tant de 95%.\n- Un intervalle de confiance est al\u00e9atoire car il d\u00e9pend des donn\u00e9es, qui sont elles-m\u00eames al\u00e9atoires.\n- Il permet de d\u00e9finir une marge d'erreur dans les r\u00e9sultats d'un sondage ou d'un relev\u00e9 de population.\n- Pour obtenir un intervalle plus pr\u00e9cis, il faut accepter un niveau de confiance plus faible, ce qui augmente le risque d'erreur.\n- Il ne doit pas \u00eatre confondu avec l'intervalle de fluctuation, qui encadre une variable al\u00e9atoire.", "rap": "[Couplet 1]\nIntervalle de confiance, en math\u00e9matiques \u00e7a fuse,\nEstimer un param\u00e8tre avec des valeurs confuses,\nEn probabilit\u00e9s, en statistiques, c'est la base,\nPour avoir une id\u00e9e, un chiffre qui d\u00e9chasse.\n\nUn pourcentage, souvent 95% en \u00e9vidence,\nLe niveau de confiance, une garantie, une pr\u00e9s\u00e9ance,\nMais attention, c'est al\u00e9atoire, \u00e7a d\u00e9pend des donn\u00e9es,\nQui elles-m\u00eames sont incertaines, c'est la r\u00e9alit\u00e9.\n\n[Refrain]\nIntervalle de confiance, calcul math\u00e9matique,\nPour estimer l'inconnu, une m\u00e9thode pratique,\nUne marge d'erreur dans les r\u00e9sultats,\nMais faut accepter, un risque d'erreur en face.\n\n[Couplet 2]\nDans les sondages, les relev\u00e9s de popu,\nL'intervalle de confiance est l\u00e0 pour qu'on s'en souvienne,\nUne marge d'erreur, mais la pr\u00e9cision a son prix,\nUn niveau de confiance plus faible, plus de risques.\n\nFluctuation n'est pas la m\u00eame chose \u00e0 retenir,\nC'est une autre id\u00e9e, une autre fa\u00e7on d'\u00e9largir,\nL'intervalle encaisse les variables al\u00e9atoires,\nMais c'est bien l'estimation qui est notre histoire.\n\n[Refrain]\nIntervalle de confiance, calcul math\u00e9matique,\nPour estimer l'inconnu, une m\u00e9thode pratique,\nUne marge d'erreur dans les r\u00e9sultats,\nMais faut accepter, un risque d'erreur en face."}, {"titre": "R\u00e9gression logistique", "text_origine": "En statistiques, la r\u00e9gression logistique ou mod\u00e8le logit est un mod\u00e8le de r\u00e9gression binomiale. Comme pour tous les mod\u00e8les de r\u00e9gression binomiale, il s'agit d'expliquer au mieux une variable binaire (la pr\u00e9sence ou l'absence d'une caract\u00e9ristique donn\u00e9e) par des observations r\u00e9elles nombreuses, gr\u00e2ce \u00e0 un mod\u00e8le math\u00e9matique. En d'autres termes d'associer une variable al\u00e9atoire de Bernoulli (g\u00e9n\u00e9riquement not\u00e9e \n  \n    \n      \n        y\n      \n    \n    {\\displaystyle y}\n  ) \u00e0 un vecteur de variables al\u00e9atoires \n  \n    \n      \n        (\n        \n          x\n          \n            1\n          \n        \n        ,\n        \u2026\n        ,\n        \n          x\n          \n            K\n          \n        \n        )\n      \n    \n    {\\displaystyle (x_{1},\\ldots ,x_{K})}\n  . La r\u00e9gression logistique constitue un cas particulier de mod\u00e8le lin\u00e9aire g\u00e9n\u00e9ralis\u00e9. Elle est largement utilis\u00e9e en apprentissage automatique.\n\n", "element_cle": "1. La r\u00e9gression logistique est un mod\u00e8le de r\u00e9gression binomiale en statistiques.\n2. Son but est d'expliquer une variable binaire \u00e0 partir d'observations r\u00e9elles gr\u00e2ce \u00e0 un mod\u00e8le math\u00e9matique.\n3. Elle associe une variable al\u00e9atoire de Bernoulli \u00e0 un vecteur de variables al\u00e9atoires.\n4. La r\u00e9gression logistique est un cas particulier de mod\u00e8le lin\u00e9aire g\u00e9n\u00e9ralis\u00e9.\n5. Elle est largement utilis\u00e9e en apprentissage automatique.", "rap": "[Couplet 1]\nLa r\u00e9gression logistique, combinaison statistique\nPour expliquer une variable binaire, c'est magique\nDans les donn\u00e9es r\u00e9elles, un mod\u00e8le math\u00e9matique\nPour pr\u00e9dire le futur, c'est fantastique\n\nElle associe une Bernoulli \u00e0 des variables multiples\nPour cr\u00e9er des pr\u00e9dictions, pas besoin d'une multitude\nUn cas particulier, du mod\u00e8le lin\u00e9aire g\u00e9n\u00e9ralis\u00e9\nEn machine learning, elle est souvent utilis\u00e9e\n\n[Refrain]\nLa r\u00e9gression logistique, \u00e9ducateur math\u00e9matique\nDans le monde des donn\u00e9es, elle est symbolique\nPr\u00e9dire, expliquer, elle fait des miracles\nUn outil essentiel pour les probl\u00e8mes binaires\n\n[Couplet 2]\nDans l'apprentissage automatique, elle est reine\nPour classer, pr\u00e9voir, elle est le meilleur moyen\nDe l'analyse de risque \u00e0 la publicit\u00e9 cibl\u00e9e\nLa r\u00e9gression logistique est toujours sollicit\u00e9e\n\nAlors ouvrez vos esprits, \u00e9coutez cette m\u00e9lodie\nLa r\u00e9gression logistique, une technique de g\u00e9nie\nElle nous guide dans l'univers des probabilit\u00e9s\nPour comprendre le monde, \u00e0 jamais connect\u00e9s\n\n[Refrain]\nLa r\u00e9gression logistique, \u00e9ducateur math\u00e9matique\nDans le monde des donn\u00e9es, elle est symbolique\nPr\u00e9dire, expliquer, elle fait des miracles\nUn outil essentiel pour les probl\u00e8mes binaires"}, {"titre": "R\u00e9gression (statistiques)", "text_origine": "En math\u00e9matiques, la r\u00e9gression recouvre plusieurs m\u00e9thodes d\u2019analyse statistique permettant d\u2019approcher une variable \u00e0 partir d\u2019autres qui lui sont corr\u00e9l\u00e9es. Par extension, le terme est aussi utilis\u00e9 pour certaines m\u00e9thodes d\u2019ajustement de courbe.\nEn apprentissage automatique, on distingue les probl\u00e8mes de r\u00e9gression des probl\u00e8mes de classification. Ainsi, on consid\u00e8re que les probl\u00e8mes de pr\u00e9diction d'une variable quantitative sont des probl\u00e8mes de r\u00e9gression tandis que les probl\u00e8mes de pr\u00e9diction d'une variable qualitative sont des probl\u00e8mes de classification. Certaines m\u00e9thodes, comme la r\u00e9gression logistique, sont \u00e0 la fois des m\u00e9thodes de r\u00e9gression au sens o\u00f9 il s'agit de pr\u00e9dire la probabilit\u00e9 d'appartenir \u00e0 chacune des classes et des m\u00e9thodes de classification.", "element_cle": "1. La r\u00e9gression statistique est une m\u00e9thode permettant d'approximer une variable en fonction d'autres variables corr\u00e9l\u00e9es.\n2. La r\u00e9gression est aussi utilis\u00e9e pour ajuster des courbes.\n3. En apprentissage automatique, la r\u00e9gression et la classification sont deux probl\u00e8mes distincts.\n4. Les probl\u00e8mes de r\u00e9gression sont associ\u00e9s \u00e0 la pr\u00e9diction de variables quantitatives.\n5. Les probl\u00e8mes de classification sont associ\u00e9s \u00e0 la pr\u00e9diction de variables qualitatives.\n6. La r\u00e9gression logistique est une m\u00e9thode qui peut \u00eatre utilis\u00e9e \u00e0 la fois pour la r\u00e9gression et la classification.", "rap": "[Couplet 1]\nLa r\u00e9gression statistique, c'est mon domaine\nJ'approxime les variables, je fais du reign\nAvec des donn\u00e9es corr\u00e9l\u00e9es, j'fais le calcul\nPour trouver la relation, c'est pas si banal\n\nJ'ajuste des courbes, j'peux pas me tromper\nDans la r\u00e9gression, faut tout bien ajuster\nEn machine learning, y'a des probl\u00e8mes diff\u00e9rents\nLa r\u00e9gression et la classification, faut faire la diff\u00e9rence\n\n[Refrain]\nR\u00e9gression, c'est pour pr\u00e9dire du quantitatif\nClassification, c'est pour pr\u00e9dire du qualitatif\nJ'utilise la r\u00e9gression logistique, c'est pas d'la tarte\nPour faire de la r\u00e9gression et de la classification \u00e0 part\n\n[Couplet 2]\nLa r\u00e9gression logistique, \u00e7a me fait bouger\nJ'utilise cette m\u00e9thode, toujours bien cibler\nPour pr\u00e9dire des variables quantitatives, c'est parfait\nPour pr\u00e9dire des variables qualitatives, j'suis jamais d\u00e9faillant\n\nJ'm'adapte aux donn\u00e9es, j'suis pas tant classique\nJ'reste dans la statistique, toujours authentique\nLa r\u00e9gression et la classification, deux univers \u00e0 part\nMais moi j'me fais un plaisir de les combiner, c'est un art\n\n[Refrain]\nR\u00e9gression, c'est pour pr\u00e9dire du quantitatif\nClassification, c'est pour pr\u00e9dire du qualitatif\nJ'utilise la r\u00e9gression logistique, c'est pas d'la tarte\nPour faire de la r\u00e9gression et de la classification \u00e0 part"}, {"titre": "Analyse pr\u00e9dictive", "text_origine": "L'analyse (ou logique) pr\u00e9dictive est une m\u00e9thode issue des statistiques, de l'extraction de connaissances \u00e0 partir de donn\u00e9es et de la th\u00e9orie des jeux, analysant des faits pr\u00e9sents et pass\u00e9s, pour faire des hypoth\u00e8ses pr\u00e9dictives.\nDes mod\u00e8les pr\u00e9dictifs exploitent ainsi des sch\u00e9mas d\u00e9couverts \u00e0 l'int\u00e9rieur d'ensembles de donn\u00e9es historiques et transactionnelles, pour identifier les risques et les opportunit\u00e9s et orienter la prise de d\u00e9cision, par exemple dans le monde des affaires (en actuariat, dans les services financiers, l'assurance ou le commerce de d\u00e9tail\u2026) ou encore dans le droit et la justice, les t\u00e9l\u00e9communications, le tourisme, la sant\u00e9, l'industrie pharmaceutique et bien d'autres domaines.\nUn exemple est l'\u00e9valuation du risque-client dans les services financiers ; elle utilise les ant\u00e9c\u00e9dents de cr\u00e9dit d'un client, ses demandes de pr\u00eat, les donn\u00e9es client, etc. pour \u00e9valuer la probabilit\u00e9 qu'il rembourse ses cr\u00e9dits \u00e0 temps. Un exemple de ceci est le FICO Score.", "element_cle": "1. L'analyse pr\u00e9dictive est une m\u00e9thode issue des statistiques et de la th\u00e9orie des jeux.\n2. Elle consiste \u00e0 analyser des faits pr\u00e9sents et pass\u00e9s pour faire des hypoth\u00e8ses pr\u00e9dictives.\n3. Les mod\u00e8les pr\u00e9dictifs exploitent des sch\u00e9mas d\u00e9couverts dans des ensembles de donn\u00e9es historiques et transactionnelles.\n4. L'analyse pr\u00e9dictive est utilis\u00e9e dans de nombreux domaines tels que les affaires, le droit, la sant\u00e9, etc.\n5. Un exemple concret est l'\u00e9valuation du risque-client dans les services financiers, utilisant les ant\u00e9c\u00e9dents de cr\u00e9dit pour pr\u00e9dire la probabilit\u00e9 de remboursement.", "rap": "[Couplet 1]\nL'analyse pr\u00e9dictive, une m\u00e9thode statistique,\nIssue des jeux, de la th\u00e9orie, c'est pas du tic-tac,\nOn analyse les faits pass\u00e9s pour pr\u00e9dire l'avenir,\nDes hypoth\u00e8ses pr\u00e9dictives, faut savoir les construire.\n\n[Refrain]\nAnalyse pr\u00e9dictive, ouvre les horizons,\nDes sch\u00e9mas d\u00e9couverts dans les donn\u00e9es, c'est l'option,\nDans les affaires, le droit, la sant\u00e9 et tous les domaines,\nPr\u00e9dire le futur, c'est l'objectif principal qu'on m\u00e8ne.\n\n[Couplet 2]\nHistorique, transactionnel, des mod\u00e8les pr\u00e9dictifs,\nExploitent les donn\u00e9es pour voir l'\u00e9volutif,\nLe risque-client dans les services financiers,\nOn \u00e9value les ant\u00e9c\u00e9dents pour \u00eatre plus pr\u00e9miers.\n\n[Refrain]\nAnalyse pr\u00e9dictive, ouvre les horizons,\nDes sch\u00e9mas d\u00e9couverts dans les donn\u00e9es, c'est l'option,\nDans les affaires, le droit, la sant\u00e9 et tous les domaines,\nPr\u00e9dire le futur, c'est l'objectif principal qu'on m\u00e8ne."}, {"titre": "Fonction softmax", "text_origine": "En math\u00e9matiques, la fonction softmax, aussi appel\u00e9e fonction softargmax ou fonction exponentielle normalis\u00e9e, est une g\u00e9n\u00e9ralisation de la fonction logistique. Elle convertit un vecteur de K nombres r\u00e9els en une distribution de probabilit\u00e9s sur K choix. Plus pr\u00e9cis\u00e9ment, un vecteur \n  \n    \n      \n        \n          z\n        \n        =\n        \n          (\n          \n            \n              z\n              \n                1\n              \n            \n            ,\n            \u2026\n            ,\n            \n              z\n              \n                K\n              \n            \n          \n          )\n        \n      \n    \n    {\\displaystyle \\mathbf {z} =\\left(z_{1},\\dots ,z_{K}\\right)}\n   est transform\u00e9 un vecteur \n  \n    \n      \n        \u03c3\n        \n          (\n          \n            z\n          \n          )\n        \n      \n    \n    {\\displaystyle \\sigma \\left(\\mathbf {z} \\right)}\n   de K nombres r\u00e9els strictement positifs et de somme 1. La fonction est d\u00e9finie par :\n\n  \n    \n      \n        \u03c3\n        (\n        \n          z\n        \n        \n          )\n          \n            j\n          \n        \n        =\n        \n          \n            \n              \n                e\n              \n              \n                \n                  z\n                  \n                    j\n                  \n                \n              \n            \n            \n              \n                \u2211\n                \n                  k\n                  =\n                  1\n                \n                \n                  K\n                \n              \n              \n                \n                  e\n                \n                \n                  \n                    z\n                    \n                      k\n                    \n                  \n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle \\sigma (\\mathbf {z} )_{j}={\\frac {\\mathrm {e} ^{z_{j}}}{\\sum _{k=1}^{K}\\mathrm {e} ^{z_{k}}}}}\n   pour tout \n  \n    \n      \n        j\n        \u2208\n        \n          {\n          \n            1\n            ,\n            \u2026\n            ,\n            K\n          \n          }\n        \n      \n    \n    {\\displaystyle j\\in \\left\\{1,\\ldots ,K\\right\\}}\n  ,c'est-\u00e0-dire que la composante j du vecteur \n  \n    \n      \n        \u03c3\n        (\n        \n          z\n        \n        )\n      \n    \n    {\\displaystyle \\sigma (\\mathbf {z} )}\n   est \u00e9gale \u00e0 l'exponentielle de la composante j du vecteur z divis\u00e9e par la somme des exponentielles de toutes les composantes de z.\nEn th\u00e9orie des probabilit\u00e9s, la sortie de la fonction softmax peut \u00eatre utilis\u00e9e pour repr\u00e9senter une loi cat\u00e9gorielle \u2013 c\u2019est-\u00e0-dire une loi de probabilit\u00e9 sur K diff\u00e9rents r\u00e9sultats possibles. La fonction softmax est \u00e9galement connue pour \u00eatre utilis\u00e9e dans diverses m\u00e9thodes de classification en classes multiples, par exemple dans le cas de r\u00e9seaux de neurones artificiels. Cette fonction est parfois consid\u00e9r\u00e9e pour une version r\u00e9guli\u00e8re de la fonction argmax : si une composante \n  \n    \n      \n        \n          z\n          \n            j\n          \n        \n      \n    \n    {\\displaystyle z_{j}}\n   est strictement plus grande que les autres composantes \n  \n    \n      \n        \n          z\n          \n            k\n          \n        \n      \n    \n    {\\displaystyle z_{k}}\n  , alors \n  \n    \n      \n        \u03c3\n        (\n        \n          z\n        \n        \n          )\n          \n            j\n          \n        \n      \n    \n    {\\displaystyle \\sigma (\\mathbf {z} )_{j}}\n   vaut presque 1 et \n  \n    \n      \n        \u03c3\n        (\n        \n          z\n        \n        \n          )\n          \n            k\n          \n        \n      \n    \n    {\\displaystyle \\sigma (\\mathbf {z} )_{k}}\n  est quasiment nulle pour tout \n  \n    \n      \n        k\n        \u2260\n        j\n      \n    \n    {\\displaystyle k\\neq j}\n  .", "element_cle": "1. La fonction softmax est une g\u00e9n\u00e9ralisation de la fonction logistique en math\u00e9matiques.\n2. Elle convertit un vecteur de nombres r\u00e9els en une distribution de probabilit\u00e9s.\n3. La fonction softmax est \u00e9galement appel\u00e9e fonction softargmax ou fonction exponentielle normalis\u00e9e.\n4. Elle est utilis\u00e9e pour obtenir une somme de probabilit\u00e9s \u00e9gale \u00e0 1 pour un ensemble de choix.\n5. La fonction softmax est d\u00e9finie par une formule qui utilise l'exponentielle et la somme des valeurs du vecteur d'entr\u00e9e.", "rap": "[Couplet 1]\nSur le chemin du savoir, j'te d\u00e9voile la v\u00e9rit\u00e9\nLa fonction softmax, un game changer dans la r\u00e9alit\u00e9\nUne g\u00e9n\u00e9ralisation math\u00e9matique, crois-moi, c'est du costaud\nElle transforme tes chiffres en probabilit\u00e9s, c'est \u00e7a le flow\n\n[Refrain]\nLa fonction softmax, une distribution de probabilit\u00e9s\nMets tes choix sur la table, tout est normalis\u00e9\n\n[Couplet 2]\nSoftargmax, autre nom de cette m\u00e9thode pr\u00e9cise\nPour obtenir des chances \u00e9gales, faut \u00eatre un p'tit peu concis\nAdditionne les valeurs, multiplie par l'exponentielle\nEt t'auras une somme qui vaut toujours cent pourcent, c'est essentiel\n\n[Refrain]\nLa fonction softmax, une distribution de probabilit\u00e9s\nMets tes choix sur la table, tout est normalis\u00e9"}, {"titre": "R\u00e9gression lin\u00e9aire", "text_origine": "En statistiques, en \u00e9conom\u00e9trie et en apprentissage automatique, un mod\u00e8le de r\u00e9gression lin\u00e9aire est un mod\u00e8le de r\u00e9gression qui cherche \u00e0 \u00e9tablir une relation lin\u00e9aire entre une variable, dite expliqu\u00e9e, et une ou plusieurs variables, dites explicatives.\nOn parle aussi de mod\u00e8le lin\u00e9aire ou de mod\u00e8le de r\u00e9gression lin\u00e9aire.\nParmi les mod\u00e8les de r\u00e9gression lin\u00e9aire, le plus simple est l'ajustement affine. Celui-ci consiste \u00e0 rechercher la droite permettant d'expliquer le comportement d'une variable statistique y comme \u00e9tant une fonction affine d'une autre variable statistique x.\nEn g\u00e9n\u00e9ral, le mod\u00e8le de r\u00e9gression lin\u00e9aire d\u00e9signe un mod\u00e8le dans lequel l'esp\u00e9rance conditionnelle de y connaissant x est une fonction affine des param\u00e8tres. Cependant, on peut aussi consid\u00e9rer des mod\u00e8les dans lesquels c'est la m\u00e9diane conditionnelle de y connaissant x ou n'importe quel quantile de la distribution de y connaissant x qui est une fonction affine des param\u00e8tres.\nLe mod\u00e8le de r\u00e9gression lin\u00e9aire est souvent estim\u00e9 par la m\u00e9thode des moindres carr\u00e9s mais il existe aussi de nombreuses autres m\u00e9thodes pour estimer ce mod\u00e8le. On peut par exemple estimer le mod\u00e8le par maximum de vraisemblance ou encore par inf\u00e9rence bay\u00e9sienne.\nBien qu'ils soient souvent pr\u00e9sent\u00e9s ensemble, le mod\u00e8le lin\u00e9aire et la m\u00e9thode des moindres carr\u00e9s ne d\u00e9signent pas la m\u00eame chose. Le mod\u00e8le lin\u00e9aire d\u00e9signe une classe de mod\u00e8les qui peuvent \u00eatre estim\u00e9s par un grand nombre de m\u00e9thodes, et la m\u00e9thode des moindres carr\u00e9s d\u00e9signe une m\u00e9thode d'estimation. Elle peut \u00eatre utilis\u00e9e pour estimer diff\u00e9rents types de mod\u00e8les.", "element_cle": "1. Un mod\u00e8le de r\u00e9gression lin\u00e9aire cherche \u00e0 \u00e9tablir une relation lin\u00e9aire entre une variable expliqu\u00e9e et une ou plusieurs variables explicatives.\n2. L'ajustement affine est le mod\u00e8le le plus simple de r\u00e9gression lin\u00e9aire, consistant \u00e0 rechercher une droite pour expliquer le comportement d'une variable statistique.\n3. Le mod\u00e8le de r\u00e9gression lin\u00e9aire peut se baser sur l'esp\u00e9rance conditionnelle, la m\u00e9diane conditionnelle ou n'importe quel quantile de la distribution de la variable expliqu\u00e9e.\n4. La m\u00e9thode des moindres carr\u00e9s est souvent utilis\u00e9e pour estimer le mod\u00e8le de r\u00e9gression lin\u00e9aire.\n5. Il existe d'autres m\u00e9thodes d'estimation pour le mod\u00e8le de r\u00e9gression lin\u00e9aire, telles que le maximum de vraisemblance et l'inf\u00e9rence bay\u00e9sienne.", "rap": "[Couplet 1]\nJ'repr\u00e9sente la r\u00e9gression lin\u00e9aire\nLe mod\u00e8le qui cherche \u00e0 tout \u00e9clairer\nEntre une variable expliqu\u00e9e et d'autres variables\n\u00c7a fait pas d'erreur, c'est math\u00e9matique, c'est pas un miracle\n\n[Couplet 2]\nL'ajustement affine, le plus simple des mod\u00e8les\nUne droite qui se brise pas, c'est pas un jeu de quilles\nOn cherche \u00e0 comprendre comment \u00e7a s'comporte\nUne variable statistique, \u00e7a tourne sans effort\n\n[Refrain]\nR\u00e9gression lin\u00e9aire, on \u00e9tablit les liens\nUn mod\u00e8le efficace pour tout comprendre, \u00e7a fait du bien\nM\u00e9thode des moindres carr\u00e9s, on estime les param\u00e8tres\nAvec pr\u00e9cision, on peut pr\u00e9dire le futur, \u00e7a va para\u00eetre clair\n\n[Couplet 3]\nEsp\u00e9rance conditionnelle, m\u00e9diane ou quantile\nOn peut tout calculer, \u00e7a m'\u00e9merveille\nLa distribution de la variable expliqu\u00e9e\nOn la scrute, on la d\u00e9code, avec la r\u00e9gression lin\u00e9aire\n\n[Couplet 4]\nLes moindres carr\u00e9s, une m\u00e9thode bien connue\nPour estimer le mod\u00e8le, y'a pas mieux, y'a pas d'vue\nMaximum de vraisemblance, inf\u00e9rence bay\u00e9sienne\nD'autres m\u00e9thodes d'estimation, \u00e7a donne de l'envergure, c'est pas un jeu de sc\u00e8ne\n\n[Refrain]\nR\u00e9gression lin\u00e9aire, on \u00e9tablit les liens\nUn mod\u00e8le efficace pour tout comprendre, \u00e7a fait du bien\nM\u00e9thode des moindres carr\u00e9s, on estime les param\u00e8tres\nAvec pr\u00e9cision, on peut pr\u00e9dire le futur, \u00e7a va para\u00eetre clair"}, {"titre": "R\u00e9gression de Cox", "text_origine": "La r\u00e9gression de Cox (mod\u00e8le \u00e0 risque proportionnel) \u2014 nomm\u00e9e ainsi d'apr\u00e8s le statisticien britannique David Cox \u2014 est une classe de mod\u00e8les de survie en statistique. Les mod\u00e8les de survie \u00e9tudient le temps \u00e9coul\u00e9 avant qu'un \u00e9v\u00e9nement ne survienne. Historiquement, dans le mod\u00e8le de Cox, cet \u00e9v\u00e9nement est le d\u00e9c\u00e8s de l'individu, c'est pourquoi on parle g\u00e9n\u00e9ralement de survie et de d\u00e9c\u00e8s. Au cours des ann\u00e9es, l'utilisation du mod\u00e8le s'est \u00e9tendue \u00e0 d'autres situations, l'\u00e9v\u00e9nement peut donc \u00eatre de quelconque nature : il peut s'agir de la r\u00e9cidive d'une maladie, ou \u00e0 l'inverse d'une gu\u00e9rison. D'un point de vue statistique, la nature de l'\u00e9v\u00e9nement n'est bien s\u00fbr pas importante, il s'agira alors d'interpr\u00e9ter les coefficients en cons\u00e9quence. \nPrenons le cas d'une \u00e9tude longitudinale, bien souvent, il n'est pas envisageable de suivre les individus sur une longue p\u00e9riode, et les \u00e9v\u00e9nements ne sont pas forc\u00e9ment observ\u00e9s sur toute la population, on parle alors de donn\u00e9es tronqu\u00e9es ou censur\u00e9es. L'avantage d'un mod\u00e8le comme celui de Cox est que l'on peut prendre en compte ces donn\u00e9es m\u00eame si elles ne sont pas \u00ab compl\u00e8tes \u00bb.", "element_cle": "1. La r\u00e9gression de Cox (mod\u00e8le \u00e0 risque proportionnel) est une classe de mod\u00e8les de survie en statistique.\n2. Le mod\u00e8le de Cox \u00e9tudie le temps \u00e9coul\u00e9 avant qu'un \u00e9v\u00e9nement ne survienne, g\u00e9n\u00e9ralement le d\u00e9c\u00e8s.\n3. Au fil des ann\u00e9es, l'utilisation du mod\u00e8le de Cox s'est \u00e9tendue \u00e0 d'autres situations o\u00f9 l'\u00e9v\u00e9nement peut \u00eatre de toute nature.\n4. L'\u00e9v\u00e9nement peut \u00eatre une r\u00e9cidive de maladie ou une gu\u00e9rison, entre autres.\n5. Le mod\u00e8le de Cox permet de prendre en compte les donn\u00e9es tronqu\u00e9es ou censur\u00e9es dans une \u00e9tude longitudinale.", "rap": "[Couplet 1]\nLa r\u00e9gression de Cox, mod\u00e8le \u00e0 risque proportionnel\nEn statistique, c'est de la survie, tout est r\u00e9v\u00e9l\u00e9\nOn \u00e9tudie le temps avant que l'\u00e9v\u00e9nement frappe\nSouvent la mort, un horizon tragique\n\n[Refrain]\nLa r\u00e9cidive de maladie ou la gu\u00e9rison\nLe mod\u00e8le de Cox, c'est la pr\u00e9cision\nDes ann\u00e9es d'utilisation, son champ s'agrandit\nPour toutes les situations, toutes les vies\n\n[Couplet 2]\nMaintenant le mod\u00e8le s'adapte \u00e0 tout type d'\u00e9v\u00e9nements\nPas seulement le tr\u00e9pas, mais d'autres changements\nUne \u00e9tude longitudinale, des donn\u00e9es censur\u00e9es\nLe mod\u00e8le de Cox r\u00e9v\u00e8le la r\u00e9alit\u00e9\n\n[Refrain]\nLa r\u00e9cidive de maladie ou la gu\u00e9rison\nLe mod\u00e8le de Cox, c'est la pr\u00e9cision\nDes ann\u00e9es d'utilisation, son champ s'agrandit\nPour toutes les situations, toutes les vies"}, {"titre": "Analyse de la variance", "text_origine": "En statistique, l'analyse de la variance (terme souvent abr\u00e9g\u00e9 par le terme anglais ANOVA : analysis of variance) est un ensemble de mod\u00e8les statistiques utilis\u00e9s pour v\u00e9rifier si les moyennes des groupes proviennent d'une m\u00eame population[source insuffisante]. Les groupes correspondent aux modalit\u00e9s d'une variable qualitative (p. ex. variable : traitement; modalit\u00e9s : programme d'entrainement sportif, suppl\u00e9ments alimentaires; placebo) et les moyennes sont calcul\u00e9s \u00e0 partir d'une variable continue (p. ex. gain musculaire).\nCe test s'applique lorsque l'on mesure une ou plusieurs variables explicatives cat\u00e9gorielle (appel\u00e9es alors facteurs de variabilit\u00e9, leurs diff\u00e9rentes modalit\u00e9s \u00e9tant parfois appel\u00e9es \u00ab niveaux \u00bb) qui ont de l'influence sur la loi d'une variable continue \u00e0 expliquer. On parle d'analyse \u00e0 un facteur lorsque l'analyse porte sur un mod\u00e8le d\u00e9crit par un seul facteur de variabilit\u00e9, d'analyse \u00e0 deux facteurs ou d'analyse multifactorielle sinon.", "element_cle": "1. L'analyse de la variance est utilis\u00e9e en statistique pour v\u00e9rifier si les moyennes des groupes proviennent d'une m\u00eame population.\n2. Elle utilise des mod\u00e8les statistiques pour comparer les moyennes de groupes.\n3. Les groupes sont d\u00e9finis par les modalit\u00e9s d'une variable qualitative.\n4. Les moyennes sont calcul\u00e9es \u00e0 partir d'une variable continue.\n5. L'ANOVA s'applique lorsque des variables cat\u00e9gorielles influencent la loi d'une variable continue \u00e0 expliquer.", "rap": "[Couplet]\nL'analyse de la variance, un outil statistique,\nPour v\u00e9rifier si les groupes proviennent de la m\u00eame clique.\nOn compare les moyennes, dans un mod\u00e8le pr\u00e9cis,\nDes groupes bien d\u00e9finis par une variable qualitative.\n\n[Couplet]\nLes moyennes sont calcul\u00e9es, \u00e0 partir d'une variable continue,\nOn cherche \u00e0 savoir si ces groupes se ressemblent un peu.\nL'ANOVA intervient, quand des variables cat\u00e9gorielles,\nInfluent sur la loi, d'une variable continue \u00e0 expliquer.\n\n[Refrain]\nAnalyse de la variance, pour comprendre la diff\u00e9rence,\nEntre les groupes, trouver la vraie essence.\nUn outil puissant, pour les stats en tout genre,\n\u00c9tudier, comparer, pour une vue plus claire."}, {"titre": "Analyse de variance multivari\u00e9e", "text_origine": "L'analyse de variance multivari\u00e9e (ou MANOVA pour \u00ab Multivariate analysis of variance \u00bb) est un test statistique qui vise \u00e0 d\u00e9terminer si des facteurs qualitatifs ont des effets significatifs sur plusieurs variables d\u00e9pendantes quantitatives prises collectivement. En cela, la MANOVA est donc une g\u00e9n\u00e9ralisation de l'analyse de la variance (ANOVA), qui est univari\u00e9e, c'est-\u00e0-dire qui ne porte que sur une seule variable d\u00e9pendante. La MANOVA est aussi utilis\u00e9e pour identifier des interactions entre les variables d\u00e9pendantes et entre les variables ind\u00e9pendantes.", "element_cle": "1. L'analyse de variance multivari\u00e9e (MANOVA) permet de tester les effets des facteurs qualitatifs sur plusieurs variables d\u00e9pendantes quantitatives.\n2. La MANOVA est une g\u00e9n\u00e9ralisation de l'analyse de variance (ANOVA) qui ne porte que sur une seule variable d\u00e9pendante.\n3. La MANOVA peut \u00e9galement d\u00e9tecter les interactions entre les variables d\u00e9pendantes et ind\u00e9pendantes.\n4. L'objectif de la MANOVA est de d\u00e9terminer si les facteurs qualitatifs ont des effets significatifs sur les variables d\u00e9pendantes.\n5. La MANOVA est une m\u00e9thode statistique utilis\u00e9e pour analyser des donn\u00e9es multivari\u00e9es.", "rap": "[Couplet 1]\nYo, laisse-moi t'expliquer la MANOVA,\nUne analyse de variance multivari\u00e9e,\nTeste les effets des facteurs qualitatifs,\nSur plusieurs variables d\u00e9pendantes quantitatives.\n\nLa MANOVA, c'est une g\u00e9n\u00e9ralisation,\nDe l'ANOVA, un peu plus d'action,\nElle ne porte pas sur une seule variable,\nMais sur plusieurs, pour plus de stabilit\u00e9.\n\n[Refrain]\nLa MANOVA, une m\u00e9thode puissante,\nPour \u00e9tudier les relations entre les variables,\nElle d\u00e9tecte les interactions, point par point,\nPour des r\u00e9sultats plus fiables, sans aucun  reproche.\n\n\n[Couplet 2]\nLa MANOVA, elle a un objectif clair,\nD\u00e9terminer si les facteurs qualitatifs ont du pouvoir,\nSur les variables d\u00e9pendantes qu'on \u00e9tudie,\nEt trouver des effets significatifs, c'est joli.\n\nElle permet d'analyser des donn\u00e9es complexe,\nDonn\u00e9es multivari\u00e9es, un vrai casse-t\u00eate,\nPour comprendre les relations entre les variables,\nLa MANOVA, c'est la m\u00e9thode id\u00e9ale, vraie merveille.\n\n[Refrain]\nLa MANOVA, une m\u00e9thode puissante,\nPour \u00e9tudier les relations entre les variables,\nElle d\u00e9tecte les interactions, point par point,\nPour des r\u00e9sultats plus fiables, sans aucun  reproche."}, {"titre": "Variance (math\u00e9matiques)", "text_origine": "En statistique et en th\u00e9orie des probabilit\u00e9s, la variance est une mesure de la dispersion des valeurs d'un \u00e9chantillon ou d'une variable al\u00e9atoire. Elle exprime la moyenne des carr\u00e9s des \u00e9carts \u00e0 la moyenne, aussi \u00e9gale \u00e0 la diff\u00e9rence entre la moyenne des carr\u00e9s des valeurs de la variable et le carr\u00e9 de la moyenne, selon le th\u00e9or\u00e8me de K\u00f6nig-Huygens. Ainsi, plus l'\u00e9cart \u00e0 la moyenne est grand plus il est pr\u00e9pond\u00e9rant dans le calcul total (voir la fonction carr\u00e9) de la variance qui donnerait donc une bonne id\u00e9e sur la dispersion des valeurs.\nLa variance est toujours positive, et ne s\u2019annule que s\u2019il n\u2019y a essentiellement qu\u2019une seule valeur. Sa racine carr\u00e9e d\u00e9finit l\u2019\u00e9cart type \u03c3, d\u2019o\u00f9 la notation \n  \n    \n      \n        \n          \u03c3\n          \n            2\n          \n        \n        =\n        V\n        =\n        \n          V\n        \n        (\n        X\n        )\n        =\n        \n          V\n          a\n          r\n          (\n          X\n          )\n        \n      \n    \n    {\\displaystyle \\sigma ^{2}=V=\\mathbb {V} (X)=\\mathrm {Var(X)} }\n  .\nLa variance est quadratique et invariante par translation. Elle peut \u00eatre estim\u00e9e \u00e0 l\u2019aide d\u2019un \u00e9chantillon et de la moyenne empirique ou d\u00e9termin\u00e9e gr\u00e2ce \u00e0 l\u2019esp\u00e9rance si celle-ci est connue.\nLa variance apparait comme un cas particulier de covariance. Elle se g\u00e9n\u00e9ralise aussi pour des vecteurs al\u00e9atoires.", "element_cle": "- La variance mesure la dispersion des valeurs d'un \u00e9chantillon ou d'une variable al\u00e9atoire en statistique et th\u00e9orie des probabilit\u00e9s.\n- Elle exprime la moyenne des carr\u00e9s des \u00e9carts \u00e0 la moyenne.\n- La variance est toujours positive et s'annule seulement s'il n'y a qu'une seule valeur.\n- Sa racine carr\u00e9e d\u00e9finit l'\u00e9cart type.\n- La variance est quadratique et invariante par translation.", "rap": "[Couplet 1]\nDans l'analyse statistique, j'prends la variance en compte\nElle mesure la dispersion, ouais, c'est \u00e7a le compte\nElle calcule la moyenne des carr\u00e9s des \u00e9carts\n\u00c7a me permet d'voir si mes donn\u00e9es sont \u00e0 l'\u00e9cart\n\nElle est toujours positive, sauf s'il y a qu'une seule valeur\nC'est l'exception qui confirme la r\u00e8gle, mon fr\u00e8re\nLe z\u00e9ro, elle fr\u00f4le pas, elle l'atteint jamais\nLa variance, elle s'annule pas, \u00e7a c'est bien vrai\n\n[Refrain]\nLa variance, je la calcule, je l'\u00e9tudie, je l'observe\nElle dit si mes donn\u00e9es, elles sont trop peu coh\u00e9rentes\nJ'en fais pas un myst\u00e8re, mais j'te l'explique en clair\nLa variance, c'est l'outil indispensable dans mon r\u00e9pertoire\n\n[Couplet 2]\nLa racine carr\u00e9e de la variance, c'est l'\u00e9cart type\nC'est lui qui dit si mes donn\u00e9es, elles suivent un type\nPlus il est grand, plus la dispersion est importante\nJ'utilise cette mesure, j'en fais ma r\u00e9f\u00e9rence\n\nLa variance, elle est quadratique, c'est math\u00e9matique\nElle se calcule en toute logique, j'ai pas besoin d'\u00e9thique\nEt elle est invariante par translation, c'est le principe\nPeu importe la moyenne, ma variance reste la m\u00eame, c'est pas du vice\n\n[Refrain]\nLa variance, je la calcule, je l'\u00e9tudie, je l'observe\nElle dit si mes donn\u00e9es, elles sont trop peu coh\u00e9rentes\nJ'en fais pas un myst\u00e8re, mais j'te l'explique en clair\nLa variance, c'est l'outil indispensable dans mon r\u00e9pertoire"}, {"titre": "Analyse discriminante lin\u00e9aire", "text_origine": "En statistique, l\u2019analyse discriminante lin\u00e9aire ou ADL (en anglais, linear discriminant analysis ou LDA) fait partie des techniques d\u2019analyse discriminante pr\u00e9dictive. Il s\u2019agit d\u2019expliquer et de pr\u00e9dire l\u2019appartenance d\u2019un individu \u00e0 une classe (groupe) pr\u00e9d\u00e9finie \u00e0 partir de ses caract\u00e9ristiques mesur\u00e9es \u00e0 l\u2019aide de variables pr\u00e9dictives.\nDans l\u2019exemple de l'article Analyse discriminante, le fichier Flea Beetles, l\u2019objectif est de d\u00e9terminer l\u2019appartenance de puces \u00e0 telle ou telle esp\u00e8ce \u00e0 partir de la largeur et de l\u2019angle de son \u00e9d\u00e9age (partie des organes g\u00e9nitaux m\u00e2les de l'insecte.) \nLa variable \u00e0 pr\u00e9dire est forc\u00e9ment cat\u00e9gorielle (discr\u00e8te), elle poss\u00e8de 3 modalit\u00e9s dans notre exemple. Les variables pr\u00e9dictives sont a priori toutes continues. Il est n\u00e9anmoins possible de traiter les variables pr\u00e9dictives discr\u00e8tes moyennant une pr\u00e9paration ad\u00e9quate des donn\u00e9es.\nL\u2019analyse discriminante lin\u00e9aire peut \u00eatre compar\u00e9e aux m\u00e9thodes supervis\u00e9es d\u00e9velopp\u00e9es en apprentissage automatique et \u00e0 la r\u00e9gression logistique d\u00e9velopp\u00e9e en statistique.", "element_cle": "1. L'analyse discriminante lin\u00e9aire est une technique d'analyse discriminante pr\u00e9dictive en statistique.\n2. Elle permet de pr\u00e9dire l'appartenance d'un individu \u00e0 une classe pr\u00e9d\u00e9finie \u00e0 partir de ses caract\u00e9ristiques mesur\u00e9es.\n3. Dans l'exemple de l'article, l'objectif est de d\u00e9terminer l'appartenance d'une puce \u00e0 une esp\u00e8ce en utilisant la largeur et l'angle de son \u00e9d\u00e9age.\n4. La variable \u00e0 pr\u00e9dire est cat\u00e9gorielle avec 3 modalit\u00e9s.\n5. Les variables pr\u00e9dictives sont g\u00e9n\u00e9ralement continues, mais peuvent aussi \u00eatre discr\u00e8tes avec une pr\u00e9paration ad\u00e9quate des donn\u00e9es.\n6. L'analyse discriminante lin\u00e9aire peut \u00eatre compar\u00e9e \u00e0 d'autres m\u00e9thodes supervis\u00e9es d'apprentissage automatique et \u00e0 la r\u00e9gression logistique en statistique.", "rap": "[Couplet 1]\nL'analyse discriminante lin\u00e9aire, une technique avanc\u00e9e\nPr\u00e9dictive en statistique, pour nous \u00e9clairer\nElle d\u00e9termine l'appartenance \u00e0 une classe pr\u00e9d\u00e9finie\n\u00c0 partir des caract\u00e9ristiques mesur\u00e9es, une prouesse garantie\n\n[Refrain]\nAnalyse discriminante lin\u00e9aire, une m\u00e9thode bien rod\u00e9e\nPour pr\u00e9dire avec pr\u00e9cision, l'appartenance souhait\u00e9e\n\n[Couplet 2]\nImagine, une puce avec sa morphologie sp\u00e9cifique\nLa largeur et l'angle de son \u00e9d\u00e9age comme indice significatif\nObjectif, d\u00e9terminer son esp\u00e8ce, telle est la mission\nPour \u00e7a, on utilise l'analyse discriminante et ses options\n\n[Refrain]\nAnalyse discriminante lin\u00e9aire, une m\u00e9thode bien rod\u00e9e\nPour pr\u00e9dire avec pr\u00e9cision, l'appartenance souhait\u00e9e\n\n[Couplet 3]\nVariable cat\u00e9gorielle, trois modalit\u00e9s possibles\nLes variables pr\u00e9dictives, souvent continues, cr\u00e9dibles\nMais elles peuvent aussi \u00eatre discr\u00e8tes, avec une condition\nPr\u00e9paration ad\u00e9quate des donn\u00e9es pour une meilleure vision\n\n[Refrain]\nAnalyse discriminante lin\u00e9aire, une m\u00e9thode bien rod\u00e9e\nPour pr\u00e9dire avec pr\u00e9cision, l'appartenance souhait\u00e9e\n\n[Couplet 4]\nCompar\u00e9e \u00e0 d'autres m\u00e9thodes, elle fait ses preuves\nSupervis\u00e9e, comme l'apprentissage automatique, qu'elle \u00e9meut\nR\u00e9gression logistique, elle lui tient compagnie\nL'analyse discriminante lin\u00e9aire, c'est la cl\u00e9 de tous nos soucis\n\n[Refrain]\nAnalyse discriminante lin\u00e9aire, une m\u00e9thode bien rod\u00e9e\nPour pr\u00e9dire avec pr\u00e9cision, l'appartenance souhait\u00e9e"}, {"titre": "Analyse de covariance", "text_origine": "L'analyse de la covariance (ANCOVA) est une m\u00e9thode statistique visant \u00e0 tester, par un mod\u00e8le lin\u00e9aire g\u00e9n\u00e9ral, l'effet sur une variable d\u00e9pendante continue d'une ou plusieurs variables ind\u00e9pendantes cat\u00e9gorielles, ind\u00e9pendamment de l'effet d'autres facteurs quantitatif continus, dits covariables. En d'autres termes, l'ANCOVA est une combinaison entre une ANOVA et une r\u00e9gression de telle sorte que l'ANCOVA permet de tester si certains facteurs ont un effet sur la variable r\u00e9sultat apr\u00e8s avoir enlev\u00e9 la variance due aux covariables. L'inclusion de covariables peut accro\u00eetre la puissance statistique parce qu'elles sont la cause d'une certaine variabilit\u00e9,.", "element_cle": "1. L'analyse de la covariance (ANCOVA) est une m\u00e9thode statistique qui teste l'effet d'une ou plusieurs variables ind\u00e9pendantes cat\u00e9gorielles sur une variable d\u00e9pendante continue.\n2. L'ANCOVA permet de contr\u00f4ler l'effet des facteurs quantitatifs continus, appel\u00e9s covariables.\n3. Cette m\u00e9thode combine les principes de l'ANOVA et de la r\u00e9gression.\n4. L'objectif de l'ANCOVA est de d\u00e9terminer si certains facteurs ont un effet significatif sur la variable r\u00e9sultat, en tenant compte de l'influence des covariables.\n5. L'inclusion des covariables peut augmenter la puissance statistique de l'analyse.", "rap": "[Couplet 1]\nL'ANCOVA, m\u00e9thode statistique,\nTestant les variables, reste caract\u00e9ristique,\nCat\u00e9goriques, ind\u00e9pendantes, tu vois,\nL'effet sur la variable continue, \u00e7a d\u00e9ploie.\n\nContr\u00f4ler les facteurs quantitatifs, faut l'faire,\nLes covariables, pour bien les avoir en l'air,\nFusion d'ANOVA et de r\u00e9gression,\nL'ANCOVA, technique d'expression.\n\n[Refrain]\nANCOVA, analyse pr\u00e9cise et claire,\nEffet significatif, faut le d\u00e9montrer,\nAvec les covariables, on peut s'am\u00e9liorer,\nAugmenter la puissance, c'est notre affaire.\n\n[Couplet 2]\nObjectif, d\u00e9terminer l'impact des facteurs,\nSur la variable r\u00e9sultat, c'est s\u00fbr,\nEn prenant compte des covariables aussi,\nL'ANCOVA, tel un magicien devant la loi.\n\nInclusion des covariables, c'est crucial,\nPuissance statistique, c'est le tribunal,\nFocus sur les dates et les \u00e9v\u00e9nements marquants,\nEn \u00e9ducation, l'ANCOVA, c'est impliquant.\n\n[Refrain]\nANCOVA, analyse pr\u00e9cise et claire,\nEffet significatif, faut le d\u00e9montrer,\nAvec les covariables, on peut s'am\u00e9liorer,\nAugmenter la puissance, c'est notre affaire."}, {"titre": "Test de Kruskal-Wallis", "text_origine": "Le test de Kruskal-Wallis (d'apr\u00e8s William Kruskal et Wilson Allen Wallis), aussi appel\u00e9 ANOVA unidirectionnelle sur rangs (ou ANOVA \u00e0 un facteur contr\u00f4l\u00e9 sur rangs) est une m\u00e9thode non param\u00e9trique utilis\u00e9e pour tester si des \u00e9chantillons trouvent leur origine dans la m\u00eame distribution,,. Ce test s'int\u00e9resse aux m\u00e9dianes de \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n   populations (\n  \n    \n      \n        k\n        \u2a7e\n        3\n      \n    \n    {\\displaystyle k\\geqslant 3}\n  ) (ou treatment dans la litt\u00e9rature en anglais) et propose comme hypoth\u00e8se nulle que les \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n   \u00e9chantillons sont confondus et proviennent d'un m\u00eame \u00e9chantillon (combin\u00e9) d'une population. Le test permet de comparer deux ou plusieurs \u00e9chantillons ind\u00e9pendants de taille similaire ou non. Il g\u00e9n\u00e9ralise le  test de Wilcoxon-Mann-Whitney, qui est utilis\u00e9 pour comparer seulement deux groupes. L'\u00e9quivalent param\u00e9trique du test de Kruskal-Wallis est l'analyse unidirectionnelle de la variance (ANOVA).\nUn test de Kruskal-Wallis significatif indique qu'au moins un \u00e9chantillon domine stochastiquement un autre \u00e9chantillon. Le test n'identifie pas o\u00f9 cette dominance stochastique se produit ni pour combien de paires de groupes la dominance stochastique s'obtient. Pour analyser les paires d'\u00e9chantillons sp\u00e9cifiques en vue de d\u00e9terminer la dominance stochastique, on utilise parfois le test de Dunn, les tests de Mann-Whitney par paires sans correction de Bonferroni ou encore le test de Conover-Iman, plus puissant mais moins connu.\nComme il s'agit d'une m\u00e9thode non param\u00e9trique, le test de Kruskal-Wallis ne suppose pas une distribution normale des r\u00e9sidus, contrairement \u00e0 l'analyse de variance \u00e0 sens unique analogue. Si le chercheur peut faire l'hypoth\u00e8se d'une distribution de forme et d'\u00e9chelle identiques pour tous les groupes, \u00e0 l'exception de toute diff\u00e9rence dans les m\u00e9dianes, alors l'hypoth\u00e8se nulle est que les m\u00e9dianes de tous les groupes sont \u00e9gales, et l'hypoth\u00e8se alternative est qu'au moins une m\u00e9diane de la population d'un groupe est diff\u00e9rente de la m\u00e9diane de la population d'au moins un autre groupe.", "element_cle": "Voici les \u00e9l\u00e9ments cl\u00e9s du texte :\n\n1. Le test de Kruskal-Wallis est une m\u00e9thode non param\u00e9trique pour tester si des \u00e9chantillons proviennent de la m\u00eame distribution.\n2. Ce test compare les m\u00e9dianes de plusieurs populations.\n3. L'hypoth\u00e8se nulle du test est que les \u00e9chantillons sont confondus et proviennent d'un m\u00eame \u00e9chantillon d'une population combin\u00e9e.\n4. Le test permet de comparer deux ou plusieurs \u00e9chantillons ind\u00e9pendants.\n5. Il g\u00e9n\u00e9ralise le test de Wilcoxon-Mann-Whitney utilis\u00e9 pour comparer seulement deux groupes.\n6. Le test de Kruskal-Wallis est l'\u00e9quivalent non param\u00e9trique de l'ANOVA.\n7. Un test significatif indique qu'au moins un \u00e9chantillon domine stochastiquement un autre \u00e9chantillon.\n8. Pour d\u00e9terminer la dominance stochastique entre les groupes, on peut utiliser le test de Dunn ou les tests de Mann-Whitney sans correction de Bonferroni.\n9. Le test de Kruskal-Wallis ne suppose pas une distribution normale des r\u00e9sidus.\n10. Si les groupes ont une distribution similaire en termes de forme et d'\u00e9chelle, l'hypoth\u00e8se nulle est que les m\u00e9dianes de tous les groupes sont \u00e9gales.", "rap": "[Couplet 1]\nLe test de Kruskal-Wallis, une technique bien pr\u00e9cise\nPour v\u00e9rifier si les \u00e9chantillons viennent de la m\u00eame mise\nOn compare les m\u00e9dianes, plusieurs populations en sc\u00e8ne\nPour d\u00e9terminer si elles ont une distribution commune, c'est sain \n\nL'hypoth\u00e8se nulle, ils viennent d'un m\u00eame \u00e9chantillon\nLa m\u00eame population, pas de confusion, pas d'embrouillon\nComparer deux ou plusieurs \u00e9chantillons, c'est notre mission\nWilcoxon-Mann-Whitney, on g\u00e9n\u00e9ralise cette notion\n\n[Refrain]\nKruskal-Wallis, tester la similitude des distributions\nAnalyse de donn\u00e9es, on fait preuve de pr\u00e9cision\nDates et \u00e9v\u00e9nements marquants, on garde en m\u00e9moire\nEducative et informative, on partage notre histoire\n\n[Couplet 2]\nL'\u00e9quivalent non param\u00e9trique de l'ANOVA, le bougre de test\nPour les situations complexes, il est le meilleur, le plus juste\nUn r\u00e9sultat significatif, \u00e7a veut dire qu'un groupe domine\nStochastiquement les autres, c'est \u00e7a qu'on examine\n\nPour d\u00e9terminer la dominance stochastique entre les groupes\nTest de Dunn ou Mann-Whitney, sans correction, que du mieux\nPas besoin d'une distribution normale des r\u00e9sidus ici\nOn avance, on avance, pas de limite, on d\u00e9fi\n\nSi les groupes ont une distribution similaire, de m\u00eame en tout aspect\nLes m\u00e9dianes sont \u00e9gales, on confirme cette hypoth\u00e8se sans regret\n\n[Refrain]\nKruskal-Wallis, tester la similitude des distributions\nAnalyse de donn\u00e9es, on fait preuve de pr\u00e9cision\nDates et \u00e9v\u00e9nements marquants, on garde en m\u00e9moire\nEducative et informative, on partage notre histoire"}, {"titre": "Loi de Fisher", "text_origine": "En th\u00e9orie des probabilit\u00e9s et en statistiques, la loi de Fisher ou encore loi de Fisher-Snedecor ou encore loi F de Snedecor est une loi de probabilit\u00e9 continue,,. Elle tire son nom des statisticiens Ronald Aylmer Fisher et George Snedecor. \nLa loi de Fisher survient tr\u00e8s fr\u00e9quemment en tant que loi de la statistique de test lorsque l'hypoth\u00e8se nulle est vraie, dans des tests statistiques, comme les tests du ratio de vraisemblance, dans les tests de Chow utilis\u00e9s en \u00e9conom\u00e9trie, ou encore dans l'analyse de la variance (ANOVA) via le test de Fisher.", "element_cle": "1. La loi de Fisher est une loi de probabilit\u00e9 continue en th\u00e9orie des probabilit\u00e9s et en statistiques.\n2. Elle est nomm\u00e9e d'apr\u00e8s les statisticiens Ronald Aylmer Fisher et George Snedecor.\n3. La loi de Fisher est utilis\u00e9e fr\u00e9quemment en tant que loi de la statistique de test lorsque l'hypoth\u00e8se nulle est vraie.\n4. Elle est utilis\u00e9e dans des tests statistiques tels que les tests du ratio de vraisemblance, les tests de Chow en \u00e9conom\u00e9trie et l'analyse de la variance (ANOVA) via le test de Fisher.", "rap": "[Couplet 1]\nLa loi de Fisher, un pilier des stats,\nUne loi de probabilit\u00e9, t'inqui\u00e8tes pas,\nRonald Fisher, George Snedecor,\nLeurs noms grav\u00e9s dans l'histoire de l'or.\n\n[Couplet 2]\nDans le royaume des tests, elle est reine,\nQuand l'hypoth\u00e8se nulle est la plus sereine,\nRatio de vraisemblance, tests de Chow,\nANOVA, Fisher montre le chemin, tu sais.\n\n[Refrain]\nLa loi de Fisher, puissante et pr\u00e9cise,\nElle guide les statisticiens avec expertise,\nDes tests solides, des r\u00e9sultats pertinents,\nMerci Fisher pour ta contribution \u00e9vidente."}, {"titre": "Statistique multivari\u00e9e", "text_origine": "En statistique, les analyses multivari\u00e9es ont pour caract\u00e9ristique de s'int\u00e9resser \u00e0 des lois de probabilit\u00e9 \u00e0 plusieurs variables. Les analyses bivari\u00e9es sont des cas particuliers \u00e0 deux variables.\nLes analyses multivari\u00e9es sont tr\u00e8s diverses selon l'objectif recherch\u00e9, la nature des variables et la mise en \u0153uvre formelle. On peut identifier deux grandes familles : celle des m\u00e9thodes descriptives (visant \u00e0 structurer et r\u00e9sumer l'information) et celle des m\u00e9thodes explicatives visant \u00e0 expliquer une ou des variables dites \u00ab d\u00e9pendantes \u00bb (variables \u00e0 expliquer) par un ensemble de variables dites \u00ab ind\u00e9pendantes \u00bb (variables explicatives).\nLes m\u00e9thodes appel\u00e9es en fran\u00e7ais analyse des donn\u00e9es en sont un sous-ensemble.", "element_cle": "1. La statistique multivari\u00e9e \u00e9tudie les lois de probabilit\u00e9 impliquant plusieurs variables.\n2. Les analyses multivari\u00e9es peuvent \u00eatre bivari\u00e9es (deux variables) ou plus.\n3. Il existe deux grandes familles d'analyses multivari\u00e9es : les m\u00e9thodes descriptives et les m\u00e9thodes explicatives.\n4. Les m\u00e9thodes descriptives cherchent \u00e0 structurer et r\u00e9sumer les informations.\n5. Les m\u00e9thodes explicatives visent \u00e0 expliquer une ou plusieurs variables d\u00e9pendantes \u00e0 l'aide de variables explicatives.\n6. Les analyses de donn\u00e9es sont un sous-ensemble des m\u00e9thodes d'analyse multivari\u00e9e.", "rap": "[Couplet 1]\nJ'm'immerge dans l'\u00e9tude de la stat multivari\u00e9e\nPlusieurs variables, des lois d'probabilit\u00e9s\nBivari\u00e9es ou plus, l'analyse est pouss\u00e9e\nD\u00e9crire, expliquer, yeah, \u00e7a c'est fouett\u00e9\n\n[Refrain]\nStat multivari\u00e9e, c'est \u00e7a qu'j'fais bouger\nDes m\u00e9thodes descriptives aux m\u00e9thodes explicatives\nJ'vais tout structurer, tout r\u00e9sumer\nEt m\u00eame analyser les donn\u00e9es, c'est pas abusif\n\n[Couplet 2]\nJ'fais du rap \u00e9ducatif, j'te donne la mati\u00e8re\nLa statistique multivari\u00e9e, c'est la gal\u00e8re\nOn cherche \u00e0 tout comprendre, tout expliquer\nLes variables d\u00e9pendantes, les variables explicatives\n\n[Refrain]\nStat multivari\u00e9e, c'est \u00e7a qu'j'fais bouger\nDes m\u00e9thodes descriptives aux m\u00e9thodes explicatives\nJ'vais tout structurer, tout r\u00e9sumer\nEt m\u00eame analyser les donn\u00e9es, c'est pas abusif"}, {"titre": "Test de Breusch-Pagan", "text_origine": "En statistiques, le test de Breusch-Pagan permet de tester l'hypoth\u00e8se d'homosc\u00e9dasticit\u00e9 du terme d'erreur d'un mod\u00e8le de r\u00e9gression lin\u00e9aire. Il a \u00e9t\u00e9 propos\u00e9 par Trevor Breusch (en) et Adrian Pagan (en) dans un article publi\u00e9 en 1979 dans la revue Econometrica. Il cherche \u00e0 d\u00e9terminer la nature de la variance du terme d'erreurs : si la variance est constante, alors on a de l'homosc\u00e9dasticit\u00e9 ; en revanche, si elle varie, on a de l'h\u00e9t\u00e9rosc\u00e9dasticit\u00e9.\nPar exemple, on estime le mod\u00e8le suivant \n\n  \n    \n      \n        y\n        =\n        \n          \u03b2\n          \n            0\n          \n        \n        +\n        \n          \u03b2\n          \n            1\n          \n        \n        x\n        +\n        u\n      \n    \n    {\\displaystyle y=\\beta _{0}+\\beta _{1}x+u}\n  \net on obtient alors les valeurs r\u00e9siduelles : \n  \n    \n      \n        \n          \n            \n              u\n              ^\n            \n          \n        \n      \n    \n    {\\displaystyle {\\hat {u}}}\n  . Les moindres carr\u00e9s ordinaires (MCO) sont un estimateur faisant en sorte que la moyenne des r\u00e9sidus soit nulle. Ainsi, en supposant que la valeur des r\u00e9sidus ne d\u00e9pend pas des variables explicatives, on peut exprimer la variance des r\u00e9sidus comme la valeur au carr\u00e9 des r\u00e9sidus. Si cette hypoth\u00e8se n'est pas tenable, alors on pourrait par exemple exprimer la variance comme une relation lin\u00e9aire entre les r\u00e9sidus et les variables explicatives. Un mod\u00e8le de ce genre peut \u00eatre test\u00e9 en r\u00e9gressant les carr\u00e9s des r\u00e9sidus sur les variables explicatives en utilisant une \u00e9quation auxiliaire de la forme \n\n  \n    \n      \n        \n          \n            \n              \n                u\n                ^\n              \n            \n          \n          \n            2\n          \n        \n        =\n        \n          \u03b3\n          \n            0\n          \n        \n        +\n        \n          \u03b3\n          \n            1\n          \n        \n        x\n        +\n        v\n      \n    \n    {\\displaystyle {\\hat {u}}^{2}=\\gamma _{0}+\\gamma _{1}x+v}\n  .\nCeci est la base du test de Breusch-Pagan. C'est un test bas\u00e9 sur un test du \u03c7\u00b2 : si la statistique du test de Breusch-Pagan est sup\u00e9rieure \u00e0 celle obtenue par le test du Chi-Deux, c'est-\u00e0-dire si la p-value est inf\u00e9rieure \u00e0 un certain seuil (souvent 5 %), alors on rejette l'hypoth\u00e8se nulle d'homosc\u00e9dasticit\u00e9 avec un risque d'erreur de premi\u00e8re esp\u00e8ce de 5 % (si on a choisi ce seuil).\n\nUne des corrections possibles peut alors \u00eatre l'utilisation des moindres carr\u00e9s pond\u00e9r\u00e9s (si l'on conna\u00eet l'origine de l'h\u00e9t\u00e9rosc\u00e9dasticit\u00e9).", "element_cle": "de sur le mod\u00e8le de r\u00e9gression lin\u00e9aire pour d\u00e9tecter l'h\u00e9t\u00e9rosc\u00e9dasticit\u00e9 des r\u00e9sidus. Il a \u00e9t\u00e9 propos\u00e9 en 1979 par Breusch et Pagan et est largement utilis\u00e9 en \u00e9conom\u00e9trie. Le test cherche \u00e0 d\u00e9terminer si la variance des r\u00e9sidus est constante (homosc\u00e9dasticit\u00e9) ou si elle varie (h\u00e9t\u00e9rosc\u00e9dasticit\u00e9). Il repose sur l'estimation des r\u00e9sidus du mod\u00e8le et la r\u00e9gression de leurs carr\u00e9s sur les variables explicatives. Si la relation entre les carr\u00e9s des r\u00e9sidus et les variables explicatives est significative, cela indique la pr\u00e9sence d'h\u00e9t\u00e9rosc\u00e9dasticit\u00e9. Ce test est important car l'h\u00e9t\u00e9rosc\u00e9dasticit\u00e9 peut biaiser les estimations des coefficients du mod\u00e8le et invalider les tests d'inf\u00e9rence.", "rap": "[Couplet 1]\nYo, check, j'te parle d'un test crucial\nLe Breusch-Pagan, mec, c'est crucial\nEn 79, Breusch et Pagan l'ont cr\u00e9\u00e9\nPour d\u00e9tecter l'h\u00e9t\u00e9rosc\u00e9dasticit\u00e9\n\n[Couplet 2]\nL'\u00e9conom\u00e9trie, \u00e7a te parle peut-\u00eatre pas\nMais ce test, il est l\u00e0 pour \u00e7a\nIl cherche \u00e0 voir si les r\u00e9sidus varient\nOu si leur variance reste constante, sans d\u00e9vier\n\n[Refrain]\nBreusch-Pagan, un test essentiel\nPour l'h\u00e9t\u00e9rosc\u00e9dasticit\u00e9, il est tellement r\u00e9el\nIl \u00e9value la constance des r\u00e9sidus\nPour pas fausser les estimations, c'est crucial pour nous\n\n[Couplet 1]\nLes r\u00e9sidus, c'est les erreurs du mod\u00e8le\nLe test est l\u00e0 pour voir s'ils se rebelent\nOn estime ces r\u00e9sidus avec m\u00e9thode\nEt on fait une r\u00e9gression avec leurs carr\u00e9s, bien s\u00fbr que \u00e7a explose\n\n[Couplet 2]\nSi la relation est significative, \u00e7a veut dire quoi ?\nQue l'h\u00e9t\u00e9rosc\u00e9dasticit\u00e9 est l\u00e0, \u00e7a se voit\nEt \u00e7a peut biaiser les coefficients du mod\u00e8le\nInvalidant les tests, ouais mec, \u00e7a sent le d\u00e9g\u00e2ts\n\n[Refrain]\nBreusch-Pagan, un test essentiel\nPour l'h\u00e9t\u00e9rosc\u00e9dasticit\u00e9, il est tellement r\u00e9el\nIl \u00e9value la constance des r\u00e9sidus\nPour pas fausser les estimations, c'est crucial pour nous\n\n[Outro]\nDonc ouvre les yeux, mec, et comprends bien \u00e7a\nLe test de Breusch-Pagan, c'est du s\u00e9rieux, voil\u00e0\nEn \u00e9conom\u00e9trie, on prend pas \u00e7a \u00e0 la l\u00e9g\u00e8re\nCar les biais et les erreurs, \u00e7a peut tout foutre en l'air"}, {"titre": "Test de Wald", "text_origine": "Le test de Wald est un test param\u00e9trique \u00e9conom\u00e9trique dont l'appellation vient du math\u00e9maticien am\u00e9ricain d'origine hongroise Abraham Wald (31 octobre 1902-13 d\u00e9cembre 1950) avec une grande vari\u00e9t\u00e9 d'utilisations. Chaque fois que nous avons une relation au sein des ou entre les \u00e9l\u00e9ments de donn\u00e9es qui peuvent \u00eatre exprim\u00e9es comme un mod\u00e8le statistique avec des param\u00e8tres \u00e0 estimer, et tout cela \u00e0 partir d'un \u00e9chantillon, le test de Wald peut \u00eatre utilis\u00e9 pour \u00ab tester la vraie valeur du param\u00e8tre \u00bb bas\u00e9 sur l'estimation de l'\u00e9chantillon.", "element_cle": "1. Le test de Wald est un test param\u00e9trique \u00e9conom\u00e9trique.\n2. Abraham Wald est le math\u00e9maticien am\u00e9ricain d'origine hongroise qui a donn\u00e9 son nom au test.\n3. Le test de Wald a une grande vari\u00e9t\u00e9 d'utilisations.\n4. Il permet de tester la vraie valeur d'un param\u00e8tre bas\u00e9 sur l'estimation de l'\u00e9chantillon.\n5. Ce test peut \u00eatre utilis\u00e9 lorsque nous avons une relation au sein des donn\u00e9es avec des param\u00e8tres \u00e0 estimer.", "rap": "[Couplet 1]\nLe test de Wald, un outil puissant\nPour \u00e9valuer nos hypoth\u00e8ses de fa\u00e7on consciente\nUn test param\u00e9trique pour les \u00e9conom\u00e8tres\nAnalyser nos donn\u00e9es sans se tromper\n\nAbraham Wald, math\u00e9maticien de g\u00e9nie\nD'origine hongroise, il a tout compris\nSon nom reste grav\u00e9 dans l'histoire\nPour son apport au test, sa grande gloire\n\n[Refrain]\nLe test de Wald, un incontournable\nPour estimer les param\u00e8tres, c'est formidable\nDans diff\u00e9rentes situations, il est utilis\u00e9\nPour tester la vraie valeur, sans se tromper\n\n[Couplet 2]\nLe test de Wald, une polyvalence sans limite\nOn l'utilise dans diverses situations bien utiles\nEstimer la valeur d'un param\u00e8tre inconnu\nBas\u00e9 sur notre \u00e9chantillon, on sait comment faire\n\nCe test nous \u00e9claire sur la vraie valeur\nDes param\u00e8tres estim\u00e9s, avec rigueur\nQuand les donn\u00e9es montrent des relations\nLe test de Wald nous donne des indications\n\n[Refrain]\nLe test de Wald, un incontournable\nPour estimer les param\u00e8tres, c'est formidable\nDans diff\u00e9rentes situations, il est utilis\u00e9\nPour tester la vraie valeur, sans se tromper"}, {"titre": "Test de Kruskal-Wallis", "text_origine": "Le test de Kruskal-Wallis (d'apr\u00e8s William Kruskal et Wilson Allen Wallis), aussi appel\u00e9 ANOVA unidirectionnelle sur rangs (ou ANOVA \u00e0 un facteur contr\u00f4l\u00e9 sur rangs) est une m\u00e9thode non param\u00e9trique utilis\u00e9e pour tester si des \u00e9chantillons trouvent leur origine dans la m\u00eame distribution,,. Ce test s'int\u00e9resse aux m\u00e9dianes de \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n   populations (\n  \n    \n      \n        k\n        \u2a7e\n        3\n      \n    \n    {\\displaystyle k\\geqslant 3}\n  ) (ou treatment dans la litt\u00e9rature en anglais) et propose comme hypoth\u00e8se nulle que les \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n   \u00e9chantillons sont confondus et proviennent d'un m\u00eame \u00e9chantillon (combin\u00e9) d'une population. Le test permet de comparer deux ou plusieurs \u00e9chantillons ind\u00e9pendants de taille similaire ou non. Il g\u00e9n\u00e9ralise le  test de Wilcoxon-Mann-Whitney, qui est utilis\u00e9 pour comparer seulement deux groupes. L'\u00e9quivalent param\u00e9trique du test de Kruskal-Wallis est l'analyse unidirectionnelle de la variance (ANOVA).\nUn test de Kruskal-Wallis significatif indique qu'au moins un \u00e9chantillon domine stochastiquement un autre \u00e9chantillon. Le test n'identifie pas o\u00f9 cette dominance stochastique se produit ni pour combien de paires de groupes la dominance stochastique s'obtient. Pour analyser les paires d'\u00e9chantillons sp\u00e9cifiques en vue de d\u00e9terminer la dominance stochastique, on utilise parfois le test de Dunn, les tests de Mann-Whitney par paires sans correction de Bonferroni ou encore le test de Conover-Iman, plus puissant mais moins connu.\nComme il s'agit d'une m\u00e9thode non param\u00e9trique, le test de Kruskal-Wallis ne suppose pas une distribution normale des r\u00e9sidus, contrairement \u00e0 l'analyse de variance \u00e0 sens unique analogue. Si le chercheur peut faire l'hypoth\u00e8se d'une distribution de forme et d'\u00e9chelle identiques pour tous les groupes, \u00e0 l'exception de toute diff\u00e9rence dans les m\u00e9dianes, alors l'hypoth\u00e8se nulle est que les m\u00e9dianes de tous les groupes sont \u00e9gales, et l'hypoth\u00e8se alternative est qu'au moins une m\u00e9diane de la population d'un groupe est diff\u00e9rente de la m\u00e9diane de la population d'au moins un autre groupe.", "element_cle": "1. Le test de Kruskal-Wallis est une m\u00e9thode non param\u00e9trique utilis\u00e9e pour tester si des \u00e9chantillons trouvent leur origine dans la m\u00eame distribution.\n2. Ce test compare les m\u00e9dianes de k populations et propose comme hypoth\u00e8se nulle que les \u00e9chantillons sont confondus et proviennent d'un m\u00eame \u00e9chantillon d'une population.\n3. Le test de Kruskal-Wallis permet de comparer deux ou plusieurs \u00e9chantillons ind\u00e9pendants de taille similaire ou non.\n4. Il g\u00e9n\u00e9ralise le test de Wilcoxon-Mann-Whitney, qui compare seulement deux groupes.\n5. Le test de Kruskal-Wallis est l'\u00e9quivalent non param\u00e9trique de l'analyse de variance (ANOVA).\n6. Un r\u00e9sultat significatif indique qu'au moins un \u00e9chantillon domine stochastiquement un autre \u00e9chantillon.\n7. Le test ne permet pas de d\u00e9terminer o\u00f9 cette dominance se produit ni pour combien de paires de groupes elle est obtenue.\n8. Pour analyser les paires d'\u00e9chantillons sp\u00e9cifiques, d'autres tests comme le test de Dunn ou le test de Conover-Iman peuvent \u00eatre utilis\u00e9s.\n9. Contrairement \u00e0 l'ANOVA, le test de Kruskal-Wallis ne suppose pas une distribution normale des r\u00e9sidus.\n10. Il est bas\u00e9 sur l'hypoth\u00e8se que les m\u00e9dianes de tous les groupes sont \u00e9gales, avec des diff\u00e9rences \u00e9ventuelles dans les formes et \u00e9chelles de distribution.", "rap": "[Couplet 1]\nLe test de Kruskal-Wallis, une m\u00e9thode non param\u00e9trique\nPour v\u00e9rifier si les \u00e9chantillons ont la m\u00eame origine magique\nOn compare les m\u00e9dianes de k populations\nPour savoir si les groupes sont confondus dans l'union\n\n[Refrain]\nKruskal-Wallis, c'est le test qui nous guide\nOn analyse les diff\u00e9rences, on fait pas de rides\nLes \u00e9chantillons, ils sont ind\u00e9pendants\nOn cherche \u00e0 comprendre, \u00e0 \u00eatre comp\u00e9tents\n\n[Couplet 2]\nCe test, il est puissant et versatile\nIl peut comparer deux groupes ou plus, c'est pas facile\nIl \u00e9tend la port\u00e9e du test de Wilcoxon-Mann-Whitney\nEt nous offre des r\u00e9sultats toujours bien pr\u00e9cis et justes\n\n[Refrain]\nKruskal-Wallis, c'est le test qui nous guide\nOn analyse les diff\u00e9rences, on fait pas de rides\nLes \u00e9chantillons, ils sont ind\u00e9pendants\nOn cherche \u00e0 comprendre, \u00e0 \u00eatre comp\u00e9tents\n\n[Outro]\nAlors n'oublie pas, le test de Kruskal-Wallis\nC'est l'\u00e9quivalent non param\u00e9trique de l'ANOVA, c'est pas du fait-maison\nIl nous \u00e9vite de faire des suppositions sur la distribution des r\u00e9sidus\nPour des r\u00e9sultats fiables, on est toujours \u00e0 l'isus"}, {"titre": "Fonction de hachage", "text_origine": "Quand il s'agit de mettre dans un tableau de taille raisonnable (typiquement r\u00e9sidant dans la m\u00e9moire principale de l'ordinateur) un ensemble de donn\u00e9es de taille variable et arbitraire, on utilise une fonction de hachage pour  attribuer \u00e0 ces donn\u00e9es des indices de ce tableau. Par cons\u00e9quent, \nune fonction de hachage est une fonction qui associe des valeurs de taille fixe \u00e0 des donn\u00e9es de taille quelconque. Les valeurs renvoy\u00e9es par une fonction de hachage sont appel\u00e9es valeurs de hachage, codes de hachage, r\u00e9sum\u00e9s, signatures ou simplement hachages. Les valeurs sont g\u00e9n\u00e9ralement utilis\u00e9es pour \u00eatre les indices d'une table de taille raisonnable appel\u00e9e table de hachage. Le hachage ou adressage de stockage dispers\u00e9 est donc l'utilisation d'une fonction de hachage pour cr\u00e9er les indices d'une table de hachage.\nLes fonctions de hachage sont utilis\u00e9es dans les applications de stockage et d'indexation de donn\u00e9es pour acc\u00e9der aux donn\u00e9es en un temps r\u00e9duit, en fait quasi-constant. Elles requi\u00e8rent un espace de stockage \u00e0 peine plus grand que l'espace total requis pour les donn\u00e9es. Ainsi, le hachage est une forme d'acc\u00e8s aux donn\u00e9es efficace en termes de calcul et d'espace de stockage.\nL'int\u00e9r\u00eat des fonctions de hachage repose sur de bonnes propri\u00e9t\u00e9s statistiques. En effet, le comportement dans le pire des cas est mauvais, mais il se manifeste avec une probabilit\u00e9 extr\u00eamement faible, en fait n\u00e9gligeable, et le comportement dans le cas moyen est optimal (collision minimale ).\n\nLes fonctions de hachage sont li\u00e9es (et souvent confondues avec) les sommes de contr\u00f4le, les cl\u00e9s de contr\u00f4le, les empreintes num\u00e9riques, la  compression avec perte, les g\u00e9n\u00e9rateurs de nombres al\u00e9atoires, les codes correcteur et les chiffrements. Bien que les concepts se chevauchent dans une certaine mesure, chacun a ses propres utilisations et exigences et est con\u00e7u et optimis\u00e9 diff\u00e9remment. La fonction de hachage diff\u00e8re de ces concepts principalement en termes d'int\u00e9grit\u00e9 (cryptographie)", "element_cle": "1. Une fonction de hachage attribue des indices \u00e0 un tableau de donn\u00e9es de taille variable.\n2. Les valeurs renvoy\u00e9es par une fonction de hachage sont appel\u00e9es hachages.\n3. Les hachages sont utilis\u00e9s comme indices dans une table de hachage.\n4. Les fonctions de hachage permettent un acc\u00e8s rapide et efficace aux donn\u00e9es.\n5. Le hachage n\u00e9cessite peu d'espace de stockage par rapport aux donn\u00e9es.\n6. Les fonctions de hachage ont de bonnes propri\u00e9t\u00e9s statistiques.\n7. Les collisions (cas o\u00f9 deux donn\u00e9es ont le m\u00eame hachage) sont rares en pratique.\n8. Les fonctions de hachage sont diff\u00e9rentes des sommes de contr\u00f4le et des chiffrements, bien qu'elles aient des utilisations similaires.\n9. La fonction de hachage garantit l'int\u00e9grit\u00e9 des donn\u00e9es dans le contexte de la cryptographie.\n10. Les fonctions de hachage sont optimis\u00e9es et con\u00e7ues de mani\u00e8re sp\u00e9cifique pour leur utilisation.", "rap": "[Couplet 1]\nYo, laisse-moi t'expliquer la fonction de hachage\nUn concept essentiel pour tes donn\u00e9es de stockage\nUne fonction attribue des indices, c'est vital\nDans un tableau pour des donn\u00e9es de taille variable\n\nLes valeurs renvoy\u00e9es ? Ce sont les hachages\nDes cl\u00e9s uniques, tu peux les stocker en vrac\nIls servent d'indices dans une table de hachage\nUn acc\u00e8s rapide et efficace, c'est du lourd, mec\n\nLe hachage, c'est l'\u00e9conomie d'espace de stockage\nComparer aux donn\u00e9es, c'est du grand carnage\nEt niveau statistiques, elles sont au top\nDes propri\u00e9t\u00e9s s\u00fbres, elles ne font aucun flop\n\n[Refrain]\nFonction de hachage, c'est du s\u00e9rieux\nPour tes donn\u00e9es, c'est vraiment pr\u00e9cieux\nGarantir l'int\u00e9grit\u00e9, dans la crypto-crypt\u00e9\nOptimis\u00e9es et con\u00e7ues pour \u00eatre exploit\u00e9es\n\n[Couplet 2]\nLes collisions ? Elles sont rares en pratique\nDeux donn\u00e9es m\u00eame hachage, pas de panique\nDiff\u00e9rentes des sommes de contr\u00f4le et chiffrements\nMais des utilisations similaires, c'est clair et net\n\nDans le domaine de la crypto, c'est vital\nLa fonction de hachage garantit l'int\u00e9gralit\u00e9\nTes donn\u00e9es sont prot\u00e9g\u00e9es, fiabilit\u00e9 assur\u00e9e\nOn parle pas de trucs bidon, on est s\u00e9rieux, man\n\nLes fonctions de hachage sont sp\u00e9cifiquement con\u00e7ues\nOptimis\u00e9es pour leur utilisation, mon pote, tu l'as vu\nAlors retiens bien ces concepts \u00e9ducatifs\nDans le monde du rap, on fait toujours explosif\n\n[Refrain]\nFonction de hachage, c'est du s\u00e9rieux\nPour tes donn\u00e9es, c'est vraiment pr\u00e9cieux\nGarantir l'int\u00e9grit\u00e9, dans la crypto-crypt\u00e9\nOptimis\u00e9es et con\u00e7ues pour \u00eatre exploit\u00e9es"}, {"titre": "Test de White", "text_origine": "En statistique, le test de White est un test statistique qui teste si la variance des erreurs d'un mod\u00e8le de r\u00e9gression est constante (homosc\u00e9dasticit\u00e9).\nLe test a \u00e9t\u00e9 propos\u00e9 par Halbert White en 1980 et est d\u00e9sormais \u00e9norm\u00e9ment utilis\u00e9, faisant de cet article l'un des plus cit\u00e9s en \u00e9conomie .\nSi jamais le test de White est statistiquement significatif, l'h\u00e9t\u00e9rosc\u00e9dasticit\u00e9 peut ne pas en \u00eatre la cause. Le probl\u00e8me peut en effet venir d'une erreur de sp\u00e9cification. Le test de White peut donc \u00eatre un test d'h\u00e9t\u00e9rosc\u00e9dasticit\u00e9 (si aucun terme crois\u00e9 n'est introduit dans la proc\u00e9dure) ou de sp\u00e9cification, ou les deux \u00e0 la fois (si les termes crois\u00e9s sont introduits dans la proc\u00e9dure). Cependant, cette plus grande g\u00e9n\u00e9ralit\u00e9 fait qu'il est moins puissant que d'autres tests d'h\u00e9t\u00e9rosc\u00e9dasticit\u00e9, comme ceux de  Breusch-Pagan et de  Goldfeld et Quandt.", "element_cle": "1. Le test de White est un test statistique utilis\u00e9 en statistique pour tester si la variance des erreurs d'un mod\u00e8le de r\u00e9gression est constante.\n2. Le test a \u00e9t\u00e9 propos\u00e9 par Halbert White en 1980 et est largement utilis\u00e9 en \u00e9conomie.\n3. Le test de White peut \u00eatre utilis\u00e9 pour tester l'h\u00e9t\u00e9rosc\u00e9dasticit\u00e9 ou l'erreur de sp\u00e9cification d'un mod\u00e8le de r\u00e9gression.\n4. Si le test de White est statistiquement significatif, cela ne signifie pas n\u00e9cessairement que l'h\u00e9t\u00e9rosc\u00e9dasticit\u00e9 en est la cause.\n5. Les termes crois\u00e9s peuvent \u00eatre introduits dans la proc\u00e9dure du test de White, ce qui en fait un test d'h\u00e9t\u00e9rosc\u00e9dasticit\u00e9 et de sp\u00e9cification simultan\u00e9ment.", "rap": "[Couplet 1]\nLe test de White, c'est du s\u00e9rieux, mon ami\nEn statistique, un outil qui pointe les erreurs infamies\nIl v\u00e9rifie si la variance de tes r\u00e9sidus est constante\nDans tes mod\u00e8les de r\u00e9gression, il est ton garant\n\nHalbert White, en 1980, a propos\u00e9 ce test v\u00e9n\u00e9r\u00e9\nUtilis\u00e9 \u00e0 foison dans l'\u00e9conomie pour pr\u00e9dire\nSi ton mod\u00e8le a des erreurs sp\u00e9cifi\u00e9es incorrectes\nLe test de White, t'\u00e9claire et les corrige en un \u00e9clair\n\n[Refrain]\nLe test de White, dans les chiffres il r\u00e9sonne\nPour l'\u00e9conomie, un must, un son qui raisonne\nIl d\u00e9tecte l'h\u00e9t\u00e9rosc\u00e9dasticit\u00e9 et la sp\u00e9cification\nUn alli\u00e9, un guide pour une juste pr\u00e9diction\n\n[Couplet 2]\nAttention, mon pote, une signification statistique\nNe signifie pas que l'h\u00e9t\u00e9rosc\u00e9dasticit\u00e9 est leur unique musique\nLe test de White, il pointe du doigt les indices\nMais \u00e0 toi d'analyser les causes et les cons\u00e9quences\n\nSi tu veux aller plus loin, introduis des termes crois\u00e9s\nLe test de White devient une arme pour balayer\nL'h\u00e9t\u00e9rosc\u00e9dasticit\u00e9 et les erreurs de sp\u00e9cification\nUn double impact pour une analyse en perfection\n\n[Refrain]\nLe test de White, dans les chiffres il r\u00e9sonne\nPour l'\u00e9conomie, un must, un son qui raisonne\nIl d\u00e9tecte l'h\u00e9t\u00e9rosc\u00e9dasticit\u00e9 et la sp\u00e9cification\nUn alli\u00e9, un guide pour une juste pr\u00e9diction"}, {"titre": "M\u00e9thode des moindres carr\u00e9s", "text_origine": "La m\u00e9thode des moindres carr\u00e9s, ind\u00e9pendamment \u00e9labor\u00e9e par Legendre et Gauss au d\u00e9but du XIXe si\u00e8cle, permet de comparer des donn\u00e9es exp\u00e9rimentales, g\u00e9n\u00e9ralement entach\u00e9es d\u2019erreurs de mesure, \u00e0 un mod\u00e8le math\u00e9matique cens\u00e9 d\u00e9crire ces donn\u00e9es.\nCe mod\u00e8le peut prendre diverses formes. Il peut s\u2019agir de lois de conservation que les quantit\u00e9s mesur\u00e9es doivent respecter. La m\u00e9thode des moindres carr\u00e9s permet alors de minimiser l\u2019impact des erreurs exp\u00e9rimentales en \u00ab ajoutant de l\u2019information \u00bb dans le processus de mesure.", "element_cle": "1. La m\u00e9thode des moindres carr\u00e9s a \u00e9t\u00e9 d\u00e9velopp\u00e9e par Legendre et Gauss au d\u00e9but du XIXe si\u00e8cle.\n2. Elle permet de comparer des donn\u00e9es exp\u00e9rimentales \u00e0 un mod\u00e8le math\u00e9matique.\n3. Le mod\u00e8le peut \u00eatre une loi de conservation ou une autre forme math\u00e9matique.\n4. La m\u00e9thode des moindres carr\u00e9s minimise l'impact des erreurs exp\u00e9rimentales.\n5. Elle permet d'ajouter de l'information dans le processus de mesure.", "rap": "[Couplet 1]\nLa m\u00e9thode des moindres carr\u00e9s, invent\u00e9e au XIXe,\nPar Legendre et Gauss, un duo hors-pair,\nElle nous permet de comparer, d'analyser,\nLes donn\u00e9es exp\u00e9rimentales pour mieux avancer.\n\n[Refrain]\nLes moindres carr\u00e9s, une m\u00e9thode de pr\u00e9cision,\nPour comprendre le monde \u00e0 l'\u00e9chelle du million,\nDes \u00e9quations, des courbes, des mod\u00e8les math\u00e9matiques,\nLes moindres carr\u00e9s, un outil scientifique.\n\n[Couplet 2]\nOn peut l'utiliser pour un mod\u00e8le de conservation,\nOu pour toute autre forme math\u00e9matique en action,\nElle minimise les erreurs, les variations,\nPour obtenir des r\u00e9sultats sans aucune d\u00e9formation.\n\n[Refrain]\nLes moindres carr\u00e9s, une technique fiable,\nPour \u00e9viter les \u00e9carts, les r\u00e9sultats instables,\nOn ajoute de l'information, on affine les mesures,\nLes moindres carr\u00e9s, un pilier de la recherche pure.\n\nNote: Le format impos\u00e9 du texte rap court rend difficile de d\u00e9velopper davantage les notions \u00e9ducatives."}, {"titre": "Corr\u00e9lation (statistiques)", "text_origine": "En probabilit\u00e9s et en statistique, la corr\u00e9lation entre plusieurs variables al\u00e9atoires ou statistiques est une notion de liaison qui contredit leur ind\u00e9pendance.\nCette corr\u00e9lation est tr\u00e8s souvent r\u00e9duite \u00e0 la corr\u00e9lation lin\u00e9aire entre variables quantitatives, c\u2019est-\u00e0-dire l\u2019ajustement d\u2019une variable par rapport \u00e0 l\u2019autre par une relation affine obtenue par r\u00e9gression lin\u00e9aire. Pour cela, on calcule un coefficient de corr\u00e9lation lin\u00e9aire, quotient de leur covariance par le produit de leurs \u00e9carts types. Son signe indique si des valeurs plus hautes de l\u2019une correspondent \u00ab en moyenne \u00bb \u00e0 des valeurs plus hautes ou plus basses pour l\u2019autre. La valeur absolue du coefficient, toujours comprise entre 0 et 1, ne mesure pas l\u2019intensit\u00e9 de la liaison mais la pr\u00e9pond\u00e9rance de la relation affine sur les variations internes des variables. Un coefficient nul n\u2019implique pas l'ind\u00e9pendance, car d\u2019autres types de corr\u00e9lation sont possibles.\nD\u2019autres indicateurs permettent de calculer un coefficient de corr\u00e9lation pour des variables ordinales.\nLe fait que deux variables soient \u00ab fortement corr\u00e9l\u00e9es \u00bb ne d\u00e9montre pas qu'il y ait une relation de causalit\u00e9 entre l'une et l'autre. Le contre-exemple le plus typique est celui o\u00f9 elles sont en fait li\u00e9es par une causalit\u00e9 commune. Cette confusion est connue sous l'expression Cum hoc ergo propter hoc.", "element_cle": "1. La corr\u00e9lation est une notion de liaison entre variables al\u00e9atoires ou statistiques qui contredit leur ind\u00e9pendance.\n2. La corr\u00e9lation lin\u00e9aire entre variables quantitatives est souvent r\u00e9duite \u00e0 l'ajustement d'une variable par rapport \u00e0 l'autre par une relation affine obtenue par r\u00e9gression lin\u00e9aire.\n3. Le coefficient de corr\u00e9lation lin\u00e9aire mesure la pr\u00e9pond\u00e9rance de la relation affine sur les variations internes des variables.\n4. Un coefficient nul de corr\u00e9lation n'implique pas l'ind\u00e9pendance, car d'autres types de corr\u00e9lation sont possibles.\n5. La corr\u00e9lation ne d\u00e9montre pas la causalit\u00e9 entre deux variables, car elles peuvent \u00eatre li\u00e9es par une causalit\u00e9 commune.", "rap": "[Couplet 1]\nLa corr\u00e9lation, c'est l'essence m\u00eame des stats\nLiaison entre variables, tout est dans le contrat\nInd\u00e9pendance, c'est pas toujours le cas\nLa corr\u00e9lation contredit, c'est un fait\n\n[Refrain]\nOn parle de stats, de relations craz'\nCorr\u00e9lation lin\u00e9aire, distingue le vrai\nAjustement d'une variable, dans cet \u00e9garement\nR\u00e9gression lin\u00e9aire, pour un lien persistant\n\n[Couplet 2]\nLe coefficient de corr\u00e9lation, il mesure tout \u00e7a\nPr\u00e9pond\u00e9rance de la relation, il en a\nSur les variations internes, il a son bras\nLes variables bougent, mais sont li\u00e9es par l\u00e0\n\n[Refrain]\nLa corr\u00e9lation, c'est pas la causalit\u00e9\nElles peuvent \u00eatre li\u00e9es, par une autre r\u00e9alit\u00e9\nLe coefficient nul, ne veut pas tout dire\nD'autres types de corr\u00e9lation peuvent \u00eatre \u00e0 d\u00e9finir\n\n[Outro]\nCorr\u00e9lation et stats, faut pas les confondre\nCausalit\u00e9, c'est autre chose \u00e0 comprendre\nOn analyse les donn\u00e9es, on cherche la v\u00e9rit\u00e9\nLa corr\u00e9lation, c'est juste un \u00e9clat de l'\u00e9quit\u00e9"}, {"titre": "Corr\u00e9lation de Spearman", "text_origine": "En statistique, la corr\u00e9lation de Spearman ou rho de Spearman, nomm\u00e9e d'apr\u00e8s Charles Spearman (1863-1945) et souvent not\u00e9e par la lettre grecque \n  \n    \n      \n        \u03c1\n      \n    \n    {\\displaystyle \\rho }\n   (rho) ou \n  \n    \n      \n        \n          r\n          \n            s\n          \n        \n      \n    \n    {\\displaystyle r_{s}}\n   est une mesure de d\u00e9pendance statistique non param\u00e9trique entre deux variables.\nLa corr\u00e9lation de Spearman est \u00e9tudi\u00e9e lorsque deux variables statistiques semblent corr\u00e9l\u00e9es sans que la relation entre les deux variables soit de type affine. Elle consiste \u00e0 trouver un coefficient de corr\u00e9lation, non pas entre les valeurs prises par les deux variables mais entre les rangs de ces valeurs. Elle estime \u00e0 quel point la relation entre deux variables peut \u00eatre d\u00e9crite par une fonction monotone. S'il n'y a pas de donn\u00e9es r\u00e9p\u00e9t\u00e9es, une corr\u00e9lation de Spearman parfaite de +1 ou -1 est obtenue quand l'une des variables est une fonction monotone parfaite de l'autre.", "element_cle": "1. La corr\u00e9lation de Spearman est une mesure de d\u00e9pendance statistique non param\u00e9trique entre deux variables.\n2. Elle a \u00e9t\u00e9 nomm\u00e9e d'apr\u00e8s Charles Spearman (1863-1945).\n3. Cette corr\u00e9lation est utilis\u00e9e lorsque deux variables semblent corr\u00e9l\u00e9es sans qu'il y ait une relation affine entre elles.\n4. Elle repose sur le classement des valeurs des variables plut\u00f4t que sur les valeurs elles-m\u00eames.\n5. La corr\u00e9lation de Spearman permet d'estimer \u00e0 quel point la relation entre deux variables peut \u00eatre d\u00e9crite par une fonction monotone.", "rap": "[Couplet 1]\nLa corr\u00e9lation de Spearman, c'est du lourd\nUne mesure statistique dont la valeur est d'or\nElle lie deux variables sans relation lin\u00e9aire\nUn outil puissant, \u00e7a faut pas le n\u00e9gliger\n\nNomme d'apr\u00e8s Charles Spearman, un grand scientifique\nQui a marqu\u00e9 son temps, son g\u00e9nie est caract\u00e9ristique\nN\u00e9 en 1863, parti en 1945\nSon h\u00e9ritage est l\u00e0, il nous guide dans nos \u00e9crits\n\n[Refrain]\nLa corr\u00e9lation de Spearman, on l'utilise bien\nPour comprendre les liens entre deux variables, c'est serein\nAvec leur classement, leurs valeurs sans \u00e9quivoque\nOn \u00e9value la relation, c'est comme lire entre les lignes, mec\n\n[Couplet 2]\nQuand les variables semblent corr\u00e9l\u00e9es sans lien direct\nLa corr\u00e9lation de Spearman entre en effet\nElle se base sur le rang des valeurs, pas juste leur grandeur\nUn vrai game changer, elle est pas dans la douleur\n\nElle nous permet d'estimer, de quantifier\n\u00c0 quel point la relation peut \u00eatre d\u00e9finie\nPar une fonction monotone, une courbe non lin\u00e9aire\nTout en gardant une coh\u00e9rence exemplaire\n\n[Refrain]\nLa corr\u00e9lation de Spearman, c'est une p\u00e9pite\nPour explorer les relations, \u00e7a met tout le monde \u00e0 la f\u00eate\nAvec son approche non param\u00e9trique, elle est unique\nElle nous aide \u00e0 comprendre, \u00e0 apprendre, c'est v\u00e9ridique"}, {"titre": "Coefficient de d\u00e9termination", "text_origine": "En statistique, le coefficient de d\u00e9termination lin\u00e9aire de Pearson, not\u00e9 R2 ou r2, est une mesure de la qualit\u00e9 de la pr\u00e9diction d'une r\u00e9gression lin\u00e9aire. \nIl est d\u00e9fini par[r\u00e9f. n\u00e9cessaire] :\n\n  \n    \n      \n        \n          R\n          \n            2\n          \n        \n        =\n        1\n        \u2212\n        \n          \n            \n              \n                \n                  \u2211\n                  \n                    i\n                    =\n                    1\n                  \n                  \n                    n\n                  \n                \n                \n                  \n                    (\n                    \n                      \n                        y\n                        \n                          i\n                        \n                      \n                      \u2212\n                      \n                        \n                          \n                            \n                              y\n                              \n                                i\n                              \n                            \n                            ^\n                          \n                        \n                      \n                    \n                    )\n                  \n                  \n                    2\n                  \n                \n              \n              \n                \n                  \u2211\n                  \n                    i\n                    =\n                    1\n                  \n                  \n                    n\n                  \n                \n                \n                  \n                    (\n                    \n                      \n                        y\n                        \n                          i\n                        \n                      \n                      \u2212\n                      \n                        \n                          \n                            y\n                            \u00af\n                          \n                        \n                      \n                    \n                    )\n                  \n                  \n                    2\n                  \n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle R^{2}=1-{\\dfrac {\\sum _{i=1}^{n}\\left(y_{i}-{\\hat {y_{i}}}\\right)^{2}}{\\sum _{i=1}^{n}\\left(y_{i}-{\\bar {y}}\\right)^{2}}}}\n  o\u00f9 n est le nombre de mesures, \n  \n    \n      \n        \n          y\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle y_{i}}\n   la valeur de la mesure no i, \n  \n    \n      \n        \n          \n            \n              \n                y\n                \n                  i\n                \n              \n              ^\n            \n          \n        \n      \n    \n    {\\displaystyle {\\hat {y_{i}}}}\n   la valeur pr\u00e9dite correspondante et \n  \n    \n      \n        \n          \n            \n              y\n              \u00af\n            \n          \n        \n      \n    \n    {\\displaystyle {\\bar {y}}}\n   la moyenne des mesures.", "element_cle": "- Le coefficient de d\u00e9termination lin\u00e9aire de Pearson est utilis\u00e9 en statistique pour \u00e9valuer la qualit\u00e9 d'une pr\u00e9diction d'une r\u00e9gression lin\u00e9aire.\n- Il est not\u00e9 R2 ou r2 et est d\u00e9fini par une formule math\u00e9matique.\n- La formule implique la somme des carr\u00e9s des \u00e9carts entre les valeurs pr\u00e9dites et les valeurs r\u00e9elles.\n- La formule utilise \u00e9galement la moyenne des valeurs r\u00e9elles.\n- Le coefficient de d\u00e9termination varie entre 0 et 1, o\u00f9 1 indique une pr\u00e9diction parfaite.\n- Le coefficient de d\u00e9termination est une mesure importante pour \u00e9valuer la validit\u00e9 d'un mod\u00e8le de r\u00e9gression lin\u00e9aire.", "rap": "[Couplet 1]\nDans les statistiques j'excelle, j'd\u00e9termine les pr\u00e9visions\nJ'suis le compositeur, j'ai l'art des d\u00e9ductions\nLe coefficient de d\u00e9termination, R2, ou r2\nC'est mon indicateur pour juger du juste et du faux\nJ'calcule la qualit\u00e9 d'une r\u00e9gression lin\u00e9aire\nEn comparant valeurs pr\u00e9dites et valeurs r\u00e9elles\n\n[Refrain]\nLe coefficient de d\u00e9termination, c'est mon outil de pr\u00e9diction\nEntre 0 et 1, j'fais l'\u00e9valuation des solutions\nJ'suis l'homme des chiffres, j'analyse avec pr\u00e9cision\nLe R2, c'est ma marque, ma passion, ma mission\n\n[Couplet 2]\nJ'additionne les carr\u00e9s des \u00e9carts, j'te donne des chiffres\nPour t'r\u00e9v\u00e9ler la justesse d'mon mod\u00e8le, sans \u00e9quivoque\nJ'utilise la moyenne des valeurs r\u00e9elles, j'compare\nLes pr\u00e9dictions \u00e0 la r\u00e9alit\u00e9, pour tout mettre au clair\nSi j'obtiens un 1, c'est une pr\u00e9diction parfaite\nMon mod\u00e8le est valide, aucun doute qui me freine\n\n[Refrain]\nLe coefficient de d\u00e9termination, c'est mon outil de pr\u00e9diction\nEntre 0 et 1, j'fais l'\u00e9valuation des solutions\nJ'suis l'homme des chiffres, j'analyse avec pr\u00e9cision\nLe R2, c'est ma marque, ma passion, ma mission"}, {"titre": "\u00c9cart type", "text_origine": "En math\u00e9matiques, l\u2019\u00e9cart type (aussi orthographi\u00e9 \u00e9cart-type) est une mesure de la dispersion des valeurs d'un \u00e9chantillon statistique ou d'une distribution de probabilit\u00e9. Il est d\u00e9fini comme la racine carr\u00e9e de la variance ou, de mani\u00e8re \u00e9quivalente, comme la moyenne quadratique des \u00e9carts par rapport \u00e0 la moyenne. Il se note en g\u00e9n\u00e9ral avec la lettre grecque \u03c3 (\u00ab sigma \u00bb), d\u2019apr\u00e8s l\u2019appellation standard deviation en anglais. Il est homog\u00e8ne \u00e0 la variable mesur\u00e9e.\nLes \u00e9carts types sont rencontr\u00e9s dans tous les domaines o\u00f9 sont appliqu\u00e9es les probabilit\u00e9s et la statistique, en particulier dans le domaine des sondages, en physique, en biologie ou dans la finance. Ils permettent en g\u00e9n\u00e9ral de synth\u00e9tiser les r\u00e9sultats num\u00e9riques d'une exp\u00e9rience r\u00e9p\u00e9t\u00e9e. Tant en probabilit\u00e9s qu'en statistique, il sert \u00e0 l'expression d'autres notions importantes comme le coefficient de corr\u00e9lation, le coefficient de variation ou la r\u00e9partition optimale de Neyman.\nQuand l'\u00e9cart type d'une population est inconnu, sa valeur est approch\u00e9e \u00e0 l'aide d'estimateurs.", "element_cle": "1. L'\u00e9cart type est une mesure de la dispersion des valeurs d'un \u00e9chantillon statistique ou d'une distribution de probabilit\u00e9.\n2. Il est d\u00e9fini comme la racine carr\u00e9e de la variance ou comme la moyenne quadratique des \u00e9carts par rapport \u00e0 la moyenne.\n3. Il est not\u00e9 g\u00e9n\u00e9ralement par la lettre grecque \u03c3 (\u00ab sigma \u00bb).\n4. L'\u00e9cart type est utilis\u00e9 dans de nombreux domaines, tels que les sondages, la physique, la biologie ou la finance.\n5. Il permet de synth\u00e9tiser les r\u00e9sultats num\u00e9riques d'une exp\u00e9rience r\u00e9p\u00e9t\u00e9e. \n6. En probabilit\u00e9s et en statistique, il est li\u00e9 \u00e0 d'autres notions importantes, comme le coefficient de corr\u00e9lation ou de variation.\n7. Quand l'\u00e9cart type d'une population est inconnu, on estime sa valeur \u00e0 l'aide d'estimateurs.", "rap": "[Couplet 1]\nL'\u00e9cart type, c'est la dispersion des valeurs \nUn concept statistique, qui donne le ton, qui s'\u00e9tale\nIl mesure la variance, la moyenne des \u00e9carts\nNot\u00e9 sigma, dans les calculs, il est un partenaire\n\nUtilis\u00e9 dans plein de domaines, physiques, sondages\nBiologie, finance, il est l\u00e0 dans tous les codes\nSynth\u00e9tise les r\u00e9sultats des exp\u00e9riences r\u00e9p\u00e9t\u00e9es\nUn indicateur pr\u00e9cis pour l'analyse effectu\u00e9e\n\n[Refrain]\nL'\u00e9cart type, dans les calculs, il est roi\nUn outil essentiel pour comprendre les lois\nDans les probabilit\u00e9s, il est li\u00e9 \u00e0 d'autres notions\nOn l'utilise partout, sans aucune restriction\n\n[Couplet 2]\nEn stats et probas, il est vital, essentiel\nCorr\u00e9lation, variation, il joue dans le panel\nQuand l'\u00e9cart type est inconnu, on l'estime avec des estimateurs\nUn peu de maths, une formule, et voil\u00e0 l'erreur corrig\u00e9e\n\nAlors n'oublie pas, l'\u00e9cart type \u00e7a compte\nDans le monde des chiffres, c'est un compte-goutte\nIl illumine les r\u00e9sultats, les rend plus clairs\nUn rep\u00e8re, une boussole, pour mieux s'y retrouver\n\n[Refrain]\nL'\u00e9cart type, dans les calculs, il est roi\nUn outil essentiel pour comprendre les lois\nDans les probabilit\u00e9s, il est li\u00e9 \u00e0 d'autres notions\nOn l'utilise partout, sans aucune restriction"}, {"titre": "Coefficient alpha de Cronbach", "text_origine": "Le coefficient alpha de Cronbach, parfois appel\u00e9 simplement coefficient \n  \n    \n      \n        \u03b1\n      \n    \n    {\\displaystyle \\alpha }\n  , est une statistique utilis\u00e9e notamment en psychom\u00e9trie pour mesurer la coh\u00e9rence interne (ou la fiabilit\u00e9) des questions pos\u00e9es lors d'un test (les r\u00e9ponses aux questions portant sur le m\u00eame sujet devant \u00eatre corr\u00e9l\u00e9es). Sa valeur est inf\u00e9rieure ou \u00e9gale \u00e0 1, \u00e9tant g\u00e9n\u00e9ralement consid\u00e9r\u00e9e comme \"acceptable\" \u00e0 partir de 0,7. Le coefficient alpha de Cronbach doit dans tous les cas \u00eatre calcul\u00e9 apr\u00e8s la validit\u00e9 interne d'un test, on dira donc que la validit\u00e9 interne est un pr\u00e9alable au calcul de la fid\u00e9lit\u00e9. \nIl permet donc l\u2019estimation de la fid\u00e9lit\u00e9 du score \u00e0 un test. Pr\u00e9sent\u00e9 par Lee Cronbach en 1951, le coefficient alpha peut \u00eatre con\u00e7u comme une g\u00e9n\u00e9ralisation au cas de  variables continues de la formule 20 de Kuder-Richardson (KR-20) pour des items dichotomiques.", "element_cle": "1. Le coefficient alpha de Cronbach est une statistique utilis\u00e9e en psychom\u00e9trie pour mesurer la coh\u00e9rence interne des questions d'un test.\n2. Sa valeur est inf\u00e9rieure ou \u00e9gale \u00e0 1 et est consid\u00e9r\u00e9e comme \"acceptable\" \u00e0 partir de 0,7.\n3. Le coefficient alpha de Cronbach doit \u00eatre calcul\u00e9 apr\u00e8s la validit\u00e9 interne d'un test.\n4. Il permet d'estimer la fid\u00e9lit\u00e9 du score \u00e0 un test.\n5. Le coefficient alpha de Cronbach a \u00e9t\u00e9 pr\u00e9sent\u00e9 par Lee Cronbach en 1951.", "rap": "[Couplet 1]\nLe coefficient alpha de Cronbach,\nUn outil de mesure, un v\u00e9ritable coach,\nEn psychom\u00e9trie, il est roi,\nPour \u00e9valuer la coh\u00e9rence des choix.\n\nDe z\u00e9ro \u00e0 un, sa valeur s'\u00e9tend,\nMais \u00e0 partir de 0,7, on peut se dire gagnant,\nIl nous guide dans nos tests,\nPour donner des r\u00e9sultats qu'on peut estimer.\n\n[Refrain]\nAlpha de Cronbach, c'est le ma\u00eetre de c\u00e9r\u00e9monie,\nOn valide nos questions, on met tout en harmonie,\nIl nous montre la fiabilit\u00e9,\nLe score fid\u00e8le \u00e0 nos \u00e9tudes, c'est garanti.\n\n[Couplet 2]\nMais avant de calculer ce coefficient,\nLa validit\u00e9 interne on la tient,\nOn \u00e9vite les biais, les erreurs,\nPour obtenir des donn\u00e9es de qualit\u00e9 et de saveur.\n\nPr\u00e9sent\u00e9 par Cronbach, ce g\u00e9nie,\nEn 1951, c'\u00e9tait l'ann\u00e9e de sa magie,\nDepuis lors, on l'utilise,\nPour mesurer nos tests, nos \u00e9tudes, notre prise.\n\n[Refrain]\nAlpha de Cronbach, c'est le ma\u00eetre de c\u00e9r\u00e9monie,\nOn valide nos questions, on met tout en harmonie,\nIl nous montre la fiabilit\u00e9,\nLe score fid\u00e8le \u00e0 nos \u00e9tudes, c'est garanti."}, {"titre": "Coefficient RV", "text_origine": "En statistique, le coefficient RV (pour rh\u00f4-vectoriel) est une g\u00e9n\u00e9ralisation multivari\u00e9e du coefficient de corr\u00e9lation de Pearson  au carr\u00e9 (car le coefficient RV prend des valeurs comprises entre 0 et 1). Dans sa version population, il mesure le lien entre deux groupes de variables al\u00e9atoires en se basant sur la matrice de variance-covariance. Il peut \u00eatre estim\u00e9 via la matrice de covariance empirique calcul\u00e9e \u00e0 partir d'un \u00e9chantillon.\nLes principales approches de l'analyse statistique multivari\u00e9e des donn\u00e9es peuvent toutes \u00eatre int\u00e9gr\u00e9es dans un cadre commun dans lequel le coefficient RV est maximis\u00e9 sous r\u00e9serve de contraintes pertinentes. Plus pr\u00e9cis\u00e9ment, ces m\u00e9thodologies statistiques comprennent :\n\nl'analyse des composants principaux ;\nl'analyse de corr\u00e9lation canonique ;\nla r\u00e9gression multivari\u00e9e ;\nla classification statistique (discrimination lin\u00e9aire).Un exemple d'application du coefficient RV est en neuroimagerie fonctionnelle o\u00f9 il peut mesurer la similitude entre les s\u00e9ries de scans c\u00e9r\u00e9braux de deux sujets ou entre diff\u00e9rents scans d'un m\u00eame sujet.", "element_cle": "- Le coefficient RV est une g\u00e9n\u00e9ralisation multivari\u00e9e du coefficient de corr\u00e9lation de Pearson.\n- Il mesure le lien entre deux groupes de variables al\u00e9atoires \u00e0 l'aide de la matrice de variance-covariance.\n- Il peut \u00eatre estim\u00e9 \u00e0 partir de la matrice de covariance empirique d'un \u00e9chantillon.\n- Le coefficient RV peut \u00eatre maximis\u00e9 sous certaines contraintes dans le cadre de diff\u00e9rentes approches statistiques multivari\u00e9es.\n- Il est utilis\u00e9 en neuroimagerie fonctionnelle pour mesurer la similitude entre les s\u00e9ries de scans c\u00e9r\u00e9braux.", "rap": "[Couplet 1]\nCoefficient RV, une g\u00e9n\u00e9ralisation de taille,\nPour mesurer l'lien entre variables sans faille,\nPearson, t'as pos\u00e9 les bases solides,\nRV, on pousse l'analyse multidimensionnelle, rapide.\n\nMatrice variance-covariance, c'est notre outil,\nPour calculer l'corr\u00e9lation, on reste subtil,\nEstim\u00e9 depuis l'matrice empirique \u00e0 bon escient,\nRV, on capte l'essence de la d\u00e9pendance.\n\n[Refrain]\nCoefficient RV, dans l'game on l'a bien piger,\nPour \u00e9valuer les liens, rien n'peut nous d\u00e9vier,\nOn fait dans l'\u00e9ducatif, on ride avec la science,\nRV, on te fait voyager dans notre r\u00e9silience.\n\n[Couplet 2]\nMaximis\u00e9 sous contraintes, on ma\u00eetrise les ficelles,\nRV, on creuse les approches statistiques sans faiblesses,\nNeuroimagerie, fonctionnelle dans nos esprits,\nRV, on mesure la ressemblance des scans infinis.\n\nDates, \u00e9v\u00e9nements, marqu\u00e9s dans notre parcours,\nRV, on fait r\u00e9sonner le savoureux retour,\n\u00c9ducateurs, rappeurs dans cette fusion,\nRV, on met l'accent sur l'\u00e9ducation sans confusion.\n\n[Refrain]\nCoefficient RV, dans l'game on l'a bien piger,\nPour \u00e9valuer les liens, rien n'peut nous d\u00e9vier,\nOn fait dans l'\u00e9ducatif, on ride avec la science,\nRV, on te fait voyager dans notre r\u00e9silience."}, {"titre": "Asym\u00e9trie (statistiques)", "text_origine": "En th\u00e9orie des probabilit\u00e9s et statistique, le coefficient d'asym\u00e9trie (skewness en anglais) correspond \u00e0 une mesure de l\u2019asym\u00e9trie de la distribution d\u2019une variable al\u00e9atoire r\u00e9elle.\nC\u2019est le premier des param\u00e8tres de forme, avec le kurtosis (les param\u00e8tres bas\u00e9s sur les moments d\u2019ordre 5 et plus n\u2019ont pas de nom attribu\u00e9).\nEn termes g\u00e9n\u00e9raux, l\u2019asym\u00e9trie d\u2019une distribution est positive si la queue de droite (\u00e0 valeurs hautes) est plus longue ou grosse, et n\u00e9gative si la queue de gauche (\u00e0 valeurs basses) est plus longue ou grosse.", "element_cle": "1. Le coefficient d'asym\u00e9trie est une mesure de l'asym\u00e9trie d'une distribution de variables al\u00e9atoires r\u00e9elles.\n2. Le coefficient d'asym\u00e9trie est le premier param\u00e8tre de forme, en conjonction avec le kurtosis.\n3. L'asym\u00e9trie est positive si la queue droite de la distribution est plus longue ou grosse.\n4. L'asym\u00e9trie est n\u00e9gative si la queue gauche de la distribution est plus longue ou grosse.\n5. Les param\u00e8tres de forme bas\u00e9s sur les moments d'ordre 5 et plus n'ont pas de nom attribu\u00e9.", "rap": "[Couplet 1]\nLe coefficient d'asym\u00e9trie, une notion \u00e0 ne pas n\u00e9gliger\nMesure l'asym\u00e9trie d'une distrib', \u00e7a c'est essentiel\nPremier param\u00e8tre de forme, il est en compagnie\nDu kurtosis, ensemble ils d\u00e9crivent la r\u00e9alit\u00e9\n\n[Refrain]\nAsym\u00e9trie, sym\u00e9trie, voil\u00e0 l'\u00e9quation\nNos stats nous guident pour mieux prendre des d\u00e9cisions\nComprendre les donn\u00e9es et leur configuration\nL'asym\u00e9trie r\u00e9v\u00e8le toute leur variation\n\n[Couplet 2]\nPositif ou n\u00e9gatif, l'asym\u00e9trie nous montre le chemin\nSi la queue \u00e0 droite est plus longue, on est dans le bon train\nSi c'est la queue \u00e0 gauche qui prend toute la place\nAlors on ajuste, la distrib' trouve sa gr\u00e2ce\n\n[Refrain]\nAsym\u00e9trie, sym\u00e9trie, voil\u00e0 l'\u00e9quation\nNos stats nous guident pour mieux prendre des d\u00e9cisions\nComprendre les donn\u00e9es et leur configuration\nL'asym\u00e9trie r\u00e9v\u00e8le toute leur variation\n\n[Outro]\nLes moments d'ordre 5 et plus ont pas de nom attribu\u00e9\nMais \u00e7a n'emp\u00eache pas l'asym\u00e9trie de nous \u00e9clairer\nAlors on creuse, on analyse, on comprend ce qu'elle r\u00e9v\u00e8le\nPour mieux appr\u00e9hender les chiffres et faire des merveilles"}, {"titre": "Corr\u00e9lation de Spearman", "text_origine": "En statistique, la corr\u00e9lation de Spearman ou rho de Spearman, nomm\u00e9e d'apr\u00e8s Charles Spearman (1863-1945) et souvent not\u00e9e par la lettre grecque \n  \n    \n      \n        \u03c1\n      \n    \n    {\\displaystyle \\rho }\n   (rho) ou \n  \n    \n      \n        \n          r\n          \n            s\n          \n        \n      \n    \n    {\\displaystyle r_{s}}\n   est une mesure de d\u00e9pendance statistique non param\u00e9trique entre deux variables.\nLa corr\u00e9lation de Spearman est \u00e9tudi\u00e9e lorsque deux variables statistiques semblent corr\u00e9l\u00e9es sans que la relation entre les deux variables soit de type affine. Elle consiste \u00e0 trouver un coefficient de corr\u00e9lation, non pas entre les valeurs prises par les deux variables mais entre les rangs de ces valeurs. Elle estime \u00e0 quel point la relation entre deux variables peut \u00eatre d\u00e9crite par une fonction monotone. S'il n'y a pas de donn\u00e9es r\u00e9p\u00e9t\u00e9es, une corr\u00e9lation de Spearman parfaite de +1 ou -1 est obtenue quand l'une des variables est une fonction monotone parfaite de l'autre.", "element_cle": "1. La corr\u00e9lation de Spearman est une mesure de d\u00e9pendance statistique non param\u00e9trique entre deux variables.\n2. Elle est \u00e9tudi\u00e9e lorsque les deux variables semblent corr\u00e9l\u00e9es sans que la relation entre elles soit de type affine.\n3. Elle repose sur les rangs des valeurs des variables plut\u00f4t que sur les valeurs elles-m\u00eames.\n4. Cette mesure permet d'estimer \u00e0 quel point la relation entre les variables peut \u00eatre d\u00e9crite par une fonction monotone.\n5. Une corr\u00e9lation de Spearman parfaite de +1 ou -1 est obtenue lorsque l'une des variables est une fonction monotone parfaite de l'autre.", "rap": "[Couplet 1]\nLa corr\u00e9lation de Spearman, c'est du lourd\nUne mesure de d\u00e9pendance, \u00e7a vaut de l'or\nQuand deux variables sont pas affines\nC'est l\u00e0 qu'on sort cette m\u00e9thode non lin\u00e9aire fine\n\nElle compare pas les valeurs, mais les rangs\nFaut bien comprendre avant de te lancer\nElle est l\u00e0 pour estimer la relation\nQuand une fonction monotone est en action\n\n[Refrain]\nSpearman, c'est le nom qui claque\nCorr\u00e9lation non param\u00e9trique, \u00e7a frappe\nOn cherche \u00e0 voir si \u00e7a se suit \u00e0 la trace\nDes valeurs qui bougent, quelle classe\n\n[Couplet 2]\nUne corr\u00e9lation parfaite, c'est le nirvana\nQuand la fonction monotone nous fait kiffer \u00e0 fond\nUn +1 ou un -1, c'est le jackpot\nLes variables en parfaite symbiose, c'est trop beau\n\nAlors on \u00e9tudie, on compare les classements\nPour voir si y'a une relation vraiment marquante\nLa corr\u00e9lation de Spearman, elle nous parle\nDe d\u00e9pendance statistique, elle en vaut le coup\n\n[Refrain]\nSpearman, c'est le nom qui claque\nCorr\u00e9lation non param\u00e9trique, \u00e7a frappe\nOn cherche \u00e0 voir si \u00e7a se suit \u00e0 la trace\nDes valeurs qui bougent, quelle classe"}, {"titre": "Corr\u00e9lation (statistiques)", "text_origine": "En probabilit\u00e9s et en statistique, la corr\u00e9lation entre plusieurs variables al\u00e9atoires ou statistiques est une notion de liaison qui contredit leur ind\u00e9pendance.\nCette corr\u00e9lation est tr\u00e8s souvent r\u00e9duite \u00e0 la corr\u00e9lation lin\u00e9aire entre variables quantitatives, c\u2019est-\u00e0-dire l\u2019ajustement d\u2019une variable par rapport \u00e0 l\u2019autre par une relation affine obtenue par r\u00e9gression lin\u00e9aire. Pour cela, on calcule un coefficient de corr\u00e9lation lin\u00e9aire, quotient de leur covariance par le produit de leurs \u00e9carts types. Son signe indique si des valeurs plus hautes de l\u2019une correspondent \u00ab en moyenne \u00bb \u00e0 des valeurs plus hautes ou plus basses pour l\u2019autre. La valeur absolue du coefficient, toujours comprise entre 0 et 1, ne mesure pas l\u2019intensit\u00e9 de la liaison mais la pr\u00e9pond\u00e9rance de la relation affine sur les variations internes des variables. Un coefficient nul n\u2019implique pas l'ind\u00e9pendance, car d\u2019autres types de corr\u00e9lation sont possibles.\nD\u2019autres indicateurs permettent de calculer un coefficient de corr\u00e9lation pour des variables ordinales.\nLe fait que deux variables soient \u00ab fortement corr\u00e9l\u00e9es \u00bb ne d\u00e9montre pas qu'il y ait une relation de causalit\u00e9 entre l'une et l'autre. Le contre-exemple le plus typique est celui o\u00f9 elles sont en fait li\u00e9es par une causalit\u00e9 commune. Cette confusion est connue sous l'expression Cum hoc ergo propter hoc.", "element_cle": "1. La corr\u00e9lation est une notion de liaison entre variables al\u00e9atoires ou statistiques qui contredit leur ind\u00e9pendance.\n2. La corr\u00e9lation lin\u00e9aire est souvent utilis\u00e9e pour \u00e9valuer l'ajustement d'une variable par rapport \u00e0 une autre.\n3. Le coefficient de corr\u00e9lation lin\u00e9aire mesure la pr\u00e9pond\u00e9rance de la relation affine entre les variables.\n4. Un coefficient nul ne signifie pas n\u00e9cessairement une absence de corr\u00e9lation.\n5. Il existe d'autres types de corr\u00e9lation et d'indicateurs pour variables ordinales.\n6. La corr\u00e9lation ne prouve pas une relation de causalit\u00e9 entre les variables.\n7. Parfois, deux variables sont corr\u00e9l\u00e9es en raison d'une causalit\u00e9 commune.\n8. Il est important de ne pas confondre corr\u00e9lation et causalit\u00e9.\n9. La confusion entre corr\u00e9lation et causalit\u00e9 est connue sous l'expression \"Cum hoc ergo propter hoc.\"\n10. La corr\u00e9lation ne peut pas \u00eatre utilis\u00e9e pour pr\u00e9dire une relation causale entre variables.", "rap": "[Refrain]\nYo, laisse-moi t'expliquer la corr\u00e9lation\nEntre les stats, y'a pas d'ind\u00e9pendance\nLa liaison entre les variables, c'est pas du vent\nEt \u00e7a, \u00e7a m\u00e9rite mon \u00e9loquence\n\n[Couplet 1]\nLa corr\u00e9lation lin\u00e9aire, un concept important\nPour \u00e9valuer l'ajustement et les rapports constants\nLe coefficient mesure la relation pr\u00e9dominante\nEntre les variables, une relation affin\u00e9e\n\nUn coefficient nul, c'est pas un billet de sortie\nPas d'absence de corr\u00e9lation, laisse-moi te dire\nD'autres types existent, pour les variables ordonn\u00e9es\nDes indicateurs diff\u00e9rents pour bien se mesurer\n\n[Couplet 2]\nNe confonds pas corr\u00e9lation et causalit\u00e9\nC'est deux choses diff\u00e9rentes, faut pas m\u00e9langer\nParfois, faut voir plus loin, chercher une causalit\u00e9 commune\nC'est pas tout simplement une corr\u00e9lation opportune\n\nLa confusion persiste, Cum hoc ergo propter hoc\nL'erreur fr\u00e9quente, chaque fois le m\u00eame tempo\nMais la corr\u00e9lation ne peut pas pr\u00e9dire\nLa relation de cause \u00e0 effet, faut bien le dire\n\n[Refrain]\nYo, la corr\u00e9lation, c'est un concept complexe\nMais faut pas prendre \u00e7a avec des pincettes\nStatistiques et variables, \u00e7a peut \u00eatre d\u00e9licat\nMais comprendre la corr\u00e9lation, \u00e7a vaut le coup d'potasser"}, {"titre": "Coefficient alpha de Cronbach", "text_origine": "Le coefficient alpha de Cronbach, parfois appel\u00e9 simplement coefficient \n  \n    \n      \n        \u03b1\n      \n    \n    {\\displaystyle \\alpha }\n  , est une statistique utilis\u00e9e notamment en psychom\u00e9trie pour mesurer la coh\u00e9rence interne (ou la fiabilit\u00e9) des questions pos\u00e9es lors d'un test (les r\u00e9ponses aux questions portant sur le m\u00eame sujet devant \u00eatre corr\u00e9l\u00e9es). Sa valeur est inf\u00e9rieure ou \u00e9gale \u00e0 1, \u00e9tant g\u00e9n\u00e9ralement consid\u00e9r\u00e9e comme \"acceptable\" \u00e0 partir de 0,7. Le coefficient alpha de Cronbach doit dans tous les cas \u00eatre calcul\u00e9 apr\u00e8s la validit\u00e9 interne d'un test, on dira donc que la validit\u00e9 interne est un pr\u00e9alable au calcul de la fid\u00e9lit\u00e9. \nIl permet donc l\u2019estimation de la fid\u00e9lit\u00e9 du score \u00e0 un test. Pr\u00e9sent\u00e9 par Lee Cronbach en 1951, le coefficient alpha peut \u00eatre con\u00e7u comme une g\u00e9n\u00e9ralisation au cas de  variables continues de la formule 20 de Kuder-Richardson (KR-20) pour des items dichotomiques.", "element_cle": "- Le coefficient alpha de Cronbach est utilis\u00e9 en psychom\u00e9trie pour mesurer la coh\u00e9rence interne des questions d'un test.\n- Sa valeur est inf\u00e9rieure ou \u00e9gale \u00e0 1 et est consid\u00e9r\u00e9e \"acceptable\" \u00e0 partir de 0,7.\n- Le coefficient alpha doit \u00eatre calcul\u00e9 apr\u00e8s la validit\u00e9 interne du test.\n- Il est utilis\u00e9 pour estimer la fid\u00e9lit\u00e9 du score \u00e0 un test.\n- Le coefficient alpha a \u00e9t\u00e9 pr\u00e9sent\u00e9 par Lee Cronbach en 1951.", "rap": "[Couplet 1]\nJ'rappe avec science, j'fais mon test mental\nAlpha de Cronbach, c'est l'outil essentiel\nOn mesure la coh\u00e9rence, on veut \u00eatre pr\u00e9cis\nPour \u00e9valuer les questions, y'a pas d'marche \u00e0 l'envers\n\n0,7 minimum, \u00e7a c'est l'objectif\nUn alpha \"acceptable\" pour un test incisif\nMais avant d'calculer, on valide en interne\nPour s'assurer que nos questions, c'est du solide en terme\n\nRefrain:\nEt le coefficient alpha, c'est l'\u00e2me des donn\u00e9es\nUn score fid\u00e8le, \u00e0 l'\u00e9preuve du temps\nCronbach le pr\u00e9senta, en l'an 51\nLes psychom\u00e9triciens, s'en souviennent encore aujourd'hui\n\n[Couplet 2]\nOn veut pas d'erreurs, pas d'incoh\u00e9rences\nLe coefficient alpha, c'est notre assurance\nIl mesure la fid\u00e9lit\u00e9, la constance des r\u00e9ponses\nPour qu'notre test soit solide, on fait pas dans la nonchalance\n\nLes scores sont-ils fiables, on veut savoir\nLe coefficient alpha, c'est le r\u00e9v\u00e9lateur\nIl nous guide dans l'analyse, dans l'interpr\u00e9tation\nPour qu'on puisse affirmer, notre \u00e9valuation\n\nRefrain:\nEt le coefficient alpha, c'est l'\u00e2me des donn\u00e9es\nUn score fid\u00e8le, \u00e0 l'\u00e9preuve du temps\nCronbach le pr\u00e9senta, en l'an 51\nLes psychom\u00e9triciens, s'en souviennent encore aujourd'hui"}, {"titre": "Quotient intellectuel", "text_origine": "Le quotient intellectuel, ou QI, est le r\u00e9sultat d'un test psychom\u00e9trique qui entend fournir une indication quantitative standardis\u00e9e de l'intelligence humaine.\nLe QI est mesur\u00e9 par un psychologue pour des raisons qui peuvent \u00eatre \u00e9ducatives ou psychiatriques. Cependant, le QI, tout comme les notions associ\u00e9es de d\u00e9ficience mentale ou d'enfant \u00e0 haut potentiel intellectuel, n'est pas un diagnostic. Le QI est g\u00e9n\u00e9ralement \u00e9valu\u00e9 dans le cadre plus complet d'un examen psychologique.\nCr\u00e9\u00e9 au d\u00e9but du XXe si\u00e8cle pour d\u00e9pister les \u00e9l\u00e8ves en difficult\u00e9 et leur faire b\u00e9n\u00e9ficier d'un soutien, la notion d'un QI a fait l'objet de nombreuses critiques, m\u00e9thodologiques et psychom\u00e9triques, ou th\u00e9oriques (discussions sur la nature de l'intelligence).", "element_cle": "1. Le quotient intellectuel, ou QI, est un test psychom\u00e9trique qui mesure l'intelligence humaine de mani\u00e8re standardis\u00e9e.\n2. Le QI est mesur\u00e9 par un psychologue pour des raisons \u00e9ducatives ou psychiatriques.\n3. Le QI n'est pas un diagnostic, mais il peut aider \u00e0 identifier des d\u00e9ficiences mentales ou des enfants \u00e0 haut potentiel intellectuel.\n4. Le QI est g\u00e9n\u00e9ralement \u00e9valu\u00e9 dans le cadre d'un examen psychologique complet.\n5. Le QI a \u00e9t\u00e9 cr\u00e9\u00e9 au d\u00e9but du XXe si\u00e8cle pour aider \u00e0 rep\u00e9rer les \u00e9l\u00e8ves en difficult\u00e9 et leur fournir un soutien.\n6. La notion de QI a suscit\u00e9 de nombreuses critiques m\u00e9thodologiques, psychom\u00e9triques et th\u00e9oriques.", "rap": "[Couplet 1]\nQuotient intellectuel, le QI on teste \nTon intelligence, mon fr\u00e8re, est manifeste \nStandardis\u00e9, psychom\u00e9trique, pr\u00e9cis \nLe QI, c'est la cl\u00e9 pour t'instruire, saisir \n\nLe psychologue mesure, \u00e9value \nPour raisons \u00e9ducatives, psychiatriques \nLe QI, \u00e7a d\u00e9c\u00e8le, \u00e7a pr\u00e9dit \nD\u00e9ficiences mentales, potentiel infini \n\n[Refrain]\nLe QI, pas un diagnostic, mais un \u00e9clairage \nPour comprendre, aider, r\u00e9v\u00e9ler ton bagage \nDans un examen psychologique, il s'introduit \nPour t'accompagner, te soutenir, t'\u00e9claircir la nuit \n\n[Couplet 2]\nLe QI, fruit du XXe si\u00e8cle, cr\u00e9\u00e9 \nPour identifier, aider les \u00e9l\u00e8ves en difficult\u00e9 \nUn soutien, une chance pour tous ces gamins \nPour qu'ils puissent s'\u00e9lever, sortir de leur p\u00e9trin \n\nCritiqu\u00e9, remis en question, sans cesse \nM\u00e9thodologique, psychom\u00e9trique, la finesse \nMais malgr\u00e9 les d\u00e9bats, les th\u00e9ories tant\u00f4t courbes \nLe QI reste un outil qu'on garde sous notre barbe \n\n[Refrain]\nLe QI, pas un diagnostic, mais un \u00e9clairage \nPour comprendre, aider, r\u00e9v\u00e9ler ton bagage \nDans un examen psychologique, il s'introduit \nPour t'accompagner, te soutenir, t'\u00e9claircir la nuit"}, {"titre": "Fid\u00e9lit\u00e9 (psychom\u00e9trie)", "text_origine": "En psychom\u00e9trie, la fid\u00e9lit\u00e9 d'un test psychologique, ou fiabilit\u00e9 d'un test (reliability en anglais), est une des trois grandes mesures de la qualit\u00e9 du test (les deux autres \u00e9tant la sensibilit\u00e9 et la validit\u00e9). Cette mesure est prise lors d'une proc\u00e9dure de standardisation d'un test. Avant sa publication, un test psychologique est g\u00e9n\u00e9ralement \u00e9valu\u00e9 sur de larges \u00e9chantillons de la population. Les r\u00e9sultats de cette proc\u00e9dure sont \u00e9valu\u00e9s : si le test obtient de bons indices de fid\u00e9lit\u00e9 et de validit\u00e9, il est consid\u00e9r\u00e9 comme suffisamment robuste pour \u00eatre publi\u00e9 et utilis\u00e9.", "element_cle": "1. La fid\u00e9lit\u00e9 d'un test psychologique est une mesure de sa qualit\u00e9.\n2. La fid\u00e9lit\u00e9 est l'une des trois grandes mesures de la qualit\u00e9 d'un test, avec la sensibilit\u00e9 et la validit\u00e9.\n3. La fid\u00e9lit\u00e9 est \u00e9valu\u00e9e lors de la standardisation d'un test psychologique.\n4. Avant sa publication, un test psychologique est \u00e9valu\u00e9 sur de larges \u00e9chantillons de la population.\n5. Si un test obtient de bons indices de fid\u00e9lit\u00e9 et de validit\u00e9, il est consid\u00e9r\u00e9 comme suffisamment robuste pour \u00eatre publi\u00e9 et utilis\u00e9.", "rap": "[Couplet 1]\nLa fid\u00e9lit\u00e9 d'un test, mesurer sa qualit\u00e9\nUn crit\u00e8re crucial dans le psychologique\nAvec sensibilit\u00e9 et validit\u00e9, on te l'dit\nCes trois piliers forgent l'utilit\u00e9\n\nStandardisation, \u00e9tape indispensable\nEvaluer la fid\u00e9lit\u00e9 du test, souvent chronophage\nDes \u00e9chantillons larges dans la population\nPour garantir des r\u00e9sultats sans extrapolation\n\n[Refrain]\nFid\u00e9lit\u00e9, mesure primordiale\nDans l'univers des tests psychologiques, c'est une valeur capitale\nValidit\u00e9 et sensibilit\u00e9, deux autres piliers\nPour un diagnostic pr\u00e9cis, c'est pas du pareil au m\u00eame\n\n[Couplet 2]\nUn test doit \u00eatre solide avant publication\nDes indices de fid\u00e9lit\u00e9 qui sortent du lot\nDes r\u00e9sultats fiables, une vraie obsession\nPour que le psychologue sache ce qu'il capte\n\nLa fid\u00e9lit\u00e9, gage de pertinence et de confiance\nSi ton test passe le cap haut la main\nConsid\u00e9r\u00e9 comme robuste, plein d'\u00e9loquence\nPubli\u00e9, utilis\u00e9, il devient une r\u00e9f\u00e9rence\n\n[Refrain]\nFid\u00e9lit\u00e9, mesure primordiale\nDans l'univers des tests psychologiques, c'est une valeur capitale\nValidit\u00e9 et sensibilit\u00e9, deux autres piliers\nPour un diagnostic pr\u00e9cis, c'est pas du pareil au m\u00eame"}]